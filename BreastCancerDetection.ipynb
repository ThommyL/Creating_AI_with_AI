{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "**DISCLAIMER: The author of this notebook and software is in no case liable for any claim, damage or liability that occurs in connection with dealings of the same. Typos, printing-, software- and typesetting errors in this work reserved. The author does not warrant correctness of software or statements made in this work. This notebook is hosted on GitHub solely for the purpose of presentation.**\n",
    "\n",
    "\n",
    "# Using AI to create AI\n",
    "## Building a model for very accurate predictions\n",
    "\n",
    "In this notebook, novel methods of data analysis are used to determine whether breast cancer is malign or benign based on tabular data. Special consideration is given to the fact that only little data is available. This is especially problematic since this leads to high variance when testing models, potentially giving the impression of having a far better (or worse) model at hand than is actually the case.\n",
    "\n",
    "This problem can be (somewhat expensively) taken care of by using K-fold cross-validation. With datasets as small as this one, it is easy to create stratified splits, meaning that each split more or less has the same class distribution. This will have a positive effect on training and reduce the variance between test scores across the splits.\n",
    "\n",
    "(If you run this code, always monitor memory usage, as you can damage your hardware otherwise! There should not be too much written out onto the disk â€” in other words to a page file.) \n",
    "\n",
    "The following few code cells will 'set the scene' by defining a few methods that will be used in the course of the notebook. Feel free to skip ahead!"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"0YbEs9phNbXYwMA94vBbx1",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Dataset\n",
    "The dataset used for this Notebook is from https:\/\/www.kaggle.com\/datasets\/vijayaadithyanvg\/breast-cancer-prediction as seen on 3. Nov. 2022, where it states that it is under the license: \"CC0: Public Domain\" https:\/\/creativecommons.org\/publicdomain\/zero\/1.0\/"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"uDbglIpUKZdqH4tTfo1cWQ",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Set up (Skip this chapter)"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"A9uq0kS2cBCB8R8zKh3bnR",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Config\n",
    "\n",
    "import tracemalloc\n",
    "\n",
    "from optuna.trial import FrozenTrial\n",
    "\n",
    "# Note: This notebook was run with device mps and cpu. The current nightly build of pytorch lead to very high memory consumption with device 'mps'.\n",
    "# Especially if you change this setting always monitor memory usage, as you can damage your hardware otherwise!\n",
    "DEVICE = \"cpu\"  # cpu is actually faster since this tabular data would need more time copying\/converting than calculating\n",
    "RESPONSE_COLUMN = 'diagnosis'\n",
    "OPTUNA_DB = \"sqlite:\/\/\/optuna_breast_cancer_detection.db\"\n",
    "NUM_FOLDS = 5\n",
    "TRAIN_PERC = 0.8\n",
    "TENSORBOARD_LOGDIR_LASSO = \"breast_cancer_detection_lasso\"\n",
    "TENSORBOARD_LOGDIR_NN_SHALLOW = \"breast_cancer_detection_nn_shallow\"\n",
    "TENSORBOARD_LOGDIR_NN_DROPOUT = \"breast_cancer_detection_nn_dropout\"\n",
    "TRAIN_FOR_EPOCHS = 10\n",
    "\n",
    "WAIT = False\n",
    "TRACK_MEMORY = False"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"AUNWfvZSXjtHcOvCIKX7UW",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "if TRACK_MEMORY:\n",
    "    tracemalloc.start()"
   ],
   "execution_count":2,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"kTyJICTAUBbUkAzcO2a1aW",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from typing import List, Tuple, Dict, Union, Callable, Optional\n",
    "\n",
    "\n",
    "# Measure\n",
    "\n",
    "def f1_score(ground_truth: List[int], predictions: List[int]):\n",
    "    fp: int = 0\n",
    "    fn: int = 0\n",
    "    tp: int = 0\n",
    "    tn: int = 0\n",
    "\n",
    "    for p, t in zip(ground_truth, predictions):\n",
    "        assert (p in (-1, 1) and t in (-1, 1)) or (p in (0, 1) and t in (0, 1))\n",
    "\n",
    "        if p == t:\n",
    "            if p == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if p == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    if (2 * tp + fp + fn) == 0:\n",
    "        return 0\n",
    "    f1 = (2 * tp)\/(2 * tp + fp + fn)\n",
    "    assert 0 <= f1 <= 1, f1\n",
    "    return f1"
   ],
   "execution_count":3,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"5N9JHeOeDjpdVy2mUQcllK",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Methods for accessing and manipulating data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_full_dataframe() -> pd.DataFrame:\n",
    "    return pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "def apply_threshold_on_response(response: List[float], to_zero) -> List[float]:\n",
    "    if to_zero:\n",
    "        sub = 0\n",
    "    else:\n",
    "        sub = -1\n",
    "    return [sub if r < 0 else 1 for r in response]\n",
    "\n",
    "\n",
    "def split_to_train_test(df: pd.DataFrame, train_ratio: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    lengths = [int(len(df) * p) for p in (train_ratio, 1 - train_ratio)]\n",
    "    lengths[0] += len(df) - sum(lengths)\n",
    "\n",
    "    tmp_x, tmp_y = split_to_xy(df)\n",
    "    x_tr: pd.DataFrame\n",
    "    y_tr: pd.DataFrame\n",
    "    x_te: pd.DataFrame\n",
    "    y_te: pd.DataFrame\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(tmp_x, tmp_y, stratify=tmp_y[RESPONSE_COLUMN],\n",
    "                                                        test_size=1 - train_ratio, random_state=0)\n",
    "    return x_tr.join(y_tr[RESPONSE_COLUMN]), x_te.join(y_te[RESPONSE_COLUMN])\n",
    "\n",
    "\n",
    "def split_to_xy(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    tmp_x = df.copy()\n",
    "    tmp_y = pd.DataFrame(tmp_x[RESPONSE_COLUMN])\n",
    "    tmp_x = tmp_x.drop(columns=[RESPONSE_COLUMN])\n",
    "    tmp_indexes = pd.DataFrame(tmp_x['id'])\n",
    "    return tmp_x, tmp_indexes.join(tmp_y)\n",
    "\n",
    "\n",
    "def get_stratified_k_fold_splits(df, num_folds: int) -> Tuple[Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    tmp_x, tmp_y = split_to_xy(df)\n",
    "\n",
    "    mb: MultiLabelBinarizer = MultiLabelBinarizer(classes=list(tmp_y[RESPONSE_COLUMN].unique()))\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_folds, random_state=0, shuffle=True)\n",
    "\n",
    "    training_ids: List[List[int]] = []\n",
    "    test_ids: List[List[int]] = []\n",
    "\n",
    "    for train, test in mskf.split(tmp_x, mb.fit_transform(list(tmp_y[RESPONSE_COLUMN]))):\n",
    "        current_train = []\n",
    "        for t in train:\n",
    "            current_train.append(tmp_y.iloc[t]['id'])\n",
    "        training_ids.append(current_train)\n",
    "\n",
    "        current_test = []\n",
    "        for t in test:\n",
    "            current_test.append(tmp_y.iloc[t]['id'])\n",
    "        test_ids.append(current_test)\n",
    "    split_datasets = []\n",
    "\n",
    "    for i in range(num_folds):\n",
    "        cur_train: pd.DataFrame = df.loc[df['id'].isin(training_ids[i])]\n",
    "        cur_test: pd.DataFrame = df.loc[~df['id'].isin(training_ids[i])]\n",
    "        split_datasets.append((cur_train, cur_test))\n",
    "    return tuple(split_datasets)\n",
    "\n",
    "\n",
    "def binarize_response(df: pd.DataFrame, to_zero) -> pd.DataFrame:\n",
    "    tmp = df.copy()\n",
    "    if to_zero:\n",
    "        sub = 0\n",
    "    else:\n",
    "        sub = -1\n",
    "    tmp[RESPONSE_COLUMN] = tmp[RESPONSE_COLUMN].apply(lambda x: 1 if (x == 'M' or x == 1) else sub)\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def df_no_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.copy().drop(columns=['id'])\n",
    "\n",
    "\n",
    "def expand_classes(c: int) -> Tuple[int, int]:\n",
    "    if c in (-1, 0):\n",
    "        return 0, 1\n",
    "    return 1, 0"
   ],
   "execution_count":4,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"I6vBBbzzq4efYMAAqLwR5N",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import time\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "def possible_emergency_brake():\n",
    "    # Do not allow usage of more than 1 GB of memory\n",
    "    if TRACK_MEMORY and tracemalloc.get_tracemalloc_memory() \/1e9 > 1:\n",
    "        raise Exception('Aborted due to unexpectedly high memory usage')\n",
    "\n",
    "def view_tensorboard(logdir: str):\n",
    "    # Note: Viewing other tensorboard requires kernel restart.\n",
    "    %load_ext tensorboard\n",
    "    delete_tensorboard_instances()\n",
    "\n",
    "    %tensorboard --logdir {logdir}  --host localhost\n",
    "\n",
    "# check what works best for your system\n",
    "def cpu_cooldown():\n",
    "    if WAIT:\n",
    "        time.sleep(0.15)"
   ],
   "execution_count":5,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"1l4Ah1zO4ExDzkhfrmx4lN",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Convenience methods for during development\n",
    "import optuna\n",
    "import tempfile\n",
    "# from tensorboard import notebook\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def delete_tensorboard_instances():\n",
    "    if os.path.exists(tensorboard_tmp_files_path := os.path.join(tempfile.gettempdir(), '.tensorboard-info')):\n",
    "        shutil.rmtree(tensorboard_tmp_files_path)\n",
    "delete_tensorboard_instances()\n",
    "\n",
    "\n",
    "def delete_study(name: str) -> None:\n",
    "    try:\n",
    "        optuna.delete_study(storage=OPTUNA_DB, study_name=name)\n",
    "        shutil.rmtree('breast_cancer_detection_' + name)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    except Exception as ex:\n",
    "        raise ex"
   ],
   "execution_count":46,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"Df74U8JPHM1pgkGkl6cZKj",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Data Exploration"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"i7s2YByt0vJWqBmAb8kV88",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "It is bad practice to skip data exploration, but this would take up a lot of this notebook which is really about something else. You can find data exploration to this dataset on the internet. In \"real projects\" never skip this step!"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"LeXMSY459LAzCGuiSnnjzZ",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_all = get_full_dataframe()\n",
    "assert len(df_all[RESPONSE_COLUMN].unique()) == 2\n",
    "df_all"
   ],
   "execution_count":8,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>id<\/th>\n",
       "      <th>diagnosis<\/th>\n",
       "      <th>Radius_mean<\/th>\n",
       "      <th>Texture_mean<\/th>\n",
       "      <th>perimeter_mean<\/th>\n",
       "      <th>area_mean<\/th>\n",
       "      <th>smoothness_mean<\/th>\n",
       "      <th>compactness_mean<\/th>\n",
       "      <th>concavity_mean<\/th>\n",
       "      <th>concave points_mean<\/th>\n",
       "      <th>...<\/th>\n",
       "      <th>radius_worst<\/th>\n",
       "      <th>texture_worst<\/th>\n",
       "      <th>perimeter_worst<\/th>\n",
       "      <th>area_worst<\/th>\n",
       "      <th>smoothness_worst<\/th>\n",
       "      <th>compactness_worst<\/th>\n",
       "      <th>concavity_worst<\/th>\n",
       "      <th>concave points_worst<\/th>\n",
       "      <th>symmetry_worst<\/th>\n",
       "      <th>fractal_dimension_worst<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>842302<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>17.99<\/td>\n",
       "      <td>10.38<\/td>\n",
       "      <td>122.80<\/td>\n",
       "      <td>1001.0<\/td>\n",
       "      <td>0.11840<\/td>\n",
       "      <td>0.27760<\/td>\n",
       "      <td>0.30010<\/td>\n",
       "      <td>0.14710<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>25.380<\/td>\n",
       "      <td>17.33<\/td>\n",
       "      <td>184.60<\/td>\n",
       "      <td>2019.0<\/td>\n",
       "      <td>0.16220<\/td>\n",
       "      <td>0.66560<\/td>\n",
       "      <td>0.7119<\/td>\n",
       "      <td>0.2654<\/td>\n",
       "      <td>0.4601<\/td>\n",
       "      <td>0.11890<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>842517<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>20.57<\/td>\n",
       "      <td>21.77<\/td>\n",
       "      <td>132.90<\/td>\n",
       "      <td>1326.0<\/td>\n",
       "      <td>0.08474<\/td>\n",
       "      <td>0.07864<\/td>\n",
       "      <td>0.08690<\/td>\n",
       "      <td>0.07017<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>24.990<\/td>\n",
       "      <td>23.41<\/td>\n",
       "      <td>158.80<\/td>\n",
       "      <td>1956.0<\/td>\n",
       "      <td>0.12380<\/td>\n",
       "      <td>0.18660<\/td>\n",
       "      <td>0.2416<\/td>\n",
       "      <td>0.1860<\/td>\n",
       "      <td>0.2750<\/td>\n",
       "      <td>0.08902<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>84300903<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>19.69<\/td>\n",
       "      <td>21.25<\/td>\n",
       "      <td>130.00<\/td>\n",
       "      <td>1203.0<\/td>\n",
       "      <td>0.10960<\/td>\n",
       "      <td>0.15990<\/td>\n",
       "      <td>0.19740<\/td>\n",
       "      <td>0.12790<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>23.570<\/td>\n",
       "      <td>25.53<\/td>\n",
       "      <td>152.50<\/td>\n",
       "      <td>1709.0<\/td>\n",
       "      <td>0.14440<\/td>\n",
       "      <td>0.42450<\/td>\n",
       "      <td>0.4504<\/td>\n",
       "      <td>0.2430<\/td>\n",
       "      <td>0.3613<\/td>\n",
       "      <td>0.08758<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>84348301<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>11.42<\/td>\n",
       "      <td>20.38<\/td>\n",
       "      <td>77.58<\/td>\n",
       "      <td>386.1<\/td>\n",
       "      <td>0.14250<\/td>\n",
       "      <td>0.28390<\/td>\n",
       "      <td>0.24140<\/td>\n",
       "      <td>0.10520<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>14.910<\/td>\n",
       "      <td>26.50<\/td>\n",
       "      <td>98.87<\/td>\n",
       "      <td>567.7<\/td>\n",
       "      <td>0.20980<\/td>\n",
       "      <td>0.86630<\/td>\n",
       "      <td>0.6869<\/td>\n",
       "      <td>0.2575<\/td>\n",
       "      <td>0.6638<\/td>\n",
       "      <td>0.17300<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>84358402<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>20.29<\/td>\n",
       "      <td>14.34<\/td>\n",
       "      <td>135.10<\/td>\n",
       "      <td>1297.0<\/td>\n",
       "      <td>0.10030<\/td>\n",
       "      <td>0.13280<\/td>\n",
       "      <td>0.19800<\/td>\n",
       "      <td>0.10430<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>22.540<\/td>\n",
       "      <td>16.67<\/td>\n",
       "      <td>152.20<\/td>\n",
       "      <td>1575.0<\/td>\n",
       "      <td>0.13740<\/td>\n",
       "      <td>0.20500<\/td>\n",
       "      <td>0.4000<\/td>\n",
       "      <td>0.1625<\/td>\n",
       "      <td>0.2364<\/td>\n",
       "      <td>0.07678<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>...<\/th>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>564<\/th>\n",
       "      <td>926424<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>21.56<\/td>\n",
       "      <td>22.39<\/td>\n",
       "      <td>142.00<\/td>\n",
       "      <td>1479.0<\/td>\n",
       "      <td>0.11100<\/td>\n",
       "      <td>0.11590<\/td>\n",
       "      <td>0.24390<\/td>\n",
       "      <td>0.13890<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>25.450<\/td>\n",
       "      <td>26.40<\/td>\n",
       "      <td>166.10<\/td>\n",
       "      <td>2027.0<\/td>\n",
       "      <td>0.14100<\/td>\n",
       "      <td>0.21130<\/td>\n",
       "      <td>0.4107<\/td>\n",
       "      <td>0.2216<\/td>\n",
       "      <td>0.2060<\/td>\n",
       "      <td>0.07115<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>565<\/th>\n",
       "      <td>926682<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>20.13<\/td>\n",
       "      <td>28.25<\/td>\n",
       "      <td>131.20<\/td>\n",
       "      <td>1261.0<\/td>\n",
       "      <td>0.09780<\/td>\n",
       "      <td>0.10340<\/td>\n",
       "      <td>0.14400<\/td>\n",
       "      <td>0.09791<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>23.690<\/td>\n",
       "      <td>38.25<\/td>\n",
       "      <td>155.00<\/td>\n",
       "      <td>1731.0<\/td>\n",
       "      <td>0.11660<\/td>\n",
       "      <td>0.19220<\/td>\n",
       "      <td>0.3215<\/td>\n",
       "      <td>0.1628<\/td>\n",
       "      <td>0.2572<\/td>\n",
       "      <td>0.06637<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>566<\/th>\n",
       "      <td>926954<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>16.60<\/td>\n",
       "      <td>28.08<\/td>\n",
       "      <td>108.30<\/td>\n",
       "      <td>858.1<\/td>\n",
       "      <td>0.08455<\/td>\n",
       "      <td>0.10230<\/td>\n",
       "      <td>0.09251<\/td>\n",
       "      <td>0.05302<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>18.980<\/td>\n",
       "      <td>34.12<\/td>\n",
       "      <td>126.70<\/td>\n",
       "      <td>1124.0<\/td>\n",
       "      <td>0.11390<\/td>\n",
       "      <td>0.30940<\/td>\n",
       "      <td>0.3403<\/td>\n",
       "      <td>0.1418<\/td>\n",
       "      <td>0.2218<\/td>\n",
       "      <td>0.07820<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>567<\/th>\n",
       "      <td>927241<\/td>\n",
       "      <td>M<\/td>\n",
       "      <td>20.60<\/td>\n",
       "      <td>29.33<\/td>\n",
       "      <td>140.10<\/td>\n",
       "      <td>1265.0<\/td>\n",
       "      <td>0.11780<\/td>\n",
       "      <td>0.27700<\/td>\n",
       "      <td>0.35140<\/td>\n",
       "      <td>0.15200<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>25.740<\/td>\n",
       "      <td>39.42<\/td>\n",
       "      <td>184.60<\/td>\n",
       "      <td>1821.0<\/td>\n",
       "      <td>0.16500<\/td>\n",
       "      <td>0.86810<\/td>\n",
       "      <td>0.9387<\/td>\n",
       "      <td>0.2650<\/td>\n",
       "      <td>0.4087<\/td>\n",
       "      <td>0.12400<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>568<\/th>\n",
       "      <td>92751<\/td>\n",
       "      <td>B<\/td>\n",
       "      <td>7.76<\/td>\n",
       "      <td>24.54<\/td>\n",
       "      <td>47.92<\/td>\n",
       "      <td>181.0<\/td>\n",
       "      <td>0.05263<\/td>\n",
       "      <td>0.04362<\/td>\n",
       "      <td>0.00000<\/td>\n",
       "      <td>0.00000<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>9.456<\/td>\n",
       "      <td>30.37<\/td>\n",
       "      <td>59.16<\/td>\n",
       "      <td>268.6<\/td>\n",
       "      <td>0.08996<\/td>\n",
       "      <td>0.06444<\/td>\n",
       "      <td>0.0000<\/td>\n",
       "      <td>0.0000<\/td>\n",
       "      <td>0.2871<\/td>\n",
       "      <td>0.07039<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<p>569 rows Ã— 32 columns<\/p>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"wTSlF4psJPZnZf7Tv2UnUR",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Set up for training models\n",
    "\n",
    "Maybe we want to test our models later with different meassures in mind. The results will therefore be categorized according to the measure as well as the modelclass."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"BaZ0ZzdEoICitadbkD6C3A",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# measure, method\n",
    "measure_dict: Dict[str, callable] = dict()\n",
    "\n",
    "# measure, model, result\n",
    "result_dict: Dict[str, Dict[str, float]] = dict()"
   ],
   "execution_count":9,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"nFHoIDAFmITFDiSilRtqzE",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "We could use all data to train but then we would never know how good the model performs in unseen cases. Thus we split a part of the data into a testset, which must only be used once by each model - at the final evaluation that is."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"4NDfWDgxIW2j4ibbBywQqA",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_train, df_test = split_to_train_test(df_all, TRAIN_PERC)\n",
    "assert len(df_train) > len(df_test)\n",
    "print('Length of training data {}\\nLength of test data: {}\\nTotal length: {}\\nRatio train to test: {}\\nRatio test to total: {}'.format(len_train := len(df_train), len_test := len(df_test), len_total := len_train + len_test, len_train \/ len_total, len_test \/ len_total))"
   ],
   "execution_count":10,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Length of training data 455\n",
      "Length of test data: 114\n",
      "Total length: 569\n",
      "Ratio train to test: 0.7996485061511424\n",
      "Ratio test to total: 0.20035149384885764\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"1roiDryVSBaDQG51JZyw2e",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "This is close to what was intended. Now the training dataset is split up into many fold. It is important to note that the test dataset will not be part of the folds!"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"h75CV1oxkiGoXQWeFFDUMJ",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "datasets_tvt = get_stratified_k_fold_splits(df_train, num_folds=NUM_FOLDS)"
   ],
   "execution_count":11,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"IrvvIaomvrWew5MOF3p0mI",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Instead of predicting 'b' or 'm' it makes more sense to predict -1 or +1. The reason why this was chosen over 0 and 1 is that this way a simple sign function can be used to later threshold the response of the model which is a real number. Note that this is only relevant for the lasso regression and later on in the notebook the more conventional 0 and 1 will be used."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"VpIZ2IFc4hD7fT1fDU39NC",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "tmp_datasets_tvt = []\n",
    "for i in range(len(datasets_tvt)):\n",
    "    tmp_datasets_tvt.append((datasets_tvt[i][0], binarize_response(datasets_tvt[i][1], False)))\n",
    "datasets_tvt = tmp_datasets_tvt\n",
    "del tmp_datasets_tvt"
   ],
   "execution_count":12,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"BEY7zds88Irgo1jQxLqUtD",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "The sets are split up to inputs and targets"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"FDvTRI3sbSJMuLVbWxWhkr",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "all_X_train, all_y_train = split_to_xy(df_train)\n",
    "all_X_test, all_y_test = split_to_xy(df_test)"
   ],
   "execution_count":13,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"kyczJlt4S7TmCo22YyQdnN",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "The F1 score can be used for binary classification tasks"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"o0XuxclhR01ZdvV0NdT4FW",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "measure_dict['F1'] = f1_score\n",
    "result_dict['F1'] = dict()"
   ],
   "execution_count":14,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"OiwCLYlIi09fn84LkOuosc",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Baseline model - Lasso regression\n",
    "\n",
    "Now a lasso model is trained, but what hyper parameters should be chosen? A simple approach would be using a grid search which is essentially just trying out every combination of values from predefined spectrum. This would be hugily inefficient. Enter optuna - This library conducts experiments and learns from previous runs, thus selecting parameters far more efficiently. It can also parameterize dynamically which will be seen later in this notebook. With very little additional effort we can create one of the best possible models in this model class."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ammHXUMm2zroH1uYoDBaZx",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from optuna.integration import TensorBoardCallback\n",
    "from sklearn import preprocessing\n",
    "scalers = [preprocessing.MinMaxScaler(), preprocessing.RobustScaler(), preprocessing.StandardScaler(), preprocessing.Normalizer()]\n",
    "\n",
    "tensorboard_callback_lasso = TensorBoardCallback(TENSORBOARD_LOGDIR_LASSO + '\/', metric_name=\"F1\")\n",
    "\n",
    "try:\n",
    "    study = optuna.load_study(storage=OPTUNA_DB, study_name=\"lasso_regression\")\n",
    "except KeyError:\n",
    "    def objective(trial):\n",
    "        scaler = scalers[trial.suggest_categorical(name='scaler', choices=[0,1,2,3])]\n",
    "\n",
    "        f1_scores = []\n",
    "        for lasso_seed, d in enumerate(datasets_tvt):\n",
    "            k_train_X, k_train_y = split_to_xy(d[0])\n",
    "            k_train_X = pd.DataFrame(scaler.fit_transform(k_train_X.to_numpy()), columns=k_train_X.columns)\n",
    "            k_test_X, k_test_y = split_to_xy(d[1])\n",
    "            k_test_X = pd.DataFrame(scaler.fit_transform(k_test_X.to_numpy()), columns=k_train_X.columns)\n",
    "            la = Lasso(alpha=trial.suggest_float(name='alpha', low=0.00001, high=0.01, log=True), fit_intercept=trial.suggest_categorical(name='fit_intercept', choices=[True, False]), random_state=lasso_seed)\n",
    "            la.fit(df_no_id(k_train_X), binarize_response(df_no_id(k_train_y), False))\n",
    "            f1_scores.append(measure_dict['F1'](list(binarize_response(k_test_y, False)[RESPONSE_COLUMN]), apply_threshold_on_response(list(la.predict(df_no_id(k_test_X))), False)))\n",
    "        return sum(f1_scores) \/ len(f1_scores)\n",
    "\n",
    "    study = optuna.create_study(storage=OPTUNA_DB, study_name=\"lasso_regression\", direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=0, n_startup_trials=100, multivariate=True, group=True), load_if_exists=True)\n",
    "\n",
    "    study.optimize(objective, n_trials=150, show_progress_bar=True, callbacks=[tensorboard_callback_lasso])\n",
    "except Exception as e:\n",
    "    raise e\n",
    "study.best_trial"
   ],
   "execution_count":15,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\u001b[32m[I 2022-11-03 17:38:38,372]\u001b[0m Trial 0 finished with value: 0.942899714536612 and parameters: {'scaler': 1, 'alpha': 0.00018662266976517952, 'fit_intercept': True}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:39,135]\u001b[0m Trial 1 finished with value: 0.8941647597254004 and parameters: {'scaler': 1, 'alpha': 0.0003860866271460546, 'fit_intercept': False}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:39,587]\u001b[0m Trial 2 finished with value: 0.544 and parameters: {'scaler': 3, 'alpha': 0.002160082074140205, 'fit_intercept': False}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:40,159]\u001b[0m Trial 3 finished with value: 0.7872460576835973 and parameters: {'scaler': 0, 'alpha': 0.0008313101133778736, 'fit_intercept': False}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:40,606]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.0002335882519483353, 'fit_intercept': True}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:41,045]\u001b[0m Trial 5 finished with value: 0.544 and parameters: {'scaler': 3, 'alpha': 0.0011103525577197586, 'fit_intercept': False}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:41,523]\u001b[0m Trial 6 finished with value: 0.7918863898214397 and parameters: {'scaler': 0, 'alpha': 4.277083049962067e-05, 'fit_intercept': False}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:41,951]\u001b[0m Trial 7 finished with value: 0.07751179751179751 and parameters: {'scaler': 3, 'alpha': 2.0236454843648904e-05, 'fit_intercept': True}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:42,698]\u001b[0m Trial 8 finished with value: 0.793563569807298 and parameters: {'scaler': 0, 'alpha': 2.9985324349454354e-05, 'fit_intercept': False}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:43,158]\u001b[0m Trial 9 finished with value: 0.07751179751179751 and parameters: {'scaler': 3, 'alpha': 1.955707167338673e-05, 'fit_intercept': True}. Best is trial 0 with value: 0.942899714536612.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:43,646]\u001b[0m Trial 10 finished with value: 0.9479649097393846 and parameters: {'scaler': 2, 'alpha': 0.00165116600355318, 'fit_intercept': False}. Best is trial 10 with value: 0.9479649097393846.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:44,011]\u001b[0m Trial 11 finished with value: 0.43520000000000003 and parameters: {'scaler': 3, 'alpha': 0.00017489966737814584, 'fit_intercept': False}. Best is trial 10 with value: 0.9479649097393846.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:44,478]\u001b[0m Trial 12 finished with value: 0.9272438711420274 and parameters: {'scaler': 0, 'alpha': 0.0005343668232660404, 'fit_intercept': True}. Best is trial 10 with value: 0.9479649097393846.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:45,073]\u001b[0m Trial 13 finished with value: 0.9236353326338094 and parameters: {'scaler': 2, 'alpha': 3.544655931853289e-05, 'fit_intercept': True}. Best is trial 10 with value: 0.9479649097393846.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:45,493]\u001b[0m Trial 14 finished with value: 0.9605457661525151 and parameters: {'scaler': 0, 'alpha': 0.0016053955926854306, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:46,096]\u001b[0m Trial 15 finished with value: 0.8990641326257766 and parameters: {'scaler': 1, 'alpha': 0.007215177748314317, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:46,522]\u001b[0m Trial 16 finished with value: 0.9508767088925122 and parameters: {'scaler': 2, 'alpha': 0.0043985505895242335, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:47,216]\u001b[0m Trial 17 finished with value: 0.544 and parameters: {'scaler': 3, 'alpha': 0.0008550088256963299, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:47,791]\u001b[0m Trial 18 finished with value: 0.9332014628499945 and parameters: {'scaler': 2, 'alpha': 0.0007145724809722474, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:48,410]\u001b[0m Trial 19 finished with value: 0.9332014628499945 and parameters: {'scaler': 2, 'alpha': 0.000911176393359584, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:48,809]\u001b[0m Trial 20 finished with value: 0.9542831032228196 and parameters: {'scaler': 0, 'alpha': 0.0026216938007596387, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:49,268]\u001b[0m Trial 21 finished with value: 0.9480672268907563 and parameters: {'scaler': 2, 'alpha': 0.004021408319922199, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:49,920]\u001b[0m Trial 22 finished with value: 0.8893599549205957 and parameters: {'scaler': 1, 'alpha': 0.00016655201514737645, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:50,329]\u001b[0m Trial 23 finished with value: 0.544 and parameters: {'scaler': 3, 'alpha': 0.003693261231099637, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:50,913]\u001b[0m Trial 24 finished with value: 0.7918863898214397 and parameters: {'scaler': 0, 'alpha': 3.980976140397892e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:51,462]\u001b[0m Trial 25 finished with value: 0.9367654481217101 and parameters: {'scaler': 2, 'alpha': 1.2459964030296777e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:52,024]\u001b[0m Trial 26 finished with value: 0.9400580353571207 and parameters: {'scaler': 2, 'alpha': 0.00040448126366514835, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:52,649]\u001b[0m Trial 27 finished with value: 0.9362574678943654 and parameters: {'scaler': 1, 'alpha': 0.006809530508136841, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:53,275]\u001b[0m Trial 28 finished with value: 0.01111111111111111 and parameters: {'scaler': 3, 'alpha': 8.617626078400925e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:53,662]\u001b[0m Trial 29 finished with value: 0.43520000000000003 and parameters: {'scaler': 3, 'alpha': 0.0002296627356539993, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:54,242]\u001b[0m Trial 30 finished with value: 0.8765768863652408 and parameters: {'scaler': 0, 'alpha': 1.1533284318779022e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:54,777]\u001b[0m Trial 31 finished with value: 0.9480672268907563 and parameters: {'scaler': 2, 'alpha': 0.004149081505976886, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:55,376]\u001b[0m Trial 32 finished with value: 0.9362574678943654 and parameters: {'scaler': 1, 'alpha': 0.00695203214369682, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:55,982]\u001b[0m Trial 33 finished with value: 0.8917856200223172 and parameters: {'scaler': 1, 'alpha': 0.00018795609187004732, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:56,318]\u001b[0m Trial 34 finished with value: 0.9400580353571207 and parameters: {'scaler': 2, 'alpha': 0.00035656385908211557, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:56,745]\u001b[0m Trial 35 finished with value: 0.8910348692715664 and parameters: {'scaler': 1, 'alpha': 0.00029118489461447966, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:57,146]\u001b[0m Trial 36 finished with value: 0.9400580353571207 and parameters: {'scaler': 2, 'alpha': 0.00045350012360576995, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:57,456]\u001b[0m Trial 37 finished with value: 0.7778261844687412 and parameters: {'scaler': 0, 'alpha': 0.006145934824126918, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:57,792]\u001b[0m Trial 38 finished with value: 0.9327756450577038 and parameters: {'scaler': 1, 'alpha': 0.008560229715881117, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:58,075]\u001b[0m Trial 39 finished with value: 0.7858392533039883 and parameters: {'scaler': 0, 'alpha': 0.002498088166138199, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:58,483]\u001b[0m Trial 40 finished with value: 0.8893599549205957 and parameters: {'scaler': 1, 'alpha': 0.00011007800595682069, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:58,819]\u001b[0m Trial 41 finished with value: 0.9236353326338094 and parameters: {'scaler': 2, 'alpha': 2.5745469436710528e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:59,095]\u001b[0m Trial 42 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.008293893742197956, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:59,477]\u001b[0m Trial 43 finished with value: 0.885482821978923 and parameters: {'scaler': 0, 'alpha': 4.973961581768231e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:38:59,874]\u001b[0m Trial 44 finished with value: 0.9367654481217101 and parameters: {'scaler': 2, 'alpha': 1.7320732229632952e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:00,221]\u001b[0m Trial 45 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.0015175142855971301, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:00,550]\u001b[0m Trial 46 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.0011216155111322078, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:00,913]\u001b[0m Trial 47 finished with value: 0.9332014628499945 and parameters: {'scaler': 2, 'alpha': 0.001233081338503634, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:01,240]\u001b[0m Trial 48 finished with value: 0.9339497131320622 and parameters: {'scaler': 2, 'alpha': 0.00012958609344773653, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:01,621]\u001b[0m Trial 49 finished with value: 0.8891786320481974 and parameters: {'scaler': 1, 'alpha': 8.325882904005886e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:01,949]\u001b[0m Trial 50 finished with value: 0.9240778829014124 and parameters: {'scaler': 0, 'alpha': 0.0004060060303227929, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:02,356]\u001b[0m Trial 51 finished with value: 0.943226464729835 and parameters: {'scaler': 2, 'alpha': 0.005151715421583567, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:02,663]\u001b[0m Trial 52 finished with value: 0.7706514463418463 and parameters: {'scaler': 0, 'alpha': 0.005153866664021134, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:03,060]\u001b[0m Trial 53 finished with value: 0.8891786320481974 and parameters: {'scaler': 1, 'alpha': 3.031213088088607e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:03,345]\u001b[0m Trial 54 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.00717172173566196, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:03,682]\u001b[0m Trial 55 finished with value: 0.7914580824072092 and parameters: {'scaler': 0, 'alpha': 0.00015678437383746812, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:03,946]\u001b[0m Trial 56 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.00011644116593520669, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:04,238]\u001b[0m Trial 57 finished with value: 0.9363716260201576 and parameters: {'scaler': 2, 'alpha': 0.006853376647997157, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:04,541]\u001b[0m Trial 58 finished with value: 0.9236353326338094 and parameters: {'scaler': 2, 'alpha': 1.1138281593286968e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:04,943]\u001b[0m Trial 59 finished with value: 0.9367654481217101 and parameters: {'scaler': 2, 'alpha': 1.0866975018682312e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:05,314]\u001b[0m Trial 60 finished with value: 0.8919833435198754 and parameters: {'scaler': 1, 'alpha': 0.0008246796389157785, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:05,699]\u001b[0m Trial 61 finished with value: 0.8919833435198754 and parameters: {'scaler': 1, 'alpha': 0.0009716586351288181, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:06,003]\u001b[0m Trial 62 finished with value: 0.9332014628499945 and parameters: {'scaler': 2, 'alpha': 0.0013174195952058627, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:06,384]\u001b[0m Trial 63 finished with value: 0.8893599549205957 and parameters: {'scaler': 1, 'alpha': 0.0001110601123506145, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:06,721]\u001b[0m Trial 64 finished with value: 0.7805359288632541 and parameters: {'scaler': 3, 'alpha': 5.600929719451107e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:07,052]\u001b[0m Trial 65 finished with value: 0.544 and parameters: {'scaler': 3, 'alpha': 0.004417338058012675, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:07,436]\u001b[0m Trial 66 finished with value: 0.8941551128027688 and parameters: {'scaler': 1, 'alpha': 0.00022277935696925097, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:07,764]\u001b[0m Trial 67 finished with value: 0.9433352716934806 and parameters: {'scaler': 2, 'alpha': 0.00399823407744763, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:08,103]\u001b[0m Trial 68 finished with value: 0.9236353326338094 and parameters: {'scaler': 2, 'alpha': 1.631583612146676e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:08,423]\u001b[0m Trial 69 finished with value: 0.9467082875664966 and parameters: {'scaler': 2, 'alpha': 0.004854646962997275, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:08,768]\u001b[0m Trial 70 finished with value: 0.9400580353571207 and parameters: {'scaler': 2, 'alpha': 0.00045314253519627415, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:09,100]\u001b[0m Trial 71 finished with value: 0.9370138953266792 and parameters: {'scaler': 2, 'alpha': 0.0001315541617453691, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:09,503]\u001b[0m Trial 72 finished with value: 0.942899714536612 and parameters: {'scaler': 1, 'alpha': 5.766702841505698e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:09,915]\u001b[0m Trial 73 finished with value: 0.8943693084321561 and parameters: {'scaler': 1, 'alpha': 0.001353895697671433, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:10,326]\u001b[0m Trial 74 finished with value: 0.942899714536612 and parameters: {'scaler': 1, 'alpha': 1.2322697118433829e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:10,665]\u001b[0m Trial 75 finished with value: 0.9370138953266792 and parameters: {'scaler': 2, 'alpha': 0.0001651303745248137, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:11,037]\u001b[0m Trial 76 finished with value: 0.9272438711420274 and parameters: {'scaler': 0, 'alpha': 0.0005387914955414468, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:11,375]\u001b[0m Trial 77 finished with value: 0.9272438711420274 and parameters: {'scaler': 0, 'alpha': 0.0005837391614562227, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:11,725]\u001b[0m Trial 78 finished with value: 0.8950617431010522 and parameters: {'scaler': 1, 'alpha': 0.0023578734360063707, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:12,095]\u001b[0m Trial 79 finished with value: 0.8893599549205957 and parameters: {'scaler': 1, 'alpha': 0.0001701784987160966, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:12,435]\u001b[0m Trial 80 finished with value: 0.9332014628499945 and parameters: {'scaler': 2, 'alpha': 0.00032222726375416967, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:12,760]\u001b[0m Trial 81 finished with value: 0.9367654481217101 and parameters: {'scaler': 2, 'alpha': 1.2826301733037316e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:13,081]\u001b[0m Trial 82 finished with value: 0.911838592992685 and parameters: {'scaler': 0, 'alpha': 0.00021836510884148965, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:13,381]\u001b[0m Trial 83 finished with value: 0.7805359288632541 and parameters: {'scaler': 3, 'alpha': 5.5232699082602105e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:13,792]\u001b[0m Trial 84 finished with value: 0.9430034996403972 and parameters: {'scaler': 1, 'alpha': 0.0010417102414324272, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:14,098]\u001b[0m Trial 85 finished with value: 0.7855266254322251 and parameters: {'scaler': 0, 'alpha': 0.008681220514302247, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:14,416]\u001b[0m Trial 86 finished with value: 0.7844488700955616 and parameters: {'scaler': 0, 'alpha': 7.112133994881229e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:14,748]\u001b[0m Trial 87 finished with value: 0.815699446855531 and parameters: {'scaler': 3, 'alpha': 2.5137280725547114e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:15,041]\u001b[0m Trial 88 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.00011367867123572806, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:15,406]\u001b[0m Trial 89 finished with value: 0.9430034996403972 and parameters: {'scaler': 1, 'alpha': 0.001243785339434205, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:15,687]\u001b[0m Trial 90 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.0020856943379751404, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:15,992]\u001b[0m Trial 91 finished with value: 0.0 and parameters: {'scaler': 3, 'alpha': 0.006419426646854943, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:16,310]\u001b[0m Trial 92 finished with value: 0.9480672268907563 and parameters: {'scaler': 2, 'alpha': 0.003856450733234924, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:16,700]\u001b[0m Trial 93 finished with value: 0.07751179751179751 and parameters: {'scaler': 3, 'alpha': 1.4983206557219537e-05, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:17,114]\u001b[0m Trial 94 finished with value: 0.8867926671359166 and parameters: {'scaler': 1, 'alpha': 2.2487785627033985e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:17,418]\u001b[0m Trial 95 finished with value: 0.544 and parameters: {'scaler': 3, 'alpha': 0.0008271050979926381, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:17,759]\u001b[0m Trial 96 finished with value: 0.936683285686656 and parameters: {'scaler': 2, 'alpha': 0.0015101754059226088, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:18,253]\u001b[0m Trial 97 finished with value: 0.8943693084321561 and parameters: {'scaler': 1, 'alpha': 0.001628406127050562, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:18,562]\u001b[0m Trial 98 finished with value: 0.9480672268907563 and parameters: {'scaler': 2, 'alpha': 0.003994859202152063, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:18,931]\u001b[0m Trial 99 finished with value: 0.8867926671359166 and parameters: {'scaler': 1, 'alpha': 1.1412182084972839e-05, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:19,205]\u001b[0m Trial 100 finished with value: 0.9591521384673273 and parameters: {'scaler': 2, 'alpha': 0.006288805718854589, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:19,472]\u001b[0m Trial 101 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008780718126510918, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:19,765]\u001b[0m Trial 102 finished with value: 0.9591521384673273 and parameters: {'scaler': 2, 'alpha': 0.006517512455981493, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:20,042]\u001b[0m Trial 103 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.006790855583983991, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:20,293]\u001b[0m Trial 104 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009842620041561645, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:20,551]\u001b[0m Trial 105 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008762548434723112, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:20,872]\u001b[0m Trial 106 finished with value: 0.9506944622966034 and parameters: {'scaler': 0, 'alpha': 0.007396199511635193, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:21,190]\u001b[0m Trial 107 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.007694707869771991, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:21,458]\u001b[0m Trial 108 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009325576395274197, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:21,718]\u001b[0m Trial 109 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008625258375620785, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:21,989]\u001b[0m Trial 110 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.009004046870049529, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:22,256]\u001b[0m Trial 111 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.0094805980087466, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:22,553]\u001b[0m Trial 112 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009293892912959033, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:22,819]\u001b[0m Trial 113 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009777136125844254, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:23,074]\u001b[0m Trial 114 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008514584437804553, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:23,396]\u001b[0m Trial 115 finished with value: 0.8990393472770475 and parameters: {'scaler': 1, 'alpha': 0.009566905533868774, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:23,667]\u001b[0m Trial 116 finished with value: 0.95112557699136 and parameters: {'scaler': 2, 'alpha': 0.0025751879659951043, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:23,941]\u001b[0m Trial 117 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008253783362644464, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:24,207]\u001b[0m Trial 118 finished with value: 0.9542831032228196 and parameters: {'scaler': 0, 'alpha': 0.0031098903268592373, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:24,459]\u001b[0m Trial 119 finished with value: 0.9542831032228196 and parameters: {'scaler': 0, 'alpha': 0.0025954053794775738, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:24,718]\u001b[0m Trial 120 finished with value: 0.9571816539474574 and parameters: {'scaler': 0, 'alpha': 0.003272369754830054, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:25,001]\u001b[0m Trial 121 finished with value: 0.9542831032228196 and parameters: {'scaler': 0, 'alpha': 0.002149171759086955, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:25,253]\u001b[0m Trial 122 finished with value: 0.9576484878382041 and parameters: {'scaler': 0, 'alpha': 0.0018389203678751262, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:25,518]\u001b[0m Trial 123 finished with value: 0.9542831032228196 and parameters: {'scaler': 0, 'alpha': 0.0031090804482069643, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:25,767]\u001b[0m Trial 124 finished with value: 0.544 and parameters: {'scaler': 3, 'alpha': 0.008264376470263424, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:26,042]\u001b[0m Trial 125 finished with value: 0.9479649097393846 and parameters: {'scaler': 2, 'alpha': 0.0022542857916186924, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:26,304]\u001b[0m Trial 126 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009551501952192032, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:26,593]\u001b[0m Trial 127 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.007523421239780643, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:26,948]\u001b[0m Trial 128 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009350058925284344, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:27,256]\u001b[0m Trial 129 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008864888232805283, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:27,527]\u001b[0m Trial 130 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009585398538539689, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:27,789]\u001b[0m Trial 131 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009562014872285479, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:28,086]\u001b[0m Trial 132 finished with value: 0.9479649097393846 and parameters: {'scaler': 2, 'alpha': 0.002164126154369372, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:28,380]\u001b[0m Trial 133 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008445224953293888, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:28,681]\u001b[0m Trial 134 finished with value: 0.95112557699136 and parameters: {'scaler': 2, 'alpha': 0.0025338243608579846, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:28,975]\u001b[0m Trial 135 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008412089592587046, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:29,253]\u001b[0m Trial 136 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009650957995805353, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:29,544]\u001b[0m Trial 137 finished with value: 0.9548458412603162 and parameters: {'scaler': 0, 'alpha': 0.0013206978051089606, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:29,836]\u001b[0m Trial 138 finished with value: 0.9480672268907563 and parameters: {'scaler': 2, 'alpha': 0.0029813682299923133, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:30,096]\u001b[0m Trial 139 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009474592217684845, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:30,391]\u001b[0m Trial 140 finished with value: 0.9480672268907563 and parameters: {'scaler': 2, 'alpha': 0.0031712303590663857, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:30,676]\u001b[0m Trial 141 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009919333029056001, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:31,015]\u001b[0m Trial 142 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009430024302665862, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:31,307]\u001b[0m Trial 143 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008376596449975795, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:31,594]\u001b[0m Trial 144 finished with value: 0.9480672268907563 and parameters: {'scaler': 2, 'alpha': 0.0029664889997466134, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:31,876]\u001b[0m Trial 145 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008904985919242818, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:32,142]\u001b[0m Trial 146 finished with value: 0.9564240907264917 and parameters: {'scaler': 2, 'alpha': 0.009542539100701207, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:32,422]\u001b[0m Trial 147 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.008407216176758749, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:32,701]\u001b[0m Trial 148 finished with value: 0.9536876722154254 and parameters: {'scaler': 2, 'alpha': 0.009025579457557645, 'fit_intercept': False}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:32,978]\u001b[0m Trial 149 finished with value: 0.9576553232620721 and parameters: {'scaler': 0, 'alpha': 0.001384511809271177, 'fit_intercept': True}. Best is trial 14 with value: 0.9605457661525151.\u001b[0m\n"
     ],
     "output_type":"stream"
    },
    {
     "name":"stderr",
     "text":[
      "<ipython-input-15-1ea8510a438e>:5: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  tensorboard_callback_lasso = TensorBoardCallback(TENSORBOARD_LOGDIR_LASSO + '\/', metric_name=\"F1\")\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/optuna\/samplers\/_tpe\/sampler.py:281: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/optuna\/samplers\/_tpe\/sampler.py:292: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-03 17:38:37,637]\u001b[0m A new study created in RDB with name: lasso_regression\u001b[0m\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/optuna\/progress_bar.py:49: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.792e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.796e+00, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.330e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.749e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.631e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.699e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.505e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.660e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.630e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.533e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.528e-02, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.635e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.877e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.706e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.051e-02, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.127e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.382e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.173e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.552e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e-02, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.481e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.338e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.037e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.535e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.710e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.678e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.573e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.573e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.782e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.635e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.678e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.156e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.292e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.305e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.853e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.950e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.673e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.101e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.862e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.814e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.591e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.200e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.607e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.244e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.364e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.463e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.955e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.366e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.910e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.025e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.807e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.241e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.505e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.324e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.402e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.660e+00, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+00, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.280e+00, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.515e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.436e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.704e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.532e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.602e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.407e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.218e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.278e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.237e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.890e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.173e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.224e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.765e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.807e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.579e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.954e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.033e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.916e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.458e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.403e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.685e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.558e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.577e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.591e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.531e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.808e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.668e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.703e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.350e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.636e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.425e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.724e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.096e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.015e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.946e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.794e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.423e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.412e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.347e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.474e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.516e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.383e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.475e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.946e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.349e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.199e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.299e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.543e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.990e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.738e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.777e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.446e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.902e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.677e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.431e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.375e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.510e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.550e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.553e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e-01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.232e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.446e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.007e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.051e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e+01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+00, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.275e+00, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.044e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+00, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.568e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.502e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.776e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.627e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.672e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.155e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.217e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.440e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.175e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.182e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.669e-02, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.170e-02, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.187e-02, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e-01, tolerance: 3.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.480e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.836e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.893e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.713e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.076e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.355e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.702e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e+00, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.001e-02, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.870e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.934e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.015e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.252e+01, tolerance: 3.640e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"22d82dea14c545889bbe7680f44fcc7f"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"rDeSFda0g9vXkUgf6qlsI8"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "FrozenTrial(number=14, values=[0.9605457661525151], datetime_start=datetime.datetime(2022, 11, 3, 17, 38, 45, 102716), datetime_complete=datetime.datetime(2022, 11, 3, 17, 38, 45, 429614), params={'alpha': 0.0016053955926854306, 'fit_intercept': True, 'scaler': 0}, distributions={'alpha': FloatDistribution(high=0.01, log=True, low=1e-05, step=None), 'fit_intercept': CategoricalDistribution(choices=(True, False)), 'scaler': CategoricalDistribution(choices=(0, 1, 2, 3))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=15, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"08QcrmzWfi1eYcNPAeeaNg",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Let us check out the result of the parameter search:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ARfFqRfrWcVQcECVUjmiqJ",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "study.best_params"
   ],
   "execution_count":16,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "{'alpha': 0.0016053955926854306, 'fit_intercept': True, 'scaler': 0}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"pZhvLZ9CLuVUnvfrLV6Cup",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "In order to evaluate the real performance the test split is given to the model:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"8PhzpUL82scyaD9hdsyL7h",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "scaler = scalers[study.best_params['scaler']]\n",
    "\n",
    "lasso = Lasso(alpha=study.best_params['alpha'], fit_intercept=study.best_params['fit_intercept'])\n",
    "lasso.fit(df_no_id(all_X_train), binarize_response(df_no_id(all_y_train), False))\n",
    "result_dict['F1']['Lasso'] = measure_dict['F1'](list(binarize_response(all_y_test, False)[RESPONSE_COLUMN]), apply_threshold_on_response(list(lasso.predict(df_no_id(all_X_test))), False))\n",
    "result_dict['F1']['Lasso']"
   ],
   "execution_count":17,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.391e+01, tolerance: 4.259e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/plain":[
       "0.9382716049382716"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"oG7IlH8gweOUyCNL2QAFb1",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "This is surprisingly good. We use this as the baseline now. It is important to use something simple as baseline, as it is otherwise very hard to determine whether the neural network that we will build in the next chapter is performing below expectations and has therefore likely a bug in the code."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"lwO8GKpleyknZxMbUdWsBX",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## The shallow neural network\n",
    "\n",
    "For our next trick we are going to use a shallow neural network.\n",
    "\n",
    "However before we get started, the pytorch class \"Dataset\" will have to be adapted for our use case."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"RhPnlB9A0wcViKsUWXR82s",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CancerDataset(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        super().__init__()\n",
    "        self.__ids = X['id']\n",
    "        self.__X = df_no_id(X.copy())\n",
    "        self.__y = df_no_id(binarize_response(y.copy(), True))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return np.array(self.__X.iloc[index].values), np.array(self.__y.iloc[index].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__X)"
   ],
   "execution_count":18,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"ZWpcC2NiXefu7vnb1rB5VM",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "This code might seem a bit messy - it would seem way cleaner to have the trial object suggest parameters outside of the neural network class and instantiate the network with these parameters passed in the constructor. However consider following situation:\n",
    "\n",
    "```\n",
    "if trial.suggest_float('test_1', 0, 1) > 0.5:\n",
    "    # code that may or may not be executed\n",
    "    do_something(trial.suggest_int('test_2', 0, 100)\n",
    "```\n",
    "\n",
    "By generating the values right where they are needed, the risk is eliminated of having optuna mistakenly assume effects of parameters that are not even used. The code below might also look more complicated than it needs to be for now. However essentially what happens here is that we let optuna decide how deep the network is and how many neurons there are per layer. Of course the first input size is the number of values that go into the network and the last input size is the number of values that should be predicted. Lastly dropout are added as regularizers. They can help e.g. to make neural networks less dependent on single columns in the dataset."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"TqZwfWeXnUa3LDtXfAfz9z",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int, trial: optuna.Trial):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        temp = []\n",
    "        last_input = input_size\n",
    "        for i in range(n_layers := trial.suggest_int('n_layers', 1, 10)):\n",
    "            is_final_layer = i == n_layers - 1\n",
    "            if is_final_layer:\n",
    "                linear_out = 2\n",
    "            else:\n",
    "                linear_out = trial.suggest_int(f'linear_{i}_out', 2 , 2500, log=True)\n",
    "\n",
    "            temp.append(nn.Linear(last_input, linear_out))\n",
    "            last_input = linear_out\n",
    "\n",
    "            if not is_final_layer:\n",
    "                temp.append(nn.Dropout(p=trial.suggest_float(f'dropout_{i}', 0, 0.5)))\n",
    "                temp.append(nn.LeakyReLU())\n",
    "\n",
    "        self.linear_leaky_relu_stack = nn.Sequential(\n",
    "            *temp\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_leaky_relu_stack(x)\n",
    "        return nn.functional.softmax(logits, 1) # 1 is the dimension\n",
    "    "
   ],
   "execution_count":19,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"d7mA6uK5fRRQIfdZhFmmDa",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "In the next cell loops for training and testing are created. Note that using tensors in python wrappers such as lists and tuples may cause problems with memory. Also make sure to detach tensors before you collect them, so that the memory can be freed again."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"QgfxkCwobm56QG2dQapBwQ",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# from memory_profiler import profile\n",
    "\n",
    "# @profile # comment this line in if you are having trouble with memory usage\n",
    "def train_loop(dataloader, model, loss_fn, optim, print_progress = False):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(iter(dataloader)):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.type(torch.float).to(DEVICE))\n",
    "        y = torch.tensor(np.stack(np.array(tuple(expand_classes(cur_y.item()) for cur_y in y))), dtype=torch.float).to(DEVICE)\n",
    "        optim.zero_grad()\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if print_progress and batch % 100 == 0:\n",
    "            loss, current = loss.detach().item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}\/{size:>5d}]\")\n",
    "\n",
    "        possible_emergency_brake()\n",
    "        cpu_cooldown()\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, report = False):\n",
    "    model.eval()\n",
    "    f1_scores_test = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.type(torch.float).to(DEVICE))\n",
    "            cur_score = f1_score([torch.argmax(t.detach()).detach().item() for t in pred], [t.detach().item() for t in y])\n",
    "            f1_scores_test.append(cur_score)\n",
    "\n",
    "    result = sum(f1_scores_test) \/ len(f1_scores_test)\n",
    "    if report:\n",
    "        print(f\"Test f1-score: = {result}\")\n",
    "    return result"
   ],
   "execution_count":20,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"vRkP5R9ZrA1nFSOpMB3aoS",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Now let us find the optimal parameters. Note that numpy arrays are used to store tensors instead of lists or tuples. This is preferable for reasons regarding memory management. If you are interested (or having problems with memory), you may read up on that.\n",
    "\n",
    "This code below allows that the inputs are either boundaries for a selection (e.g. batch size from 1 to 100 or a list of scalers to choose from) or concrete values. This means that we can reuse this method later when we have fixed some of the choices and are still testing for some others. We can also leverage this method for the final testing by fixing all of the values! The bit of additional complexity therefore really pays off."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"SAPyjxfbDcptwnNu86Glxh",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def test_params(trial: Optional[optuna.Trial], datasets: Union[Tuple[pd.DataFrame, pd.DataFrame], List[Tuple[pd.DataFrame, pd.DataFrame]], CancerDataset], model_type: type, scalers: Union[List[object], object], batch_size: Union[Tuple[int, int], int], loss_functions: Union[List[Callable], Callable], learning_rate: Union[Tuple[float, float], float], prune: bool) -> (float, int):\n",
    "    nn_f1_scores = []\n",
    "    best_epochs = []\n",
    "\n",
    "    if isinstance(datasets, tuple):\n",
    "        datasets = [datasets]\n",
    "    for cur_seed, d in enumerate(datasets):\n",
    "        torch.manual_seed(cur_seed)\n",
    "        \n",
    "        k_train_X, k_train_y = split_to_xy(d[0])\n",
    "        if isinstance(scalers, list):\n",
    "            scaler = scalers[trial.suggest_categorical(name='scaler', choices=list(range(len(scalers))))]\n",
    "        else:\n",
    "            scaler = scalers\n",
    "        \n",
    "        k_train_X = pd.DataFrame(scaler.fit_transform(k_train_X.to_numpy()), columns=k_train_X.columns)\n",
    "        k_test_X, k_test_y = split_to_xy(d[1])\n",
    "        k_test_X = pd.DataFrame(scaler.fit_transform(k_test_X.to_numpy()), columns=k_train_X.columns)\n",
    "\n",
    "        if isinstance(batch_size, tuple):\n",
    "            assert len(batch_size) == 2\n",
    "            assert batch_size[0] < batch_size[1]\n",
    "            batch_size = trial.suggest_int('batch_size', batch_size[0], batch_size[1])\n",
    "        \n",
    "\n",
    "        if isinstance(loss_functions, list):\n",
    "            loss_fn = loss_functions[trial.suggest_categorical('loss_fn', list(range(len(loss_functions))))]\n",
    "        else:\n",
    "            loss_fn = loss_functions\n",
    "\n",
    "        if isinstance(learning_rate, tuple):\n",
    "            assert learning_rate[0] < learning_rate[1]\n",
    "            cur_learning_rate = trial.suggest_float('lr', 1e-6, 1e-3, log=True)\n",
    "        else:\n",
    "            cur_learning_rate = learning_rate\n",
    "\n",
    "        if trial is None:\n",
    "            model = model_type(all_X_train.shape[1] - 1).to(DEVICE)\n",
    "        else:\n",
    "            model = model_type(all_X_train.shape[1] - 1, trial).to(DEVICE)\n",
    "\n",
    "        opt = torch.optim.Adam(lr=cur_learning_rate, params=[p for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "        cur_train_dataset = CancerDataset(k_train_X, k_train_y)\n",
    "        tr_loader = DataLoader(cur_train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "        cur_test_dataset = CancerDataset(k_test_X, k_test_y)\n",
    "\n",
    "        best_result: float = - np.inf\n",
    "        best_epoch: int = -1\n",
    "\n",
    "        for ep in range(TRAIN_FOR_EPOCHS):\n",
    "            train_loop(tr_loader, model, loss_fn, opt)\n",
    "            te_loader = DataLoader(cur_test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "            result = test_loop(te_loader, model)\n",
    "\n",
    "            if result > best_result:\n",
    "                best_result = result\n",
    "                best_epoch = ep\n",
    "            \n",
    "            if trial is not None and prune:\n",
    "                trial.report(result, ep)\n",
    "\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            nn_f1_scores.append(best_result)\n",
    "            best_epochs.append(best_epoch)\n",
    "        return sum(nn_f1_scores) \/ len(nn_f1_scores), best_epochs\n",
    "    \n",
    "\n",
    "def run_study(name: str, datasets: Union[Tuple[pd.DataFrame, pd.DataFrame], List[Tuple[pd.DataFrame, pd.DataFrame]], CancerDataset], model_type: Callable, scalers: Union[List[object], object], batch_size: Union[Tuple[int, int], int], loss_functions: Union[List[Callable], Callable], learning_rate: Union[Tuple[float, float], float], n_startup_trials: int, n_trials: int, prune: bool, tensorboard_cb: optuna.integration.TensorBoardCallback) -> optuna.Trial:\n",
    "    try:\n",
    "      study = optuna.load_study(storage=OPTUNA_DB, study_name=name)\n",
    "    except KeyError:\n",
    "        def objective(trial):\n",
    "            return test_params(trial, datasets, model_type, scalers, batch_size, loss_functions, learning_rate, prune)[0]\n",
    "\n",
    "        if prune:\n",
    "            pruner = optuna.pruners.SuccessiveHalvingPruner()\n",
    "        else:\n",
    "            pruner = None\n",
    "        study = optuna.create_study(storage=OPTUNA_DB, study_name=name, direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=0, n_startup_trials=n_startup_trials, multivariate=True, group=True), load_if_exists=True,  pruner=pruner)\n",
    "\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True, callbacks=[tensorboard_cb])\n",
    "    return study"
   ],
   "execution_count":34,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"CM1b974kRfuFjsibOW2ZZd",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Note that pruning is NOT used here. The reason for this is that runs are not comparable in their first epochs. A deeper network might need more epochs of training in order to get to a good result."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Yqy8XvuqEhdFDgwRH1nWTU",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "tensorboard_callback_nn = TensorBoardCallback(TENSORBOARD_LOGDIR_NN_SHALLOW + '\/', metric_name=\"F1\")\n",
    "loss_functions = [nn.BCELoss(), nn.HingeEmbeddingLoss(), nn.KLDivLoss(reduction='batchmean')]\n",
    "study = run_study('nn_shallow', datasets_tvt, NeuralNetwork, scalers, (1, 100), loss_functions, (1e-6, 1e-3), 250, 500, False, tensorboard_callback_nn)"
   ],
   "execution_count":22,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\u001b[32m[I 2022-11-03 17:39:37,971]\u001b[0m Trial 0 finished with value: 0.13837024171370674 and parameters: {'scaler': 1, 'batch_size': 43, 'loss_fn': 2, 'lr': 0.0007780155576901416, 'n_layers': 4, 'linear_0_out': 533, 'dropout_0': 0.26444745987645224, 'linear_1_out': 101, 'dropout_1': 0.4627983191463305, 'linear_2_out': 3, 'dropout_2': 0.043564649850770354}. Best is trial 0 with value: 0.13837024171370674.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:39,757]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 98, 'loss_fn': 0, 'lr': 2.263722969739549e-06, 'n_layers': 7, 'linear_0_out': 4, 'dropout_0': 0.47233445852479194, 'linear_1_out': 72, 'dropout_1': 0.2073309699952618, 'linear_2_out': 11, 'dropout_2': 0.38711684471710833, 'linear_3_out': 44, 'dropout_3': 0.28421697443432425, 'linear_4_out': 2, 'dropout_4': 0.30881774853793853, 'linear_5_out': 141, 'dropout_5': 0.30846699843737846}. Best is trial 0 with value: 0.13837024171370674.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:41,205]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 70, 'loss_fn': 2, 'lr': 4.27708304996207e-06, 'n_layers': 2, 'linear_0_out': 16, 'dropout_0': 0.1818553854713113}. Best is trial 0 with value: 0.13837024171370674.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:43,019]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 21, 'loss_fn': 1, 'lr': 2.5057187257477673e-05, 'n_layers': 3, 'linear_0_out': 5, 'dropout_0': 0.05518757058215257, 'linear_1_out': 195, 'dropout_1': 0.0690914756743069}. Best is trial 0 with value: 0.13837024171370674.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:45,003]\u001b[0m Trial 4 finished with value: 0.6349358974358975 and parameters: {'scaler': 2, 'batch_size': 84, 'loss_fn': 1, 'lr': 0.0008516933662231994, 'n_layers': 7, 'linear_0_out': 361, 'dropout_0': 0.019593896127160337, 'linear_1_out': 12, 'dropout_1': 0.06009828060658445, 'linear_2_out': 13, 'dropout_2': 0.05936385947712203, 'linear_3_out': 16, 'dropout_3': 0.20713149725733498, 'linear_4_out': 2, 'dropout_4': 0.3462360596850099, 'linear_5_out': 100, 'dropout_5': 0.1326947454697227}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:46,597]\u001b[0m Trial 5 finished with value: 0.5272775776977456 and parameters: {'scaler': 3, 'batch_size': 32, 'loss_fn': 2, 'lr': 7.382751981499337e-06, 'n_layers': 2, 'linear_0_out': 116, 'dropout_0': 0.010053773093746776}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:48,925]\u001b[0m Trial 6 finished with value: 0.5088261253309796 and parameters: {'scaler': 0, 'batch_size': 74, 'loss_fn': 0, 'lr': 5.9720824347773275e-05, 'n_layers': 6, 'linear_0_out': 8, 'dropout_0': 0.4763745057584925, 'linear_1_out': 41, 'dropout_1': 0.4232043362355639, 'linear_2_out': 269, 'dropout_2': 0.14871847542756683, 'linear_3_out': 628, 'dropout_3': 0.19825287042349232, 'linear_4_out': 1035, 'dropout_4': 0.29063643631792935}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:50,528]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 96, 'loss_fn': 0, 'lr': 1.1417725427734158e-06, 'n_layers': 4, 'linear_0_out': 201, 'dropout_0': 0.14503880360522203, 'linear_1_out': 147, 'dropout_1': 0.21438435047288307, 'linear_2_out': 4, 'dropout_2': 0.14914116297801538}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:52,797]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 66, 'loss_fn': 1, 'lr': 2.0304615777978837e-05, 'n_layers': 9, 'linear_0_out': 594, 'dropout_0': 0.35194429177018316, 'linear_1_out': 3, 'dropout_1': 0.4597413068723368, 'linear_2_out': 300, 'dropout_2': 0.49942350328393326, 'linear_3_out': 5, 'dropout_3': 0.4340630286841071, 'linear_4_out': 5, 'dropout_4': 0.3077797821419221, 'linear_5_out': 4, 'dropout_5': 0.4240041146611172, 'linear_6_out': 599, 'dropout_6': 0.28455036930729666, 'linear_7_out': 31, 'dropout_7': 0.034583497727569024}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:54,580]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 98, 'loss_fn': 0, 'lr': 0.00015487156510304194, 'n_layers': 2, 'linear_0_out': 72, 'dropout_0': 0.027168994169626814}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:56,962]\u001b[0m Trial 10 finished with value: 0.5255171559519385 and parameters: {'scaler': 2, 'batch_size': 35, 'loss_fn': 0, 'lr': 3.1194818957137977e-06, 'n_layers': 7, 'linear_0_out': 109, 'dropout_0': 0.11894641068725431, 'linear_1_out': 1535, 'dropout_1': 0.306982977982948, 'linear_2_out': 80, 'dropout_2': 0.2949549881772855, 'linear_3_out': 338, 'dropout_3': 0.15597249773980093, 'linear_4_out': 29, 'dropout_4': 0.10492187448756107, 'linear_5_out': 6, 'dropout_5': 0.4721861949919668}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:39:59,141]\u001b[0m Trial 11 finished with value: 0.47619047619047616 and parameters: {'scaler': 0, 'batch_size': 6, 'loss_fn': 2, 'lr': 1.3591128476936901e-05, 'n_layers': 2, 'linear_0_out': 2, 'dropout_0': 0.03362481573162429}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:01,621]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 100, 'loss_fn': 1, 'lr': 1.1533284318779028e-06, 'n_layers': 8, 'linear_0_out': 16, 'dropout_0': 0.19173194708594898, 'linear_1_out': 118, 'dropout_1': 0.4155242276180952, 'linear_2_out': 159, 'dropout_2': 0.43632532772369764, 'linear_3_out': 11, 'dropout_3': 0.39902341695628185, 'linear_4_out': 6, 'dropout_4': 0.4763958284859723, 'linear_5_out': 246, 'dropout_5': 0.10775383855677922, 'linear_6_out': 1692, 'dropout_6': 0.3654279033850789}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:05,538]\u001b[0m Trial 13 finished with value: 0.49784482758620696 and parameters: {'scaler': 2, 'batch_size': 21, 'loss_fn': 2, 'lr': 6.805908701019703e-06, 'n_layers': 6, 'linear_0_out': 911, 'dropout_0': 0.05876592798101654, 'linear_1_out': 70, 'dropout_1': 0.06603405317257666, 'linear_2_out': 306, 'dropout_2': 0.19802985140364687, 'linear_3_out': 100, 'dropout_3': 0.09163991810703931, 'linear_4_out': 4, 'dropout_4': 0.24402814032447728}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:07,410]\u001b[0m Trial 14 finished with value: 0.26107327087061794 and parameters: {'scaler': 1, 'batch_size': 91, 'loss_fn': 2, 'lr': 0.0007687924960093078, 'n_layers': 3, 'linear_0_out': 9, 'dropout_0': 0.05014697113274891, 'linear_1_out': 2, 'dropout_1': 0.46476465839609526}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:12,841]\u001b[0m Trial 15 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 7, 'loss_fn': 1, 'lr': 1.0338960009667776e-05, 'n_layers': 10, 'linear_0_out': 8, 'dropout_0': 0.4746594112078407, 'linear_1_out': 1619, 'dropout_1': 0.39960129367619585, 'linear_2_out': 161, 'dropout_2': 0.4371439833124735, 'linear_3_out': 13, 'dropout_3': 0.4244717776564591, 'linear_4_out': 147, 'dropout_4': 0.006618428879449745, 'linear_5_out': 20, 'dropout_5': 0.07407043047408252, 'linear_6_out': 2185, 'dropout_6': 0.23918515351999403, 'linear_7_out': 60, 'dropout_7': 0.3197362581993618, 'linear_8_out': 23, 'dropout_8': 0.06845013584279946}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:16,454]\u001b[0m Trial 16 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 10, 'loss_fn': 1, 'lr': 0.0005244046061116682, 'n_layers': 8, 'linear_0_out': 18, 'dropout_0': 0.04055069499399838, 'linear_1_out': 31, 'dropout_1': 0.11611707108547137, 'linear_2_out': 4, 'dropout_2': 0.02671359089341263, 'linear_3_out': 327, 'dropout_3': 0.005713729312515514, 'linear_4_out': 456, 'dropout_4': 0.07347332270018753, 'linear_5_out': 3, 'dropout_5': 0.04480151711930269, 'linear_6_out': 219, 'dropout_6': 0.12268360492642238}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:18,979]\u001b[0m Trial 17 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 28, 'loss_fn': 2, 'lr': 6.114408463441423e-06, 'n_layers': 5, 'linear_0_out': 239, 'dropout_0': 0.3478127228194286, 'linear_1_out': 12, 'dropout_1': 0.18996347795006024, 'linear_2_out': 6, 'dropout_2': 0.39427275615325935, 'linear_3_out': 2, 'dropout_3': 0.34849862086249367}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:20,524]\u001b[0m Trial 18 finished with value: 0.1160391363022942 and parameters: {'scaler': 0, 'batch_size': 59, 'loss_fn': 1, 'lr': 2.3964460217819023e-05, 'n_layers': 1}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:22,758]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 58, 'loss_fn': 0, 'lr': 1.9552726186680726e-05, 'n_layers': 6, 'linear_0_out': 80, 'dropout_0': 0.34069625530191894, 'linear_1_out': 12, 'dropout_1': 0.0644302827331601, 'linear_2_out': 28, 'dropout_2': 0.4782028613979744, 'linear_3_out': 6, 'dropout_3': 0.4519919774641185, 'linear_4_out': 85, 'dropout_4': 0.2284557108228829}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:26,255]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 91, 'loss_fn': 1, 'lr': 0.00018635280243835695, 'n_layers': 7, 'linear_0_out': 9, 'dropout_0': 0.08026941124262821, 'linear_1_out': 552, 'dropout_1': 0.47958330151761125, 'linear_2_out': 45, 'dropout_2': 0.29549208266184246, 'linear_3_out': 870, 'dropout_3': 0.22861172667692853, 'linear_4_out': 1750, 'dropout_4': 0.2878755810224362, 'linear_5_out': 662, 'dropout_5': 0.4544218592063692}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:30,606]\u001b[0m Trial 21 finished with value: 0.5216783216783217 and parameters: {'scaler': 0, 'batch_size': 7, 'loss_fn': 2, 'lr': 1.2586757923192073e-06, 'n_layers': 10, 'linear_0_out': 21, 'dropout_0': 0.17835344520127144, 'linear_1_out': 2, 'dropout_1': 0.09261616261809197, 'linear_2_out': 29, 'dropout_2': 0.46464570865135696, 'linear_3_out': 3, 'dropout_3': 0.47265076673953976, 'linear_4_out': 950, 'dropout_4': 0.2270811984537759, 'linear_5_out': 17, 'dropout_5': 0.11637206463952843, 'linear_6_out': 143, 'dropout_6': 0.01653729573775281, 'linear_7_out': 2, 'dropout_7': 0.21439786124911892, 'linear_8_out': 2, 'dropout_8': 0.12597049412304645}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:32,727]\u001b[0m Trial 22 finished with value: 0.5374417249417248 and parameters: {'scaler': 1, 'batch_size': 12, 'loss_fn': 2, 'lr': 1.6871833702391155e-05, 'n_layers': 2, 'linear_0_out': 171, 'dropout_0': 0.24515267327436857}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:35,028]\u001b[0m Trial 23 finished with value: 0.5307617525359463 and parameters: {'scaler': 0, 'batch_size': 25, 'loss_fn': 2, 'lr': 3.5639003446967106e-05, 'n_layers': 5, 'linear_0_out': 92, 'dropout_0': 0.14352575995981487, 'linear_1_out': 284, 'dropout_1': 0.207428434666782, 'linear_2_out': 22, 'dropout_2': 0.4143284572778689, 'linear_3_out': 1433, 'dropout_3': 0.023003655443648463}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:36,705]\u001b[0m Trial 24 finished with value: 0.43520000000000003 and parameters: {'scaler': 3, 'batch_size': 97, 'loss_fn': 2, 'lr': 5.600929719451111e-06, 'n_layers': 2, 'linear_0_out': 1738, 'dropout_0': 0.11671012773404815}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:38,489]\u001b[0m Trial 25 finished with value: 0.4801618478944061 and parameters: {'scaler': 3, 'batch_size': 28, 'loss_fn': 2, 'lr': 5.169180860350465e-06, 'n_layers': 2, 'linear_0_out': 42, 'dropout_0': 0.15223420368865975}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:40,982]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 64, 'loss_fn': 1, 'lr': 0.00012552354057838986, 'n_layers': 10, 'linear_0_out': 2399, 'dropout_0': 0.22591084133487982, 'linear_1_out': 3, 'dropout_1': 0.14639701572025943, 'linear_2_out': 5, 'dropout_2': 0.2087431873980059, 'linear_3_out': 4, 'dropout_3': 0.302058902010441, 'linear_4_out': 26, 'dropout_4': 0.447692942144105, 'linear_5_out': 1969, 'dropout_5': 0.2734424508347111, 'linear_6_out': 12, 'dropout_6': 0.2961152093809184, 'linear_7_out': 1163, 'dropout_7': 0.20336667291787414, 'linear_8_out': 90, 'dropout_8': 0.13582638380307294}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:43,507]\u001b[0m Trial 27 finished with value: 0.5272775776977456 and parameters: {'scaler': 3, 'batch_size': 32, 'loss_fn': 2, 'lr': 1.0012035881371352e-05, 'n_layers': 10, 'linear_0_out': 900, 'dropout_0': 0.02434514798776427, 'linear_1_out': 10, 'dropout_1': 0.22306775632960096, 'linear_2_out': 3, 'dropout_2': 0.17423799451674854, 'linear_3_out': 364, 'dropout_3': 0.34025724057141293, 'linear_4_out': 152, 'dropout_4': 0.3552642013611728, 'linear_5_out': 7, 'dropout_5': 0.17084905743236606, 'linear_6_out': 226, 'dropout_6': 0.43961738151566354, 'linear_7_out': 85, 'dropout_7': 0.1413498254727683, 'linear_8_out': 2, 'dropout_8': 0.3551684144871067}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:45,720]\u001b[0m Trial 28 finished with value: 0.4896921260557624 and parameters: {'scaler': 3, 'batch_size': 9, 'loss_fn': 0, 'lr': 7.356871603100482e-05, 'n_layers': 3, 'linear_0_out': 7, 'dropout_0': 0.05785161666354682, 'linear_1_out': 109, 'dropout_1': 0.347635002952343}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:48,874]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 61, 'loss_fn': 1, 'lr': 0.00012287040565803545, 'n_layers': 9, 'linear_0_out': 66, 'dropout_0': 0.16698243479840458, 'linear_1_out': 530, 'dropout_1': 0.048621462816212324, 'linear_2_out': 40, 'dropout_2': 0.2599761872854191, 'linear_3_out': 258, 'dropout_3': 0.04544286601620473, 'linear_4_out': 8, 'dropout_4': 0.20515078134506282, 'linear_5_out': 153, 'dropout_5': 0.44348039060870875, 'linear_6_out': 148, 'dropout_6': 0.06673073546746722, 'linear_7_out': 2165, 'dropout_7': 0.43589286737774646}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:51,012]\u001b[0m Trial 30 finished with value: 0.4782608695652174 and parameters: {'scaler': 3, 'batch_size': 83, 'loss_fn': 0, 'lr': 3.344383040815528e-06, 'n_layers': 4, 'linear_0_out': 1753, 'dropout_0': 0.1500144597379648, 'linear_1_out': 5, 'dropout_1': 0.44315233304327994, 'linear_2_out': 41, 'dropout_2': 0.45393779717716304}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:54,501]\u001b[0m Trial 31 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 70, 'loss_fn': 0, 'lr': 1.5248797993516155e-06, 'n_layers': 10, 'linear_0_out': 363, 'dropout_0': 0.44903117860686753, 'linear_1_out': 220, 'dropout_1': 0.2644699645154416, 'linear_2_out': 14, 'dropout_2': 0.4989811256643367, 'linear_3_out': 22, 'dropout_3': 0.23532447460695477, 'linear_4_out': 25, 'dropout_4': 0.4897634646677293, 'linear_5_out': 5, 'dropout_5': 0.16399400045403983, 'linear_6_out': 233, 'dropout_6': 0.03160380916931532, 'linear_7_out': 136, 'dropout_7': 0.23882325143820804, 'linear_8_out': 12, 'dropout_8': 0.119206640462029}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:40:57,860]\u001b[0m Trial 32 finished with value: 0.5440000000000002 and parameters: {'scaler': 0, 'batch_size': 98, 'loss_fn': 2, 'lr': 5.930355149468688e-05, 'n_layers': 7, 'linear_0_out': 29, 'dropout_0': 0.49963899696108555, 'linear_1_out': 20, 'dropout_1': 0.3607033339799762, 'linear_2_out': 170, 'dropout_2': 0.4065269316237303, 'linear_3_out': 2096, 'dropout_3': 0.4448968282227701, 'linear_4_out': 436, 'dropout_4': 0.3491242389091453, 'linear_5_out': 18, 'dropout_5': 0.07384278910335368}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:01,673]\u001b[0m Trial 33 finished with value: 0.5130718954248366 and parameters: {'scaler': 3, 'batch_size': 78, 'loss_fn': 0, 'lr': 5.8760322274750966e-05, 'n_layers': 8, 'linear_0_out': 811, 'dropout_0': 0.46791604010839427, 'linear_1_out': 2211, 'dropout_1': 0.19990084611226294, 'linear_2_out': 25, 'dropout_2': 0.07390433834863619, 'linear_3_out': 241, 'dropout_3': 0.32838097922041853, 'linear_4_out': 899, 'dropout_4': 0.04862899739382032, 'linear_5_out': 60, 'dropout_5': 0.29054096483603153, 'linear_6_out': 9, 'dropout_6': 0.08451270306458064}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:03,568]\u001b[0m Trial 34 finished with value: 0.5403184386235234 and parameters: {'scaler': 0, 'batch_size': 46, 'loss_fn': 0, 'lr': 2.2487785627034e-06, 'n_layers': 3, 'linear_0_out': 30, 'dropout_0': 0.19990607000466537, 'linear_1_out': 218, 'dropout_1': 0.17235906368775383}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:05,531]\u001b[0m Trial 35 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 62, 'loss_fn': 1, 'lr': 0.00015101754059226085, 'n_layers': 6, 'linear_0_out': 3, 'dropout_0': 0.20251780664847496, 'linear_1_out': 30, 'dropout_1': 0.16052149502160845, 'linear_2_out': 2, 'dropout_2': 0.36862712129823866, 'linear_3_out': 3, 'dropout_3': 0.30315406652254256, 'linear_4_out': 277, 'dropout_4': 0.3173931614668474}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:07,041]\u001b[0m Trial 36 finished with value: 0.09808612440191387 and parameters: {'scaler': 0, 'batch_size': 54, 'loss_fn': 1, 'lr': 3.729930544394517e-06, 'n_layers': 1}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:08,968]\u001b[0m Trial 37 finished with value: 0.22505575232847957 and parameters: {'scaler': 1, 'batch_size': 9, 'loss_fn': 1, 'lr': 6.239059036120756e-06, 'n_layers': 1}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:11,047]\u001b[0m Trial 38 finished with value: 0.5156679494227597 and parameters: {'scaler': 1, 'batch_size': 78, 'loss_fn': 0, 'lr': 1.990456170075517e-05, 'n_layers': 6, 'linear_0_out': 20, 'dropout_0': 0.39073980011733067, 'linear_1_out': 394, 'dropout_1': 0.46360590368655896, 'linear_2_out': 2, 'dropout_2': 0.4478456456051017, 'linear_3_out': 28, 'dropout_3': 0.43918624768999703, 'linear_4_out': 252, 'dropout_4': 0.4936743785369841}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:13,414]\u001b[0m Trial 39 finished with value: 0.5224747474747475 and parameters: {'scaler': 0, 'batch_size': 37, 'loss_fn': 2, 'lr': 6.792361847828891e-06, 'n_layers': 6, 'linear_0_out': 4, 'dropout_0': 0.07992264342709565, 'linear_1_out': 2, 'dropout_1': 0.4853657213853164, 'linear_2_out': 2, 'dropout_2': 0.08928998402882815, 'linear_3_out': 141, 'dropout_3': 0.04068479942665265, 'linear_4_out': 1041, 'dropout_4': 0.3598100789211441}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:14,906]\u001b[0m Trial 40 finished with value: 0.09999999999999999 and parameters: {'scaler': 0, 'batch_size': 94, 'loss_fn': 2, 'lr': 1.3054379853120687e-05, 'n_layers': 1}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:17,078]\u001b[0m Trial 41 finished with value: 0.056159420289855086 and parameters: {'scaler': 2, 'batch_size': 45, 'loss_fn': 2, 'lr': 0.0009455205830884036, 'n_layers': 4, 'linear_0_out': 1945, 'dropout_0': 0.39593978481545067, 'linear_1_out': 225, 'dropout_1': 0.12244473971004971, 'linear_2_out': 7, 'dropout_2': 0.08302391226062283}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:19,786]\u001b[0m Trial 42 finished with value: 0.2565359477124183 and parameters: {'scaler': 0, 'batch_size': 78, 'loss_fn': 0, 'lr': 0.00033772613003160847, 'n_layers': 9, 'linear_0_out': 3, 'dropout_0': 0.0781916744339815, 'linear_1_out': 14, 'dropout_1': 0.03767953454167017, 'linear_2_out': 35, 'dropout_2': 0.053808852574790955, 'linear_3_out': 102, 'dropout_3': 0.12327846990557806, 'linear_4_out': 125, 'dropout_4': 0.058762821451818825, 'linear_5_out': 2091, 'dropout_5': 0.4662806019286702, 'linear_6_out': 27, 'dropout_6': 0.12108929706304272, 'linear_7_out': 10, 'dropout_7': 0.24169676760119602}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:21,920]\u001b[0m Trial 43 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.0004927518845685147, 'n_layers': 8, 'linear_0_out': 21, 'dropout_0': 0.3108327182266289, 'linear_1_out': 13, 'dropout_1': 0.43719995853742116, 'linear_2_out': 3, 'dropout_2': 0.10621718064702051, 'linear_3_out': 6, 'dropout_3': 0.20151300120214433, 'linear_4_out': 378, 'dropout_4': 0.26345372452609017, 'linear_5_out': 56, 'dropout_5': 0.00027298244849782716, 'linear_6_out': 35, 'dropout_6': 0.031776887418079214}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:24,358]\u001b[0m Trial 44 finished with value: 0.5250710554877223 and parameters: {'scaler': 1, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.00015263863552441296, 'n_layers': 7, 'linear_0_out': 620, 'dropout_0': 0.23969227469459403, 'linear_1_out': 1330, 'dropout_1': 0.024674473394219854, 'linear_2_out': 13, 'dropout_2': 0.3575262987325835, 'linear_3_out': 33, 'dropout_3': 0.08647567713557819, 'linear_4_out': 3, 'dropout_4': 0.4086695557308107, 'linear_5_out': 50, 'dropout_5': 0.4411418359595537}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:26,657]\u001b[0m Trial 45 finished with value: 0.2764227642276423 and parameters: {'scaler': 0, 'batch_size': 89, 'loss_fn': 0, 'lr': 0.0005734852082192119, 'n_layers': 8, 'linear_0_out': 6, 'dropout_0': 0.24175906371372935, 'linear_1_out': 4, 'dropout_1': 0.17949763916981604, 'linear_2_out': 1568, 'dropout_2': 0.46165265377935416, 'linear_3_out': 12, 'dropout_3': 0.16981552208309958, 'linear_4_out': 129, 'dropout_4': 0.48159864763019, 'linear_5_out': 4, 'dropout_5': 0.12845832184333456, 'linear_6_out': 979, 'dropout_6': 0.24594611585417225}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:29,386]\u001b[0m Trial 46 finished with value: 0.5272775776977456 and parameters: {'scaler': 0, 'batch_size': 32, 'loss_fn': 0, 'lr': 0.0005557920251351604, 'n_layers': 8, 'linear_0_out': 331, 'dropout_0': 0.1449567247959777, 'linear_1_out': 109, 'dropout_1': 0.389589716650917, 'linear_2_out': 549, 'dropout_2': 0.17226523037715613, 'linear_3_out': 457, 'dropout_3': 0.3679469484038665, 'linear_4_out': 4, 'dropout_4': 0.4329727342832386, 'linear_5_out': 40, 'dropout_5': 0.24320522444433273, 'linear_6_out': 42, 'dropout_6': 0.28392300073875376}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:30,899]\u001b[0m Trial 47 finished with value: 0.2962962962962963 and parameters: {'scaler': 2, 'batch_size': 41, 'loss_fn': 1, 'lr': 4.308879880535995e-06, 'n_layers': 1}. Best is trial 4 with value: 0.6349358974358975.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:32,504]\u001b[0m Trial 48 finished with value: 0.73723247827737 and parameters: {'scaler': 1, 'batch_size': 18, 'loss_fn': 1, 'lr': 0.0008738904440963012, 'n_layers': 1}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:35,006]\u001b[0m Trial 49 finished with value: 0.493545183714002 and parameters: {'scaler': 0, 'batch_size': 76, 'loss_fn': 1, 'lr': 2.850341758833881e-05, 'n_layers': 10, 'linear_0_out': 92, 'dropout_0': 0.41343080152434747, 'linear_1_out': 326, 'dropout_1': 0.019278623029499176, 'linear_2_out': 465, 'dropout_2': 0.10843512504552033, 'linear_3_out': 1219, 'dropout_3': 0.021462095304416007, 'linear_4_out': 18, 'dropout_4': 0.049866473617377005, 'linear_5_out': 51, 'dropout_5': 0.4100112179348759, 'linear_6_out': 14, 'dropout_6': 0.0754674486555208, 'linear_7_out': 17, 'dropout_7': 0.406940070960318, 'linear_8_out': 4, 'dropout_8': 0.1136812245387509}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:37,276]\u001b[0m Trial 50 finished with value: 0.4954620462046204 and parameters: {'scaler': 1, 'batch_size': 72, 'loss_fn': 2, 'lr': 4.49767976457883e-06, 'n_layers': 10, 'linear_0_out': 5, 'dropout_0': 0.14542045332837128, 'linear_1_out': 6, 'dropout_1': 0.17275282817816723, 'linear_2_out': 53, 'dropout_2': 0.26108793450105955, 'linear_3_out': 844, 'dropout_3': 0.4447239544079333, 'linear_4_out': 8, 'dropout_4': 0.3114470160928762, 'linear_5_out': 3, 'dropout_5': 0.22948493009103416, 'linear_6_out': 16, 'dropout_6': 0.1582503727268032, 'linear_7_out': 54, 'dropout_7': 0.3649138177646338, 'linear_8_out': 3, 'dropout_8': 0.43958666884370223}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:40,197]\u001b[0m Trial 51 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 100, 'loss_fn': 1, 'lr': 8.175619524965558e-06, 'n_layers': 6, 'linear_0_out': 1399, 'dropout_0': 0.4026319277895875, 'linear_1_out': 323, 'dropout_1': 0.2795868910508511, 'linear_2_out': 1405, 'dropout_2': 0.24618070334544206, 'linear_3_out': 981, 'dropout_3': 0.4169908219383159, 'linear_4_out': 7, 'dropout_4': 0.3856127314829551}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:42,648]\u001b[0m Trial 52 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 74, 'loss_fn': 2, 'lr': 4.852210719617299e-06, 'n_layers': 7, 'linear_0_out': 122, 'dropout_0': 0.005031847828046665, 'linear_1_out': 51, 'dropout_1': 0.35438519547052433, 'linear_2_out': 2, 'dropout_2': 0.43976074151186506, 'linear_3_out': 71, 'dropout_3': 0.01533052416285896, 'linear_4_out': 8, 'dropout_4': 0.4768378482136565, 'linear_5_out': 113, 'dropout_5': 0.05373628388440227}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:45,242]\u001b[0m Trial 53 finished with value: 0.5320813771517995 and parameters: {'scaler': 1, 'batch_size': 49, 'loss_fn': 2, 'lr': 5.099207352283889e-06, 'n_layers': 7, 'linear_0_out': 173, 'dropout_0': 0.4742701505644205, 'linear_1_out': 483, 'dropout_1': 0.424172634895003, 'linear_2_out': 57, 'dropout_2': 0.09267429348969142, 'linear_3_out': 2424, 'dropout_3': 0.0646778805193498, 'linear_4_out': 50, 'dropout_4': 0.0340465496210533, 'linear_5_out': 1649, 'dropout_5': 0.4824624704242198}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:41:48,723]\u001b[0m Trial 54 finished with value: 0.37588665290677675 and parameters: {'scaler': 0, 'batch_size': 13, 'loss_fn': 0, 'lr': 7.587862071233333e-05, 'n_layers': 8, 'linear_0_out': 2, 'dropout_0': 0.21505799218836996, 'linear_1_out': 189, 'dropout_1': 0.4266229880792564, 'linear_2_out': 51, 'dropout_2': 0.4846029358588426, 'linear_3_out': 11, 'dropout_3': 0.00675435331335944, 'linear_4_out': 54, 'dropout_4': 0.12805689751000898, 'linear_5_out': 676, 'dropout_5': 0.11638633609055604, 'linear_6_out': 15, 'dropout_6': 0.39561371550955615}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:42:09,131]\u001b[0m Trial 55 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 1, 'loss_fn': 1, 'lr': 1.4230705806406946e-06, 'n_layers': 10, 'linear_0_out': 879, 'dropout_0': 0.07601361360478476, 'linear_1_out': 2, 'dropout_1': 0.4708338976948782, 'linear_2_out': 12, 'dropout_2': 0.09294880142774875, 'linear_3_out': 254, 'dropout_3': 0.0544518694206631, 'linear_4_out': 11, 'dropout_4': 0.48754734010602324, 'linear_5_out': 172, 'dropout_5': 0.2603388957412768, 'linear_6_out': 29, 'dropout_6': 0.387250477442101, 'linear_7_out': 4, 'dropout_7': 0.4836689010184911, 'linear_8_out': 892, 'dropout_8': 0.30882849128462164}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:42:38,378]\u001b[0m Trial 56 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 36, 'loss_fn': 2, 'lr': 1.9987350677964433e-06, 'n_layers': 8, 'linear_0_out': 2, 'dropout_0': 0.4835274590386098, 'linear_1_out': 144, 'dropout_1': 0.2762195294958166, 'linear_2_out': 13, 'dropout_2': 0.4646458357848917, 'linear_3_out': 11, 'dropout_3': 0.41407330660834746, 'linear_4_out': 2239, 'dropout_4': 0.3916983227574029, 'linear_5_out': 71, 'dropout_5': 0.03303713192583596, 'linear_6_out': 50, 'dropout_6': 0.21912797348585178}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:43:26,984]\u001b[0m Trial 57 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 45, 'loss_fn': 1, 'lr': 0.0005232319548256756, 'n_layers': 9, 'linear_0_out': 90, 'dropout_0': 0.42590429137862157, 'linear_1_out': 1892, 'dropout_1': 0.05526114702633028, 'linear_2_out': 162, 'dropout_2': 0.4989970004678293, 'linear_3_out': 2286, 'dropout_3': 0.3016614961453723, 'linear_4_out': 4, 'dropout_4': 0.2915964154952641, 'linear_5_out': 2, 'dropout_5': 0.09945566733342981, 'linear_6_out': 1806, 'dropout_6': 0.16522028630142194, 'linear_7_out': 171, 'dropout_7': 0.14042974731612134}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:43:33,101]\u001b[0m Trial 58 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 11, 'loss_fn': 2, 'lr': 2.029265375813338e-06, 'n_layers': 4, 'linear_0_out': 12, 'dropout_0': 0.2531714596619021, 'linear_1_out': 20, 'dropout_1': 0.3532052888335055, 'linear_2_out': 2, 'dropout_2': 0.31699346065295375}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:43:38,475]\u001b[0m Trial 59 finished with value: 0.5272775776977456 and parameters: {'scaler': 3, 'batch_size': 32, 'loss_fn': 0, 'lr': 0.0001791005413720772, 'n_layers': 2, 'linear_0_out': 35, 'dropout_0': 0.4463535821244908}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:43:47,861]\u001b[0m Trial 60 finished with value: 0.2618927098895456 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 0, 'lr': 2.8761813044696728e-05, 'n_layers': 6, 'linear_0_out': 2218, 'dropout_0': 0.34866512541502576, 'linear_1_out': 27, 'dropout_1': 0.13188384322523106, 'linear_2_out': 1658, 'dropout_2': 0.0677742165542532, 'linear_3_out': 314, 'dropout_3': 0.46269751264622033, 'linear_4_out': 208, 'dropout_4': 0.21152722008306057}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:43:53,127]\u001b[0m Trial 61 finished with value: 0.5440000000000002 and parameters: {'scaler': 2, 'batch_size': 93, 'loss_fn': 2, 'lr': 6.745458243470788e-06, 'n_layers': 4, 'linear_0_out': 25, 'dropout_0': 0.28022529435489013, 'linear_1_out': 213, 'dropout_1': 0.14335834152019716, 'linear_2_out': 2, 'dropout_2': 0.19961119182895465}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:44:38,162]\u001b[0m Trial 62 finished with value: 0.39313658201784485 and parameters: {'scaler': 1, 'batch_size': 66, 'loss_fn': 2, 'lr': 1.97620096108291e-06, 'n_layers': 9, 'linear_0_out': 2, 'dropout_0': 0.40821051560717786, 'linear_1_out': 600, 'dropout_1': 0.025503654414377908, 'linear_2_out': 157, 'dropout_2': 0.2512265371564486, 'linear_3_out': 5, 'dropout_3': 0.07418946883868782, 'linear_4_out': 465, 'dropout_4': 0.28384637441842203, 'linear_5_out': 2204, 'dropout_5': 0.49112388864417206, 'linear_6_out': 2368, 'dropout_6': 0.059307759182882946, 'linear_7_out': 1582, 'dropout_7': 0.1222848045102814}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:44:47,522]\u001b[0m Trial 63 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 19, 'loss_fn': 2, 'lr': 1.032677014460136e-06, 'n_layers': 5, 'linear_0_out': 207, 'dropout_0': 0.20084409250199436, 'linear_1_out': 3, 'dropout_1': 0.03134443101182027, 'linear_2_out': 12, 'dropout_2': 0.08465634527180038, 'linear_3_out': 1930, 'dropout_3': 0.0756151124870425}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:01,299]\u001b[0m Trial 64 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 98, 'loss_fn': 1, 'lr': 1.5378040589895286e-05, 'n_layers': 10, 'linear_0_out': 127, 'dropout_0': 0.05945847107300678, 'linear_1_out': 33, 'dropout_1': 0.3907908638408038, 'linear_2_out': 258, 'dropout_2': 0.4581701649182871, 'linear_3_out': 10, 'dropout_3': 0.3790968581769119, 'linear_4_out': 45, 'dropout_4': 0.2868048734834077, 'linear_5_out': 1791, 'dropout_5': 0.4896431599945887, 'linear_6_out': 896, 'dropout_6': 0.17954854386514812, 'linear_7_out': 1087, 'dropout_7': 0.3193045888207065, 'linear_8_out': 36, 'dropout_8': 0.017871341250241868}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:07,005]\u001b[0m Trial 65 finished with value: 0.5393939393939392 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 2.6301383959491535e-05, 'n_layers': 7, 'linear_0_out': 2, 'dropout_0': 0.05115840794379711, 'linear_1_out': 13, 'dropout_1': 0.4914950549789198, 'linear_2_out': 4, 'dropout_2': 0.16529815037960516, 'linear_3_out': 2, 'dropout_3': 0.16563444014636314, 'linear_4_out': 16, 'dropout_4': 0.4734035854722611, 'linear_5_out': 793, 'dropout_5': 0.19138210962138574}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:09,621]\u001b[0m Trial 66 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 100, 'loss_fn': 1, 'lr': 2.023300547168615e-05, 'n_layers': 8, 'linear_0_out': 229, 'dropout_0': 0.46893218722201957, 'linear_1_out': 150, 'dropout_1': 0.048905080739526374, 'linear_2_out': 1060, 'dropout_2': 0.38457776249429554, 'linear_3_out': 295, 'dropout_3': 0.026866773676867683, 'linear_4_out': 28, 'dropout_4': 0.08371790972976961, 'linear_5_out': 667, 'dropout_5': 0.3502643114089314, 'linear_6_out': 1050, 'dropout_6': 0.48328755346208196}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:12,604]\u001b[0m Trial 67 finished with value: 0.014492753623188404 and parameters: {'scaler': 1, 'batch_size': 2, 'loss_fn': 2, 'lr': 0.000762847252621894, 'n_layers': 1}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:14,646]\u001b[0m Trial 68 finished with value: 0.5567302325581396 and parameters: {'scaler': 1, 'batch_size': 99, 'loss_fn': 1, 'lr': 0.00020164339151537458, 'n_layers': 6, 'linear_0_out': 9, 'dropout_0': 0.1356530506292331, 'linear_1_out': 10, 'dropout_1': 0.2661601641292804, 'linear_2_out': 277, 'dropout_2': 0.47463995002157106, 'linear_3_out': 258, 'dropout_3': 0.3905964219811953, 'linear_4_out': 5, 'dropout_4': 0.18703131250366284}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:16,634]\u001b[0m Trial 69 finished with value: 0.519392033542977 and parameters: {'scaler': 1, 'batch_size': 36, 'loss_fn': 0, 'lr': 1.7168735068845917e-06, 'n_layers': 4, 'linear_0_out': 443, 'dropout_0': 0.34434171323934026, 'linear_1_out': 287, 'dropout_1': 0.38360503302704846, 'linear_2_out': 13, 'dropout_2': 0.274128140971044}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:18,069]\u001b[0m Trial 70 finished with value: 0.19722222222222222 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 2, 'lr': 0.0006793559747932856, 'n_layers': 1}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:20,426]\u001b[0m Trial 71 finished with value: 0.6887277748037284 and parameters: {'scaler': 1, 'batch_size': 22, 'loss_fn': 1, 'lr': 0.0004168293428724935, 'n_layers': 5, 'linear_0_out': 62, 'dropout_0': 0.27002398184684595, 'linear_1_out': 180, 'dropout_1': 0.17242829331137405, 'linear_2_out': 3, 'dropout_2': 0.15918946833308828, 'linear_3_out': 5, 'dropout_3': 0.27806658972523696}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:22,362]\u001b[0m Trial 72 finished with value: 0.1762285549504572 and parameters: {'scaler': 2, 'batch_size': 62, 'loss_fn': 0, 'lr': 8.72512856920029e-06, 'n_layers': 4, 'linear_0_out': 7, 'dropout_0': 0.24357406345868732, 'linear_1_out': 2328, 'dropout_1': 0.4560754765057944, 'linear_2_out': 4, 'dropout_2': 0.012595144645253076}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:24,094]\u001b[0m Trial 73 finished with value: 0.5055994729907773 and parameters: {'scaler': 0, 'batch_size': 65, 'loss_fn': 1, 'lr': 4.26168574257341e-06, 'n_layers': 2, 'linear_0_out': 6, 'dropout_0': 0.3427335729565585}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:26,714]\u001b[0m Trial 74 finished with value: 0.4041762013729978 and parameters: {'scaler': 3, 'batch_size': 30, 'loss_fn': 2, 'lr': 3.998837635690273e-05, 'n_layers': 10, 'linear_0_out': 28, 'dropout_0': 0.05334122340135672, 'linear_1_out': 31, 'dropout_1': 0.14806388670734666, 'linear_2_out': 58, 'dropout_2': 0.3285218384582116, 'linear_3_out': 46, 'dropout_3': 0.4675802560389128, 'linear_4_out': 1064, 'dropout_4': 0.3509887975830986, 'linear_5_out': 57, 'dropout_5': 0.06584364090722844, 'linear_6_out': 29, 'dropout_6': 0.35220076970058684, 'linear_7_out': 12, 'dropout_7': 0.051994038771710216, 'linear_8_out': 1263, 'dropout_8': 0.3545254049077723}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:30,295]\u001b[0m Trial 75 finished with value: 0.2764227642276423 and parameters: {'scaler': 2, 'batch_size': 89, 'loss_fn': 0, 'lr': 3.799724301708135e-05, 'n_layers': 6, 'linear_0_out': 1575, 'dropout_0': 0.1525943513465145, 'linear_1_out': 2211, 'dropout_1': 0.45106560740211604, 'linear_2_out': 45, 'dropout_2': 0.4087266318090831, 'linear_3_out': 451, 'dropout_3': 0.3389474848092606, 'linear_4_out': 16, 'dropout_4': 0.09822549591047697}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:31,886]\u001b[0m Trial 76 finished with value: 0.43259259259259253 and parameters: {'scaler': 1, 'batch_size': 45, 'loss_fn': 0, 'lr': 3.501880420955544e-05, 'n_layers': 2, 'linear_0_out': 297, 'dropout_0': 0.4152381725604798}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:33,738]\u001b[0m Trial 77 finished with value: 0.49473684210526325 and parameters: {'scaler': 3, 'batch_size': 67, 'loss_fn': 0, 'lr': 1.32813417411531e-05, 'n_layers': 4, 'linear_0_out': 25, 'dropout_0': 0.3289310668632141, 'linear_1_out': 22, 'dropout_1': 0.4501837258021128, 'linear_2_out': 2209, 'dropout_2': 0.015213257668502955}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:37,127]\u001b[0m Trial 78 finished with value: 0.36458333333333337 and parameters: {'scaler': 3, 'batch_size': 45, 'loss_fn': 0, 'lr': 0.0006149732401164298, 'n_layers': 7, 'linear_0_out': 559, 'dropout_0': 0.2754969850927431, 'linear_1_out': 2163, 'dropout_1': 0.2943310773407371, 'linear_2_out': 2, 'dropout_2': 0.09899139996989742, 'linear_3_out': 30, 'dropout_3': 0.30063858628688817, 'linear_4_out': 460, 'dropout_4': 0.20654306295194313, 'linear_5_out': 291, 'dropout_5': 0.3949347515545625}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:45:41,091]\u001b[0m Trial 79 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 56, 'loss_fn': 2, 'lr': 2.8252004751118314e-06, 'n_layers': 6, 'linear_0_out': 36, 'dropout_0': 0.46157951058687013, 'linear_1_out': 3, 'dropout_1': 0.4912869443404564, 'linear_2_out': 993, 'dropout_2': 0.036913140782124265, 'linear_3_out': 57, 'dropout_3': 0.35877975010626295, 'linear_4_out': 358, 'dropout_4': 0.4532470626189604}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:46:03,175]\u001b[0m Trial 80 finished with value: 0.32894557823129256 and parameters: {'scaler': 0, 'batch_size': 14, 'loss_fn': 1, 'lr': 0.00038697040263699936, 'n_layers': 6, 'linear_0_out': 20, 'dropout_0': 0.42441651280220505, 'linear_1_out': 588, 'dropout_1': 0.49917743854963476, 'linear_2_out': 805, 'dropout_2': 0.20722826740283984, 'linear_3_out': 4, 'dropout_3': 0.42032045410023894, 'linear_4_out': 2, 'dropout_4': 0.1751356036724271}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:46:10,544]\u001b[0m Trial 81 finished with value: 0.04210526315789474 and parameters: {'scaler': 1, 'batch_size': 5, 'loss_fn': 1, 'lr': 1.606166280787606e-06, 'n_layers': 3, 'linear_0_out': 21, 'dropout_0': 0.2175709932581648, 'linear_1_out': 120, 'dropout_1': 0.3611957593491182}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:46:34,906]\u001b[0m Trial 82 finished with value: 0.529263220439691 and parameters: {'scaler': 1, 'batch_size': 26, 'loss_fn': 2, 'lr': 0.00020265545977877334, 'n_layers': 9, 'linear_0_out': 314, 'dropout_0': 0.4895054595004114, 'linear_1_out': 1180, 'dropout_1': 0.2933585831116171, 'linear_2_out': 118, 'dropout_2': 0.017133520176114747, 'linear_3_out': 2473, 'dropout_3': 0.06578799868307089, 'linear_4_out': 364, 'dropout_4': 0.41050759756215444, 'linear_5_out': 24, 'dropout_5': 0.09842602733265687, 'linear_6_out': 3, 'dropout_6': 0.3743030029147889, 'linear_7_out': 43, 'dropout_7': 0.3568588795005678}. Best is trial 48 with value: 0.73723247827737.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:46:41,067]\u001b[0m Trial 83 finished with value: 0.8090869499644988 and parameters: {'scaler': 2, 'batch_size': 31, 'loss_fn': 1, 'lr': 9.343617273071668e-05, 'n_layers': 2, 'linear_0_out': 188, 'dropout_0': 0.41365661388792485}. Best is trial 83 with value: 0.8090869499644988.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:46:45,075]\u001b[0m Trial 84 finished with value: 0.5272518646012622 and parameters: {'scaler': 0, 'batch_size': 59, 'loss_fn': 1, 'lr': 3.5064462331448802e-06, 'n_layers': 2, 'linear_0_out': 6, 'dropout_0': 0.1733039053045859}. Best is trial 83 with value: 0.8090869499644988.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:46:52,298]\u001b[0m Trial 85 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 99, 'loss_fn': 1, 'lr': 8.367507641755529e-06, 'n_layers': 9, 'linear_0_out': 2, 'dropout_0': 0.00018367187572893018, 'linear_1_out': 11, 'dropout_1': 0.23104876481372494, 'linear_2_out': 171, 'dropout_2': 0.0508851332722724, 'linear_3_out': 221, 'dropout_3': 0.40090793352984727, 'linear_4_out': 6, 'dropout_4': 0.20756262741589693, 'linear_5_out': 71, 'dropout_5': 0.22590350904224032, 'linear_6_out': 566, 'dropout_6': 0.4802611990596654, 'linear_7_out': 563, 'dropout_7': 0.038996408937912286}. Best is trial 83 with value: 0.8090869499644988.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:47:00,913]\u001b[0m Trial 86 finished with value: 0.9019613054121063 and parameters: {'scaler': 0, 'batch_size': 20, 'loss_fn': 1, 'lr': 0.0007569843781663808, 'n_layers': 3, 'linear_0_out': 431, 'dropout_0': 0.43509108925357426, 'linear_1_out': 97, 'dropout_1': 0.22811125098077656}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:47:10,953]\u001b[0m Trial 87 finished with value: 0.4942989214175654 and parameters: {'scaler': 0, 'batch_size': 41, 'loss_fn': 0, 'lr': 0.0003577629930055494, 'n_layers': 8, 'linear_0_out': 12, 'dropout_0': 0.1886344663328801, 'linear_1_out': 1444, 'dropout_1': 0.40903861258693064, 'linear_2_out': 143, 'dropout_2': 0.11074508940147887, 'linear_3_out': 2, 'dropout_3': 0.21562892342094908, 'linear_4_out': 220, 'dropout_4': 0.4142402452589258, 'linear_5_out': 838, 'dropout_5': 0.016387950646681693, 'linear_6_out': 9, 'dropout_6': 0.16954729423870152}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:47:19,324]\u001b[0m Trial 88 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 99, 'loss_fn': 1, 'lr': 3.0870603272943467e-06, 'n_layers': 7, 'linear_0_out': 3, 'dropout_0': 0.28292254770935543, 'linear_1_out': 34, 'dropout_1': 0.3642369827705074, 'linear_2_out': 1197, 'dropout_2': 0.3849357573345277, 'linear_3_out': 820, 'dropout_3': 0.01647272426561619, 'linear_4_out': 15, 'dropout_4': 0.2577165433431662, 'linear_5_out': 33, 'dropout_5': 0.11562747648984423}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:48:23,941]\u001b[0m Trial 89 finished with value: 0.37362637362637363 and parameters: {'scaler': 1, 'batch_size': 1, 'loss_fn': 0, 'lr': 5.831678203625928e-06, 'n_layers': 9, 'linear_0_out': 7, 'dropout_0': 0.39876318043396997, 'linear_1_out': 602, 'dropout_1': 0.4635102843931979, 'linear_2_out': 4, 'dropout_2': 0.10863948616891567, 'linear_3_out': 371, 'dropout_3': 0.09800037714036952, 'linear_4_out': 13, 'dropout_4': 0.08337079005568132, 'linear_5_out': 5, 'dropout_5': 0.24077667731410285, 'linear_6_out': 3, 'dropout_6': 0.1608488092318111, 'linear_7_out': 36, 'dropout_7': 0.012274058261988796}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:48:32,634]\u001b[0m Trial 90 finished with value: 0.46251993620414666 and parameters: {'scaler': 3, 'batch_size': 82, 'loss_fn': 2, 'lr': 5.1750866848641635e-06, 'n_layers': 8, 'linear_0_out': 1112, 'dropout_0': 0.40306207572022207, 'linear_1_out': 3, 'dropout_1': 0.004529999761192449, 'linear_2_out': 6, 'dropout_2': 0.13523867047331162, 'linear_3_out': 145, 'dropout_3': 0.1921365876211592, 'linear_4_out': 277, 'dropout_4': 0.1765374802608043, 'linear_5_out': 5, 'dropout_5': 0.15634492174301756, 'linear_6_out': 1060, 'dropout_6': 0.4792661721225324}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:48:52,172]\u001b[0m Trial 91 finished with value: 0.5081420029246118 and parameters: {'scaler': 3, 'batch_size': 17, 'loss_fn': 2, 'lr': 0.00012644452634526433, 'n_layers': 9, 'linear_0_out': 100, 'dropout_0': 0.2384006819644301, 'linear_1_out': 151, 'dropout_1': 0.264370755849724, 'linear_2_out': 49, 'dropout_2': 0.3797251257288214, 'linear_3_out': 6, 'dropout_3': 0.08558602407757926, 'linear_4_out': 37, 'dropout_4': 0.160373958022473, 'linear_5_out': 3, 'dropout_5': 0.4222352462093672, 'linear_6_out': 459, 'dropout_6': 0.2719607499014924, 'linear_7_out': 2145, 'dropout_7': 0.03630003327380266}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:00,877]\u001b[0m Trial 92 finished with value: 0.525229357798165 and parameters: {'scaler': 0, 'batch_size': 79, 'loss_fn': 1, 'lr': 1.5033833489286598e-06, 'n_layers': 9, 'linear_0_out': 158, 'dropout_0': 0.45249115978917076, 'linear_1_out': 388, 'dropout_1': 0.2805604637148874, 'linear_2_out': 744, 'dropout_2': 0.13902511915061105, 'linear_3_out': 87, 'dropout_3': 0.14680840990170507, 'linear_4_out': 1975, 'dropout_4': 0.11309815042100319, 'linear_5_out': 2, 'dropout_5': 0.1629274210018981, 'linear_6_out': 62, 'dropout_6': 0.014181467115037538, 'linear_7_out': 95, 'dropout_7': 0.4371413874756151}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:09,883]\u001b[0m Trial 93 finished with value: 0.4304347826086956 and parameters: {'scaler': 3, 'batch_size': 83, 'loss_fn': 0, 'lr': 6.588487384253115e-05, 'n_layers': 10, 'linear_0_out': 649, 'dropout_0': 0.17030232194217598, 'linear_1_out': 5, 'dropout_1': 0.39202930723357704, 'linear_2_out': 374, 'dropout_2': 0.48352339598966154, 'linear_3_out': 988, 'dropout_3': 0.2778313126362037, 'linear_4_out': 3, 'dropout_4': 0.24175032919198003, 'linear_5_out': 15, 'dropout_5': 0.2562042410124199, 'linear_6_out': 14, 'dropout_6': 0.4309114959877979, 'linear_7_out': 788, 'dropout_7': 0.15773257858352796, 'linear_8_out': 128, 'dropout_8': 0.21509042881952706}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:21,355]\u001b[0m Trial 94 finished with value: 0.45280564845782234 and parameters: {'scaler': 3, 'batch_size': 18, 'loss_fn': 2, 'lr': 2.9624236377983616e-05, 'n_layers': 7, 'linear_0_out': 7, 'dropout_0': 0.23830711428366302, 'linear_1_out': 3, 'dropout_1': 0.16071096263783236, 'linear_2_out': 12, 'dropout_2': 0.22231268005121002, 'linear_3_out': 1489, 'dropout_3': 0.0906338310739212, 'linear_4_out': 29, 'dropout_4': 0.30779860955482236, 'linear_5_out': 1682, 'dropout_5': 0.06657409576788409}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:30,535]\u001b[0m Trial 95 finished with value: 0.49784482758620696 and parameters: {'scaler': 0, 'batch_size': 21, 'loss_fn': 2, 'lr': 0.0007331493200386492, 'n_layers': 6, 'linear_0_out': 954, 'dropout_0': 0.3040857928383897, 'linear_1_out': 20, 'dropout_1': 0.09709710380673453, 'linear_2_out': 32, 'dropout_2': 0.2614121414619239, 'linear_3_out': 2, 'dropout_3': 0.07292058293542536, 'linear_4_out': 129, 'dropout_4': 0.11250079733858104}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:39,572]\u001b[0m Trial 96 finished with value: 0.5440000000000002 and parameters: {'scaler': 0, 'batch_size': 94, 'loss_fn': 2, 'lr': 5.792477971056799e-06, 'n_layers': 7, 'linear_0_out': 642, 'dropout_0': 0.30359032006509606, 'linear_1_out': 1824, 'dropout_1': 0.3544414496304207, 'linear_2_out': 3, 'dropout_2': 0.27920501327293995, 'linear_3_out': 309, 'dropout_3': 0.4009786201867226, 'linear_4_out': 2, 'dropout_4': 0.3594394576357122, 'linear_5_out': 686, 'dropout_5': 0.37341690546767825}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:44,780]\u001b[0m Trial 97 finished with value: 0.5440000000000002 and parameters: {'scaler': 3, 'batch_size': 93, 'loss_fn': 1, 'lr': 1.6032791039858672e-06, 'n_layers': 6, 'linear_0_out': 13, 'dropout_0': 0.14258746406628614, 'linear_1_out': 21, 'dropout_1': 0.1573663860002379, 'linear_2_out': 110, 'dropout_2': 0.3418007501767785, 'linear_3_out': 11, 'dropout_3': 0.06488131128419067, 'linear_4_out': 2, 'dropout_4': 0.2878764225152761}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:50,191]\u001b[0m Trial 98 finished with value: 0.4226800976800976 and parameters: {'scaler': 2, 'batch_size': 10, 'loss_fn': 1, 'lr': 1.3411236610673985e-06, 'n_layers': 2, 'linear_0_out': 25, 'dropout_0': 0.4427613187244385}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:49:56,923]\u001b[0m Trial 99 finished with value: 0.5055994729907773 and parameters: {'scaler': 1, 'batch_size': 65, 'loss_fn': 2, 'lr': 3.0253788077125455e-06, 'n_layers': 8, 'linear_0_out': 138, 'dropout_0': 0.09255819443961527, 'linear_1_out': 2, 'dropout_1': 0.004642225252963539, 'linear_2_out': 78, 'dropout_2': 0.4713897047805968, 'linear_3_out': 179, 'dropout_3': 0.35714992314687183, 'linear_4_out': 59, 'dropout_4': 0.2909444713172849, 'linear_5_out': 4, 'dropout_5': 0.4384103102003154, 'linear_6_out': 424, 'dropout_6': 0.4990994764223048}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:02,405]\u001b[0m Trial 100 finished with value: 0.525229357798165 and parameters: {'scaler': 3, 'batch_size': 79, 'loss_fn': 1, 'lr': 2.8474625663730958e-06, 'n_layers': 2, 'linear_0_out': 1907, 'dropout_0': 0.1524820914788611}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:12,510]\u001b[0m Trial 101 finished with value: 0.15384615384615383 and parameters: {'scaler': 0, 'batch_size': 1, 'loss_fn': 2, 'lr': 0.00012426508668692083, 'n_layers': 2, 'linear_0_out': 1623, 'dropout_0': 0.3605217042162448}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:15,949]\u001b[0m Trial 102 finished with value: 0.5146365914786967 and parameters: {'scaler': 2, 'batch_size': 38, 'loss_fn': 2, 'lr': 3.308108221933576e-06, 'n_layers': 9, 'linear_0_out': 2, 'dropout_0': 0.3301692979891112, 'linear_1_out': 32, 'dropout_1': 0.3956407761162469, 'linear_2_out': 316, 'dropout_2': 0.240053903572592, 'linear_3_out': 178, 'dropout_3': 0.2508865653499726, 'linear_4_out': 618, 'dropout_4': 0.238041992984116, 'linear_5_out': 73, 'dropout_5': 0.12526029320858928, 'linear_6_out': 134, 'dropout_6': 0.15145240433491752, 'linear_7_out': 109, 'dropout_7': 0.08483905778703493}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:19,312]\u001b[0m Trial 103 finished with value: 0.5080443008629844 and parameters: {'scaler': 2, 'batch_size': 14, 'loss_fn': 2, 'lr': 2.4297429265578227e-05, 'n_layers': 8, 'linear_0_out': 51, 'dropout_0': 0.4520254097176409, 'linear_1_out': 2, 'dropout_1': 0.09033031077031717, 'linear_2_out': 18, 'dropout_2': 0.28874809403256124, 'linear_3_out': 839, 'dropout_3': 0.17510097597828822, 'linear_4_out': 11, 'dropout_4': 0.030944584421447874, 'linear_5_out': 664, 'dropout_5': 0.18983322160333949, 'linear_6_out': 104, 'dropout_6': 0.4917777090856102}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:20,971]\u001b[0m Trial 104 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 77, 'loss_fn': 1, 'lr': 6.394860784066617e-05, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:22,575]\u001b[0m Trial 105 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.0008400850720114435, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:25,009]\u001b[0m Trial 106 finished with value: 0.529263220439691 and parameters: {'scaler': 0, 'batch_size': 26, 'loss_fn': 0, 'lr': 1.5166635081858994e-05, 'n_layers': 4, 'linear_0_out': 102, 'dropout_0': 0.3339885362301089, 'linear_1_out': 768, 'dropout_1': 0.2486156984886863, 'linear_2_out': 27, 'dropout_2': 0.07198826704769085}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:27,642]\u001b[0m Trial 107 finished with value: 0.4452631578947369 and parameters: {'scaler': 0, 'batch_size': 67, 'loss_fn': 2, 'lr': 6.120051248825933e-05, 'n_layers': 5, 'linear_0_out': 256, 'dropout_0': 0.4098449027872676, 'linear_1_out': 56, 'dropout_1': 0.06713351185891242, 'linear_2_out': 826, 'dropout_2': 0.2874951636370572, 'linear_3_out': 363, 'dropout_3': 0.3523323268041458}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:29,711]\u001b[0m Trial 108 finished with value: 0.04166666666666667 and parameters: {'scaler': 0, 'batch_size': 40, 'loss_fn': 2, 'lr': 7.5459259811694576e-06, 'n_layers': 3, 'linear_0_out': 113, 'dropout_0': 0.1290179783708773, 'linear_1_out': 50, 'dropout_1': 0.4170881282781185}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:31,654]\u001b[0m Trial 109 finished with value: 0.004878048780487805 and parameters: {'scaler': 2, 'batch_size': 98, 'loss_fn': 2, 'lr': 1.751112610930873e-05, 'n_layers': 4, 'linear_0_out': 2, 'dropout_0': 0.09210215325941357, 'linear_1_out': 9, 'dropout_1': 0.09175223353566925, 'linear_2_out': 405, 'dropout_2': 0.26794149063805583}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:33,798]\u001b[0m Trial 110 finished with value: 0.4900000000000001 and parameters: {'scaler': 1, 'batch_size': 71, 'loss_fn': 2, 'lr': 0.0005306635515071287, 'n_layers': 5, 'linear_0_out': 18, 'dropout_0': 0.4947625414725136, 'linear_1_out': 179, 'dropout_1': 0.18299901323559042, 'linear_2_out': 3, 'dropout_2': 0.3939247224732106, 'linear_3_out': 287, 'dropout_3': 0.46095789962428246}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:36,593]\u001b[0m Trial 111 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 18, 'loss_fn': 1, 'lr': 1.3726223474943096e-06, 'n_layers': 5, 'linear_0_out': 240, 'dropout_0': 0.26918421923450786, 'linear_1_out': 105, 'dropout_1': 0.11238866419633231, 'linear_2_out': 808, 'dropout_2': 0.28069935879556207, 'linear_3_out': 298, 'dropout_3': 0.49093210850665125}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:39,137]\u001b[0m Trial 112 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 60, 'loss_fn': 0, 'lr': 9.020047069415738e-06, 'n_layers': 8, 'linear_0_out': 102, 'dropout_0': 0.3945179862796667, 'linear_1_out': 709, 'dropout_1': 0.42146742965064105, 'linear_2_out': 33, 'dropout_2': 0.2106366981582054, 'linear_3_out': 1447, 'dropout_3': 0.33088179730220524, 'linear_4_out': 3, 'dropout_4': 0.27109347704623415, 'linear_5_out': 21, 'dropout_5': 0.49371749485818156, 'linear_6_out': 2, 'dropout_6': 0.306090436535279}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:42,981]\u001b[0m Trial 113 finished with value: 0.5461149743268993 and parameters: {'scaler': 2, 'batch_size': 92, 'loss_fn': 1, 'lr': 0.0003524405779968913, 'n_layers': 7, 'linear_0_out': 82, 'dropout_0': 0.05729408483780285, 'linear_1_out': 83, 'dropout_1': 0.31595207317821333, 'linear_2_out': 1803, 'dropout_2': 0.29252550521193477, 'linear_3_out': 1963, 'dropout_3': 0.48080305780333105, 'linear_4_out': 187, 'dropout_4': 0.25295399205904434, 'linear_5_out': 48, 'dropout_5': 0.4451892805578913}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:46,211]\u001b[0m Trial 114 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 34, 'loss_fn': 0, 'lr': 3.932811822300938e-05, 'n_layers': 7, 'linear_0_out': 1614, 'dropout_0': 0.2878170364304907, 'linear_1_out': 143, 'dropout_1': 0.033927908851887734, 'linear_2_out': 1754, 'dropout_2': 0.2640409639546931, 'linear_3_out': 572, 'dropout_3': 0.025145531573694535, 'linear_4_out': 34, 'dropout_4': 0.1284877295763508, 'linear_5_out': 11, 'dropout_5': 0.3957268649804647}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:48,579]\u001b[0m Trial 115 finished with value: 0.5440000000000002 and parameters: {'scaler': 3, 'batch_size': 97, 'loss_fn': 2, 'lr': 0.0007148788424003312, 'n_layers': 10, 'linear_0_out': 115, 'dropout_0': 0.1517744253268536, 'linear_1_out': 17, 'dropout_1': 0.4489567757430138, 'linear_2_out': 58, 'dropout_2': 0.0655581144835728, 'linear_3_out': 9, 'dropout_3': 0.13839745073374954, 'linear_4_out': 4, 'dropout_4': 0.23152219076064567, 'linear_5_out': 1341, 'dropout_5': 0.33439127149613046, 'linear_6_out': 3, 'dropout_6': 0.002747408904581361, 'linear_7_out': 12, 'dropout_7': 0.1813464673969702, 'linear_8_out': 477, 'dropout_8': 0.4835027619651833}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:50,978]\u001b[0m Trial 116 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 64, 'loss_fn': 2, 'lr': 4.008818971780071e-06, 'n_layers': 9, 'linear_0_out': 263, 'dropout_0': 0.18316218541537732, 'linear_1_out': 76, 'dropout_1': 0.2714032343764068, 'linear_2_out': 300, 'dropout_2': 0.25827797054959806, 'linear_3_out': 4, 'dropout_3': 0.3867273357609563, 'linear_4_out': 31, 'dropout_4': 0.48154694510596363, 'linear_5_out': 12, 'dropout_5': 0.1315393901482923, 'linear_6_out': 18, 'dropout_6': 0.28615850797931275, 'linear_7_out': 1146, 'dropout_7': 0.0881408200700074}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:52,979]\u001b[0m Trial 117 finished with value: 0.4782608695652174 and parameters: {'scaler': 1, 'batch_size': 83, 'loss_fn': 0, 'lr': 0.00025303239901440755, 'n_layers': 6, 'linear_0_out': 13, 'dropout_0': 0.3190422988611419, 'linear_1_out': 115, 'dropout_1': 0.4507814098698052, 'linear_2_out': 2, 'dropout_2': 0.4550656935667334, 'linear_3_out': 79, 'dropout_3': 0.007838058024956962, 'linear_4_out': 19, 'dropout_4': 0.3621667819376599}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:55,593]\u001b[0m Trial 118 finished with value: 0.4782608695652174 and parameters: {'scaler': 1, 'batch_size': 83, 'loss_fn': 2, 'lr': 0.0001033433744516868, 'n_layers': 5, 'linear_0_out': 4, 'dropout_0': 0.29012408328565026, 'linear_1_out': 1168, 'dropout_1': 0.20944621325920748, 'linear_2_out': 1289, 'dropout_2': 0.251763909891201, 'linear_3_out': 150, 'dropout_3': 0.41649423802782143}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:57,280]\u001b[0m Trial 119 finished with value: 0.05014619883040936 and parameters: {'scaler': 2, 'batch_size': 72, 'loss_fn': 0, 'lr': 0.00014670749345675738, 'n_layers': 2, 'linear_0_out': 2330, 'dropout_0': 0.42268676855360193}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:50:59,210]\u001b[0m Trial 120 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 88, 'loss_fn': 1, 'lr': 1.0267089337728083e-05, 'n_layers': 2, 'linear_0_out': 2331, 'dropout_0': 0.2857487232312278}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:51:10,500]\u001b[0m Trial 121 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 9, 'loss_fn': 1, 'lr': 0.0003271004437990773, 'n_layers': 10, 'linear_0_out': 4, 'dropout_0': 0.12968690926349974, 'linear_1_out': 36, 'dropout_1': 0.00045164276062481523, 'linear_2_out': 3, 'dropout_2': 0.11324563897051082, 'linear_3_out': 53, 'dropout_3': 0.1257613690843064, 'linear_4_out': 1002, 'dropout_4': 0.16213643777100556, 'linear_5_out': 1429, 'dropout_5': 0.487393630367355, 'linear_6_out': 42, 'dropout_6': 0.11356440844966181, 'linear_7_out': 13, 'dropout_7': 0.3881668408297231, 'linear_8_out': 11, 'dropout_8': 0.1902914339601423}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:51:18,495]\u001b[0m Trial 122 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 36, 'loss_fn': 1, 'lr': 1.2006855989387073e-05, 'n_layers': 9, 'linear_0_out': 14, 'dropout_0': 0.18596738992453443, 'linear_1_out': 1656, 'dropout_1': 0.3641894981634341, 'linear_2_out': 69, 'dropout_2': 0.3885963642017203, 'linear_3_out': 4, 'dropout_3': 0.23224517661042116, 'linear_4_out': 4, 'dropout_4': 0.11680907250979, 'linear_5_out': 4, 'dropout_5': 0.18090061958456966, 'linear_6_out': 25, 'dropout_6': 0.4736542909166204, 'linear_7_out': 11, 'dropout_7': 0.23621442265825843}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:51:25,452]\u001b[0m Trial 123 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 50, 'loss_fn': 2, 'lr': 0.0001643526321185132, 'n_layers': 6, 'linear_0_out': 1079, 'dropout_0': 0.41545439888878793, 'linear_1_out': 2, 'dropout_1': 0.284209521433108, 'linear_2_out': 138, 'dropout_2': 0.48078757215004075, 'linear_3_out': 2, 'dropout_3': 0.26555188548431446, 'linear_4_out': 7, 'dropout_4': 0.026831453145794548}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:51:31,137]\u001b[0m Trial 124 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 41, 'loss_fn': 1, 'lr': 4.421277129613579e-06, 'n_layers': 4, 'linear_0_out': 12, 'dropout_0': 0.48113995566379913, 'linear_1_out': 20, 'dropout_1': 0.44708625764648596, 'linear_2_out': 6, 'dropout_2': 0.38187343359410714}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:51:38,432]\u001b[0m Trial 125 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 96, 'loss_fn': 1, 'lr': 1.1928469827734548e-05, 'n_layers': 10, 'linear_0_out': 14, 'dropout_0': 0.204647656117381, 'linear_1_out': 3, 'dropout_1': 0.328469480950072, 'linear_2_out': 2, 'dropout_2': 0.24245263759951863, 'linear_3_out': 238, 'dropout_3': 0.41061880047455546, 'linear_4_out': 5, 'dropout_4': 0.3770451831243587, 'linear_5_out': 311, 'dropout_5': 0.2797852670598921, 'linear_6_out': 115, 'dropout_6': 0.04563536042838906, 'linear_7_out': 129, 'dropout_7': 0.19076110353541614, 'linear_8_out': 936, 'dropout_8': 0.1565494408679951}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:51:57,565]\u001b[0m Trial 126 finished with value: 0.48948458948458945 and parameters: {'scaler': 2, 'batch_size': 8, 'loss_fn': 0, 'lr': 1.1999633869478679e-06, 'n_layers': 10, 'linear_0_out': 1009, 'dropout_0': 0.31193395028863874, 'linear_1_out': 2, 'dropout_1': 0.1889882369914383, 'linear_2_out': 2137, 'dropout_2': 0.3406651793701173, 'linear_3_out': 5, 'dropout_3': 0.2302983743272503, 'linear_4_out': 1954, 'dropout_4': 0.2673540872082967, 'linear_5_out': 2, 'dropout_5': 0.30988604213798887, 'linear_6_out': 11, 'dropout_6': 0.049422975938452185, 'linear_7_out': 30, 'dropout_7': 0.2792615487161224, 'linear_8_out': 2, 'dropout_8': 0.27952340431797373}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:52:01,515]\u001b[0m Trial 127 finished with value: 0.3095238095238095 and parameters: {'scaler': 1, 'batch_size': 75, 'loss_fn': 0, 'lr': 0.00012129215444395101, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:52:09,843]\u001b[0m Trial 128 finished with value: 0.2408008658008658 and parameters: {'scaler': 0, 'batch_size': 71, 'loss_fn': 0, 'lr': 0.0003580719601299203, 'n_layers': 3, 'linear_0_out': 416, 'dropout_0': 0.3169125565776118, 'linear_1_out': 1792, 'dropout_1': 0.1301232886458804}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:52:16,431]\u001b[0m Trial 129 finished with value: 0.5088261253309796 and parameters: {'scaler': 3, 'batch_size': 74, 'loss_fn': 2, 'lr': 0.0007408233588121216, 'n_layers': 6, 'linear_0_out': 185, 'dropout_0': 0.25034604951028105, 'linear_1_out': 12, 'dropout_1': 0.1430738019983021, 'linear_2_out': 15, 'dropout_2': 0.09542500208207699, 'linear_3_out': 1208, 'dropout_3': 0.42919906702334293, 'linear_4_out': 46, 'dropout_4': 0.18362570628008523}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:52:31,890]\u001b[0m Trial 130 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 20, 'loss_fn': 1, 'lr': 0.00040626017195113576, 'n_layers': 10, 'linear_0_out': 434, 'dropout_0': 0.23254589207187942, 'linear_1_out': 729, 'dropout_1': 0.06019369708300082, 'linear_2_out': 239, 'dropout_2': 0.259168893726717, 'linear_3_out': 6, 'dropout_3': 0.486466808640107, 'linear_4_out': 18, 'dropout_4': 0.3077117029816917, 'linear_5_out': 1016, 'dropout_5': 0.2533444219574103, 'linear_6_out': 4, 'dropout_6': 0.40936954217364496, 'linear_7_out': 21, 'dropout_7': 0.4915334344459194, 'linear_8_out': 1056, 'dropout_8': 0.4267246666744786}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:52:38,197]\u001b[0m Trial 131 finished with value: 0.5324675324675325 and parameters: {'scaler': 2, 'batch_size': 48, 'loss_fn': 2, 'lr': 5.525499681908728e-06, 'n_layers': 4, 'linear_0_out': 62, 'dropout_0': 0.036040078680758425, 'linear_1_out': 3, 'dropout_1': 0.2105553794440404, 'linear_2_out': 10, 'dropout_2': 0.20301865126638424}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:52:45,006]\u001b[0m Trial 132 finished with value: 0.2764227642276423 and parameters: {'scaler': 1, 'batch_size': 89, 'loss_fn': 1, 'lr': 1.2522078905181566e-05, 'n_layers': 8, 'linear_0_out': 35, 'dropout_0': 0.40347564378566686, 'linear_1_out': 311, 'dropout_1': 0.4714197231055081, 'linear_2_out': 79, 'dropout_2': 0.40107397699389763, 'linear_3_out': 16, 'dropout_3': 0.1728729225449323, 'linear_4_out': 29, 'dropout_4': 0.20545786714904452, 'linear_5_out': 3, 'dropout_5': 0.2595494696659318, 'linear_6_out': 3, 'dropout_6': 0.444881067909882}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:52:53,492]\u001b[0m Trial 133 finished with value: 0.525229357798165 and parameters: {'scaler': 1, 'batch_size': 79, 'loss_fn': 0, 'lr': 0.000238597287454967, 'n_layers': 8, 'linear_0_out': 3, 'dropout_0': 0.34275635952288813, 'linear_1_out': 304, 'dropout_1': 0.43108313352101363, 'linear_2_out': 65, 'dropout_2': 0.23054700015167867, 'linear_3_out': 1930, 'dropout_3': 0.39825612786937675, 'linear_4_out': 95, 'dropout_4': 0.16530853565563974, 'linear_5_out': 793, 'dropout_5': 0.22771819473220234, 'linear_6_out': 3, 'dropout_6': 0.2274521363567199}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:00,599]\u001b[0m Trial 134 finished with value: 0.2868899521531101 and parameters: {'scaler': 0, 'batch_size': 100, 'loss_fn': 2, 'lr': 0.00027589577188836227, 'n_layers': 5, 'linear_0_out': 120, 'dropout_0': 0.36564640460150993, 'linear_1_out': 800, 'dropout_1': 0.0290882011883557, 'linear_2_out': 470, 'dropout_2': 0.22375171998910098, 'linear_3_out': 202, 'dropout_3': 0.38231650547942503}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:09,485]\u001b[0m Trial 135 finished with value: 0.49540399372737953 and parameters: {'scaler': 0, 'batch_size': 69, 'loss_fn': 0, 'lr': 5.660756683831392e-05, 'n_layers': 4, 'linear_0_out': 83, 'dropout_0': 0.15036345289232012, 'linear_1_out': 359, 'dropout_1': 0.12967075399351274, 'linear_2_out': 1915, 'dropout_2': 0.3309743660867657}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:18,035]\u001b[0m Trial 136 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 32, 'loss_fn': 1, 'lr': 3.259559932373216e-05, 'n_layers': 6, 'linear_0_out': 16, 'dropout_0': 0.3070875011819207, 'linear_1_out': 34, 'dropout_1': 0.0996140732120896, 'linear_2_out': 196, 'dropout_2': 0.18692028462960603, 'linear_3_out': 508, 'dropout_3': 0.20769747875476352, 'linear_4_out': 65, 'dropout_4': 0.39373323959044815}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:24,836]\u001b[0m Trial 137 finished with value: 0.5440000000000002 and parameters: {'scaler': 1, 'batch_size': 96, 'loss_fn': 2, 'lr': 0.0001048034189426208, 'n_layers': 10, 'linear_0_out': 13, 'dropout_0': 0.14568076431299598, 'linear_1_out': 1361, 'dropout_1': 0.3996528208632798, 'linear_2_out': 7, 'dropout_2': 0.28502343904638383, 'linear_3_out': 379, 'dropout_3': 0.17651819522375456, 'linear_4_out': 38, 'dropout_4': 0.2876983058304465, 'linear_5_out': 48, 'dropout_5': 0.3765211950345164, 'linear_6_out': 2, 'dropout_6': 0.21731626219552524, 'linear_7_out': 18, 'dropout_7': 0.30458202641491344, 'linear_8_out': 474, 'dropout_8': 0.03807258110076511}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:30,255]\u001b[0m Trial 138 finished with value: 0.5440000000000002 and parameters: {'scaler': 2, 'batch_size': 99, 'loss_fn': 2, 'lr': 6.400686650767653e-05, 'n_layers': 6, 'linear_0_out': 86, 'dropout_0': 0.46954785477476946, 'linear_1_out': 4, 'dropout_1': 0.03659864926248918, 'linear_2_out': 5, 'dropout_2': 0.12249510495247523, 'linear_3_out': 122, 'dropout_3': 0.3062126245483672, 'linear_4_out': 8, 'dropout_4': 0.24461274965546875}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:38,536]\u001b[0m Trial 139 finished with value: 0.493545183714002 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 2, 'lr': 3.413105807321405e-06, 'n_layers': 5, 'linear_0_out': 138, 'dropout_0': 0.09238728741864366, 'linear_1_out': 411, 'dropout_1': 0.03949812389815871, 'linear_2_out': 1680, 'dropout_2': 0.23411074710906787, 'linear_3_out': 18, 'dropout_3': 0.05840350358132018}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:43,172]\u001b[0m Trial 140 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 84, 'loss_fn': 0, 'lr': 0.0005169577834991394, 'n_layers': 3, 'linear_0_out': 6, 'dropout_0': 0.4999820092713012, 'linear_1_out': 15, 'dropout_1': 0.062370093904681845}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:53:56,630]\u001b[0m Trial 141 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 10, 'loss_fn': 1, 'lr': 2.8302160172149545e-06, 'n_layers': 6, 'linear_0_out': 81, 'dropout_0': 0.09920337387444966, 'linear_1_out': 132, 'dropout_1': 0.1701156171584728, 'linear_2_out': 9, 'dropout_2': 0.25520030544951405, 'linear_3_out': 13, 'dropout_3': 0.11106996088060661, 'linear_4_out': 1024, 'dropout_4': 0.07788128828670865}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:54:02,983]\u001b[0m Trial 142 finished with value: 0.5130718954248366 and parameters: {'scaler': 1, 'batch_size': 78, 'loss_fn': 2, 'lr': 2.379389231278886e-06, 'n_layers': 4, 'linear_0_out': 1041, 'dropout_0': 0.18458059755310985, 'linear_1_out': 164, 'dropout_1': 0.25731276800431563, 'linear_2_out': 4, 'dropout_2': 0.3245347988954176}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:54:10,265]\u001b[0m Trial 143 finished with value: 0.2809917355371901 and parameters: {'scaler': 0, 'batch_size': 87, 'loss_fn': 2, 'lr': 1.1642706155647523e-06, 'n_layers': 8, 'linear_0_out': 872, 'dropout_0': 0.22665202618837876, 'linear_1_out': 38, 'dropout_1': 0.139234481034683, 'linear_2_out': 2, 'dropout_2': 0.09315175833317801, 'linear_3_out': 2154, 'dropout_3': 0.4336430385606783, 'linear_4_out': 11, 'dropout_4': 0.4818744285605232, 'linear_5_out': 23, 'dropout_5': 0.14879268737559004, 'linear_6_out': 5, 'dropout_6': 0.450805534755337}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:54:31,010]\u001b[0m Trial 144 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 11, 'loss_fn': 1, 'lr': 0.00028498258687029637, 'n_layers': 5, 'linear_0_out': 9, 'dropout_0': 0.2963797892714717, 'linear_1_out': 539, 'dropout_1': 0.1638121745259879, 'linear_2_out': 273, 'dropout_2': 0.21392958999034367, 'linear_3_out': 1915, 'dropout_3': 0.3854700433013658}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:54:35,838]\u001b[0m Trial 145 finished with value: 0.6201298701298701 and parameters: {'scaler': 2, 'batch_size': 13, 'loss_fn': 1, 'lr': 8.040918430009324e-06, 'n_layers': 2, 'linear_0_out': 45, 'dropout_0': 0.4329218799178738}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:54:43,152]\u001b[0m Trial 146 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 92, 'loss_fn': 1, 'lr': 7.424717525028117e-06, 'n_layers': 10, 'linear_0_out': 20, 'dropout_0': 0.05392484063034364, 'linear_1_out': 27, 'dropout_1': 0.22383914547999118, 'linear_2_out': 398, 'dropout_2': 0.4749571334735014, 'linear_3_out': 644, 'dropout_3': 0.465470655627553, 'linear_4_out': 51, 'dropout_4': 0.3596582841182171, 'linear_5_out': 15, 'dropout_5': 0.034793554259508974, 'linear_6_out': 23, 'dropout_6': 0.34895761416414883, 'linear_7_out': 12, 'dropout_7': 0.43070294782076046, 'linear_8_out': 530, 'dropout_8': 0.09702127459230148}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:54:51,683]\u001b[0m Trial 147 finished with value: 0.32185990338164244 and parameters: {'scaler': 1, 'batch_size': 35, 'loss_fn': 0, 'lr': 5.4369413040964306e-05, 'n_layers': 4, 'linear_0_out': 164, 'dropout_0': 0.13323063808969143, 'linear_1_out': 1279, 'dropout_1': 0.38047094358722805, 'linear_2_out': 2, 'dropout_2': 0.39195273864251706}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:08,245]\u001b[0m Trial 148 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 58, 'loss_fn': 1, 'lr': 6.796679160055155e-05, 'n_layers': 7, 'linear_0_out': 39, 'dropout_0': 0.18636837571880333, 'linear_1_out': 1553, 'dropout_1': 0.16596356739634333, 'linear_2_out': 2, 'dropout_2': 0.2004200770772287, 'linear_3_out': 528, 'dropout_3': 0.3242341790244597, 'linear_4_out': 1889, 'dropout_4': 0.05310093380956882, 'linear_5_out': 1297, 'dropout_5': 0.18442459695703106}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:12,422]\u001b[0m Trial 149 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.00037339128046701267, 'n_layers': 7, 'linear_0_out': 5, 'dropout_0': 0.3843861115268768, 'linear_1_out': 1955, 'dropout_1': 0.4672801872650091, 'linear_2_out': 1397, 'dropout_2': 0.003905107702871613, 'linear_3_out': 119, 'dropout_3': 0.12831630831951463, 'linear_4_out': 99, 'dropout_4': 0.15901514458027732, 'linear_5_out': 5, 'dropout_5': 0.22224686167917335}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:14,648]\u001b[0m Trial 150 finished with value: 0.6330943068231204 and parameters: {'scaler': 1, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.00018993671715631427, 'n_layers': 5, 'linear_0_out': 7, 'dropout_0': 0.40500193041859994, 'linear_1_out': 101, 'dropout_1': 0.06975259689341484, 'linear_2_out': 588, 'dropout_2': 0.4792929551812891, 'linear_3_out': 20, 'dropout_3': 0.14675612604322175}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:16,806]\u001b[0m Trial 151 finished with value: 0.08587656303433097 and parameters: {'scaler': 2, 'batch_size': 49, 'loss_fn': 2, 'lr': 0.00040092351200541617, 'n_layers': 4, 'linear_0_out': 995, 'dropout_0': 0.05852654957551595, 'linear_1_out': 9, 'dropout_1': 0.45080336345335925, 'linear_2_out': 65, 'dropout_2': 0.30409619189851206}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:19,527]\u001b[0m Trial 152 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 14, 'loss_fn': 0, 'lr': 1.244889036964728e-05, 'n_layers': 3, 'linear_0_out': 3, 'dropout_0': 0.14035329528706686, 'linear_1_out': 50, 'dropout_1': 0.40875439944839775}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:21,680]\u001b[0m Trial 153 finished with value: 0.2974200206398349 and parameters: {'scaler': 1, 'batch_size': 42, 'loss_fn': 2, 'lr': 3.2440826894119e-05, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:24,490]\u001b[0m Trial 154 finished with value: 0.06658669789754983 and parameters: {'scaler': 0, 'batch_size': 29, 'loss_fn': 2, 'lr': 4.3490885279185996e-05, 'n_layers': 4, 'linear_0_out': 627, 'dropout_0': 0.3487001891828829, 'linear_1_out': 32, 'dropout_1': 0.31480915135329657, 'linear_2_out': 484, 'dropout_2': 0.42577889714174466}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:28,127]\u001b[0m Trial 155 finished with value: 0.5022803114571747 and parameters: {'scaler': 2, 'batch_size': 21, 'loss_fn': 0, 'lr': 8.392610617151963e-06, 'n_layers': 5, 'linear_0_out': 16, 'dropout_0': 0.03508678393245224, 'linear_1_out': 62, 'dropout_1': 0.4817997221974437, 'linear_2_out': 140, 'dropout_2': 0.15001593580856265, 'linear_3_out': 1806, 'dropout_3': 0.19461862597611368}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:32,661]\u001b[0m Trial 156 finished with value: 0.45782312925170066 and parameters: {'scaler': 2, 'batch_size': 15, 'loss_fn': 2, 'lr': 3.0124566898592286e-05, 'n_layers': 7, 'linear_0_out': 3, 'dropout_0': 0.10990219892823594, 'linear_1_out': 5, 'dropout_1': 0.300580291775017, 'linear_2_out': 6, 'dropout_2': 0.029923157775425313, 'linear_3_out': 14, 'dropout_3': 0.33860621455697637, 'linear_4_out': 109, 'dropout_4': 0.1653624827473179, 'linear_5_out': 727, 'dropout_5': 0.1381345540060448}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:37,319]\u001b[0m Trial 157 finished with value: 0.529905030133863 and parameters: {'scaler': 1, 'batch_size': 16, 'loss_fn': 0, 'lr': 0.00015874912602477833, 'n_layers': 10, 'linear_0_out': 467, 'dropout_0': 0.20281694731163186, 'linear_1_out': 122, 'dropout_1': 0.373248907937852, 'linear_2_out': 32, 'dropout_2': 0.18012407940615055, 'linear_3_out': 4, 'dropout_3': 0.3681304007379378, 'linear_4_out': 755, 'dropout_4': 0.15829220551497641, 'linear_5_out': 502, 'dropout_5': 0.30510652916849373, 'linear_6_out': 504, 'dropout_6': 0.2056686915748322, 'linear_7_out': 384, 'dropout_7': 0.204254558948813, 'linear_8_out': 3, 'dropout_8': 0.27528945906747204}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:40,637]\u001b[0m Trial 158 finished with value: 0.0811594202898551 and parameters: {'scaler': 2, 'batch_size': 4, 'loss_fn': 2, 'lr': 0.00024977537767067906, 'n_layers': 2, 'linear_0_out': 758, 'dropout_0': 0.1239636141268326}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:45,444]\u001b[0m Trial 159 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 93, 'loss_fn': 1, 'lr': 9.863616311754945e-05, 'n_layers': 10, 'linear_0_out': 576, 'dropout_0': 0.13742219710713072, 'linear_1_out': 523, 'dropout_1': 0.3463308231419518, 'linear_2_out': 29, 'dropout_2': 0.038398735113557514, 'linear_3_out': 7, 'dropout_3': 0.3986189458216775, 'linear_4_out': 9, 'dropout_4': 0.498928991511674, 'linear_5_out': 258, 'dropout_5': 0.23861124035880393, 'linear_6_out': 103, 'dropout_6': 0.3054363617707181, 'linear_7_out': 1986, 'dropout_7': 0.08087059731575974, 'linear_8_out': 11, 'dropout_8': 0.3547955239856218}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:50,059]\u001b[0m Trial 160 finished with value: 0.07685881370091896 and parameters: {'scaler': 1, 'batch_size': 5, 'loss_fn': 1, 'lr': 0.0005657420486462826, 'n_layers': 8, 'linear_0_out': 2, 'dropout_0': 0.28631649833737494, 'linear_1_out': 101, 'dropout_1': 0.10118615246799012, 'linear_2_out': 18, 'dropout_2': 0.22913944679188114, 'linear_3_out': 2, 'dropout_3': 0.07488820464294393, 'linear_4_out': 5, 'dropout_4': 0.18961787722819545, 'linear_5_out': 384, 'dropout_5': 0.41565182954862945, 'linear_6_out': 5, 'dropout_6': 0.37595301800338493}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:54,831]\u001b[0m Trial 161 finished with value: 0.4407229134501862 and parameters: {'scaler': 2, 'batch_size': 9, 'loss_fn': 0, 'lr': 0.0004426982116468227, 'n_layers': 10, 'linear_0_out': 16, 'dropout_0': 0.421084050218997, 'linear_1_out': 878, 'dropout_1': 0.3026952402510181, 'linear_2_out': 100, 'dropout_2': 0.28791920462280485, 'linear_3_out': 14, 'dropout_3': 0.3094335194694954, 'linear_4_out': 9, 'dropout_4': 0.08881614503780438, 'linear_5_out': 32, 'dropout_5': 0.3528902114922176, 'linear_6_out': 151, 'dropout_6': 0.48244103966985125, 'linear_7_out': 182, 'dropout_7': 0.07065702489796022, 'linear_8_out': 5, 'dropout_8': 0.04653357003891606}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:55:57,444]\u001b[0m Trial 162 finished with value: 0.4942989214175654 and parameters: {'scaler': 3, 'batch_size': 41, 'loss_fn': 1, 'lr': 6.123602805023379e-05, 'n_layers': 2, 'linear_0_out': 51, 'dropout_0': 0.08653613018173417}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:02,901]\u001b[0m Trial 163 finished with value: 0.5080443008629844 and parameters: {'scaler': 0, 'batch_size': 14, 'loss_fn': 2, 'lr': 0.00014155500157769717, 'n_layers': 6, 'linear_0_out': 3, 'dropout_0': 0.2831309271400165, 'linear_1_out': 3, 'dropout_1': 0.009086509638118911, 'linear_2_out': 21, 'dropout_2': 0.1202724595319497, 'linear_3_out': 124, 'dropout_3': 0.46432124403480685, 'linear_4_out': 313, 'dropout_4': 0.38368043098549354}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:05,031]\u001b[0m Trial 164 finished with value: 0.050847457627118633 and parameters: {'scaler': 0, 'batch_size': 87, 'loss_fn': 1, 'lr': 8.198127198365308e-06, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:08,109]\u001b[0m Trial 165 finished with value: 0.37054972648192985 and parameters: {'scaler': 1, 'batch_size': 44, 'loss_fn': 0, 'lr': 1.777758013435998e-05, 'n_layers': 6, 'linear_0_out': 72, 'dropout_0': 0.18386334253392478, 'linear_1_out': 430, 'dropout_1': 0.033614519995606884, 'linear_2_out': 2, 'dropout_2': 0.21012966979918768, 'linear_3_out': 1162, 'dropout_3': 0.13878467526483457, 'linear_4_out': 5, 'dropout_4': 0.4641041971646881}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:10,523]\u001b[0m Trial 166 finished with value: 0.36499442586399106 and parameters: {'scaler': 2, 'batch_size': 23, 'loss_fn': 2, 'lr': 1.2413023675606489e-06, 'n_layers': 2, 'linear_0_out': 1839, 'dropout_0': 0.2963956457744842}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:22,608]\u001b[0m Trial 167 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 97, 'loss_fn': 0, 'lr': 2.690368498150143e-05, 'n_layers': 10, 'linear_0_out': 1528, 'dropout_0': 0.004623553489764398, 'linear_1_out': 399, 'dropout_1': 0.0031188832233551844, 'linear_2_out': 2226, 'dropout_2': 0.20848360099784924, 'linear_3_out': 2054, 'dropout_3': 0.18387340451531875, 'linear_4_out': 13, 'dropout_4': 0.15814598191730245, 'linear_5_out': 339, 'dropout_5': 0.09983641696509848, 'linear_6_out': 912, 'dropout_6': 0.2952863468133712, 'linear_7_out': 2000, 'dropout_7': 0.4935424517430743, 'linear_8_out': 6, 'dropout_8': 0.4778910267880089}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:27,977]\u001b[0m Trial 168 finished with value: 0.45782312925170066 and parameters: {'scaler': 3, 'batch_size': 15, 'loss_fn': 2, 'lr': 7.65159068159521e-05, 'n_layers': 8, 'linear_0_out': 55, 'dropout_0': 0.32420685112091413, 'linear_1_out': 351, 'dropout_1': 0.3689406419586507, 'linear_2_out': 2, 'dropout_2': 0.049954036865030305, 'linear_3_out': 22, 'dropout_3': 0.0305987235517709, 'linear_4_out': 26, 'dropout_4': 0.19478342423609613, 'linear_5_out': 1384, 'dropout_5': 0.28353592744734546, 'linear_6_out': 283, 'dropout_6': 0.4435993410431142}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:32,332]\u001b[0m Trial 169 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 91, 'loss_fn': 2, 'lr': 1.1303715229429974e-05, 'n_layers': 7, 'linear_0_out': 12, 'dropout_0': 0.04895939939537075, 'linear_1_out': 62, 'dropout_1': 0.4616159185590838, 'linear_2_out': 148, 'dropout_2': 0.10441331239186719, 'linear_3_out': 237, 'dropout_3': 0.3841805720488163, 'linear_4_out': 16, 'dropout_4': 0.2796047007155193, 'linear_5_out': 236, 'dropout_5': 0.08017657269024409}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:40,677]\u001b[0m Trial 170 finished with value: 0.09038174960882248 and parameters: {'scaler': 2, 'batch_size': 49, 'loss_fn': 2, 'lr': 1.6201753158618232e-05, 'n_layers': 5, 'linear_0_out': 1077, 'dropout_0': 0.31783863194042095, 'linear_1_out': 38, 'dropout_1': 0.4939988498049064, 'linear_2_out': 143, 'dropout_2': 0.1613314824924858, 'linear_3_out': 253, 'dropout_3': 0.24784996134150256}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:45,717]\u001b[0m Trial 171 finished with value: 0.3385429385429385 and parameters: {'scaler': 1, 'batch_size': 27, 'loss_fn': 1, 'lr': 1.2566944610505965e-05, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:56:52,630]\u001b[0m Trial 172 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 49, 'loss_fn': 1, 'lr': 1.133459803833223e-05, 'n_layers': 6, 'linear_0_out': 2, 'dropout_0': 0.08741828162205456, 'linear_1_out': 1556, 'dropout_1': 0.014717618530680598, 'linear_2_out': 3, 'dropout_2': 0.21032350851685938, 'linear_3_out': 341, 'dropout_3': 0.13443911519517426, 'linear_4_out': 15, 'dropout_4': 0.15273649006219336}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:00,474]\u001b[0m Trial 173 finished with value: 0.10034100596760442 and parameters: {'scaler': 3, 'batch_size': 73, 'loss_fn': 2, 'lr': 1.3201200326154422e-05, 'n_layers': 8, 'linear_0_out': 3, 'dropout_0': 0.44764841837707087, 'linear_1_out': 3, 'dropout_1': 0.18646254813079732, 'linear_2_out': 84, 'dropout_2': 0.13178882122510943, 'linear_3_out': 185, 'dropout_3': 0.2772143636962057, 'linear_4_out': 307, 'dropout_4': 0.1770696825610804, 'linear_5_out': 86, 'dropout_5': 0.4060927000906145, 'linear_6_out': 614, 'dropout_6': 0.35711998742594075}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:06,914]\u001b[0m Trial 174 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 87, 'loss_fn': 1, 'lr': 1.9449364089451818e-06, 'n_layers': 7, 'linear_0_out': 3, 'dropout_0': 0.39106768171220796, 'linear_1_out': 10, 'dropout_1': 0.2693759292218283, 'linear_2_out': 617, 'dropout_2': 0.39401768435015, 'linear_3_out': 59, 'dropout_3': 0.48792320665773636, 'linear_4_out': 60, 'dropout_4': 0.13939570834552772, 'linear_5_out': 14, 'dropout_5': 0.3718213619386351}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:12,201]\u001b[0m Trial 175 finished with value: 0.2809917355371901 and parameters: {'scaler': 0, 'batch_size': 87, 'loss_fn': 0, 'lr': 1.204955128052487e-06, 'n_layers': 4, 'linear_0_out': 51, 'dropout_0': 0.4548706339931349, 'linear_1_out': 26, 'dropout_1': 0.14426250143144637, 'linear_2_out': 104, 'dropout_2': 0.45734714977484725}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:20,209]\u001b[0m Trial 176 finished with value: 0.5743214589859327 and parameters: {'scaler': 1, 'batch_size': 55, 'loss_fn': 1, 'lr': 1.0956467544968874e-05, 'n_layers': 6, 'linear_0_out': 242, 'dropout_0': 0.2830118885576516, 'linear_1_out': 320, 'dropout_1': 0.1901574685562452, 'linear_2_out': 900, 'dropout_2': 0.09148779679197988, 'linear_3_out': 16, 'dropout_3': 0.3868388318851587, 'linear_4_out': 18, 'dropout_4': 0.3340773011850076}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:27,289]\u001b[0m Trial 177 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 47, 'loss_fn': 1, 'lr': 0.00018510786137737633, 'n_layers': 3, 'linear_0_out': 127, 'dropout_0': 0.01255476908857156, 'linear_1_out': 732, 'dropout_1': 0.09372237681817758}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:35,460]\u001b[0m Trial 178 finished with value: 0.5264970853206147 and parameters: {'scaler': 2, 'batch_size': 51, 'loss_fn': 2, 'lr': 0.00023280093710124152, 'n_layers': 8, 'linear_0_out': 74, 'dropout_0': 0.4124308368649186, 'linear_1_out': 45, 'dropout_1': 0.23259477523577782, 'linear_2_out': 58, 'dropout_2': 0.11845511261228547, 'linear_3_out': 1419, 'dropout_3': 0.1293753374392746, 'linear_4_out': 7, 'dropout_4': 0.12187589666579263, 'linear_5_out': 645, 'dropout_5': 0.3842728188381808, 'linear_6_out': 36, 'dropout_6': 0.006890952312291254}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:40,650]\u001b[0m Trial 179 finished with value: 0.5440000000000002 and parameters: {'scaler': 0, 'batch_size': 94, 'loss_fn': 0, 'lr': 1.3585400975441233e-05, 'n_layers': 3, 'linear_0_out': 312, 'dropout_0': 0.41325931624705525, 'linear_1_out': 181, 'dropout_1': 0.09304636565455104}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:44,835]\u001b[0m Trial 180 finished with value: 0.8331547776465218 and parameters: {'scaler': 1, 'batch_size': 37, 'loss_fn': 1, 'lr': 0.0008206887217492763, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:48,758]\u001b[0m Trial 181 finished with value: 0.7195275467102802 and parameters: {'scaler': 1, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.0005892855617619061, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:57:55,355]\u001b[0m Trial 182 finished with value: 0.4312393887945671 and parameters: {'scaler': 3, 'batch_size': 43, 'loss_fn': 0, 'lr': 0.00014251271704987523, 'n_layers': 8, 'linear_0_out': 4, 'dropout_0': 0.2809557289038645, 'linear_1_out': 18, 'dropout_1': 0.22942489102288777, 'linear_2_out': 35, 'dropout_2': 0.0523872021245943, 'linear_3_out': 5, 'dropout_3': 0.043404308071825104, 'linear_4_out': 6, 'dropout_4': 0.4262221932488728, 'linear_5_out': 2, 'dropout_5': 0.21580862514342802, 'linear_6_out': 571, 'dropout_6': 0.05012910226369505}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:58:02,933]\u001b[0m Trial 183 finished with value: 0.45280564845782234 and parameters: {'scaler': 1, 'batch_size': 18, 'loss_fn': 0, 'lr': 0.00024271975938257735, 'n_layers': 4, 'linear_0_out': 15, 'dropout_0': 0.1393360256551182, 'linear_1_out': 17, 'dropout_1': 0.1702937998538026, 'linear_2_out': 263, 'dropout_2': 0.12013110057563625}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:58:18,466]\u001b[0m Trial 184 finished with value: 0.5739971139971141 and parameters: {'scaler': 2, 'batch_size': 11, 'loss_fn': 1, 'lr': 0.0003047902841283019, 'n_layers': 8, 'linear_0_out': 107, 'dropout_0': 0.07250779471355595, 'linear_1_out': 265, 'dropout_1': 0.44767433192076106, 'linear_2_out': 10, 'dropout_2': 0.4793429478420041, 'linear_3_out': 458, 'dropout_3': 0.15016078738955618, 'linear_4_out': 146, 'dropout_4': 0.15392396604034725, 'linear_5_out': 3, 'dropout_5': 0.4120743348103427, 'linear_6_out': 210, 'dropout_6': 0.30700032564036095}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:58:24,537]\u001b[0m Trial 185 finished with value: 0.1037593984962406 and parameters: {'scaler': 2, 'batch_size': 5, 'loss_fn': 2, 'lr': 8.798819600157223e-05, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:58:34,192]\u001b[0m Trial 186 finished with value: 0.5241984271022383 and parameters: {'scaler': 2, 'batch_size': 62, 'loss_fn': 2, 'lr': 2.231435760481272e-06, 'n_layers': 10, 'linear_0_out': 2058, 'dropout_0': 0.2225008445447037, 'linear_1_out': 10, 'dropout_1': 0.4792972232626556, 'linear_2_out': 648, 'dropout_2': 0.362114302779116, 'linear_3_out': 46, 'dropout_3': 0.20528935072058607, 'linear_4_out': 487, 'dropout_4': 0.2598068388823133, 'linear_5_out': 202, 'dropout_5': 0.28309649080420596, 'linear_6_out': 296, 'dropout_6': 0.04705250203920047, 'linear_7_out': 25, 'dropout_7': 0.08354459425493255, 'linear_8_out': 9, 'dropout_8': 0.1004121382690904}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:58:40,171]\u001b[0m Trial 187 finished with value: 0.47619047619047616 and parameters: {'scaler': 2, 'batch_size': 6, 'loss_fn': 0, 'lr': 0.0003096785022928817, 'n_layers': 2, 'linear_0_out': 3, 'dropout_0': 0.02845322630191599}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:58:49,148]\u001b[0m Trial 188 finished with value: 0.4900000000000001 and parameters: {'scaler': 0, 'batch_size': 71, 'loss_fn': 1, 'lr': 2.2269109688411165e-05, 'n_layers': 9, 'linear_0_out': 14, 'dropout_0': 0.3429861949626156, 'linear_1_out': 39, 'dropout_1': 0.04807762715074415, 'linear_2_out': 22, 'dropout_2': 0.4206400331740538, 'linear_3_out': 2047, 'dropout_3': 0.4225408353080026, 'linear_4_out': 5, 'dropout_4': 0.1727546492245423, 'linear_5_out': 715, 'dropout_5': 0.2769479671978827, 'linear_6_out': 475, 'dropout_6': 0.38889163330839505, 'linear_7_out': 3, 'dropout_7': 0.17120328280051156}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 17:58:58,719]\u001b[0m Trial 189 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 10, 'loss_fn': 2, 'lr': 7.667217820113476e-06, 'n_layers': 4, 'linear_0_out': 157, 'dropout_0': 0.2525957775356895, 'linear_1_out': 6, 'dropout_1': 0.07236362442128969, 'linear_2_out': 57, 'dropout_2': 0.3896954782001402}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:10,695]\u001b[0m Trial 190 finished with value: 0.37362637362637363 and parameters: {'scaler': 1, 'batch_size': 1, 'loss_fn': 0, 'lr': 2.581484964093337e-05, 'n_layers': 10, 'linear_0_out': 2, 'dropout_0': 0.05764059136894417, 'linear_1_out': 24, 'dropout_1': 0.04255295405678605, 'linear_2_out': 3, 'dropout_2': 0.28343633967527254, 'linear_3_out': 7, 'dropout_3': 0.31326760527856473, 'linear_4_out': 1481, 'dropout_4': 0.4119411048515646, 'linear_5_out': 9, 'dropout_5': 0.04483146305566149, 'linear_6_out': 1728, 'dropout_6': 0.4972479656866624, 'linear_7_out': 24, 'dropout_7': 0.2303386305712805, 'linear_8_out': 4, 'dropout_8': 0.35509039638884066}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:13,356]\u001b[0m Trial 191 finished with value: 0.0047619047619047615 and parameters: {'scaler': 1, 'batch_size': 34, 'loss_fn': 0, 'lr': 0.00010411514947168541, 'n_layers': 7, 'linear_0_out': 174, 'dropout_0': 0.3102105523204355, 'linear_1_out': 78, 'dropout_1': 0.37887356271370654, 'linear_2_out': 23, 'dropout_2': 0.2376191693202508, 'linear_3_out': 29, 'dropout_3': 0.10460524556096373, 'linear_4_out': 16, 'dropout_4': 0.027507538804950327, 'linear_5_out': 17, 'dropout_5': 0.19529154646656455}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:15,841]\u001b[0m Trial 192 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 36, 'loss_fn': 1, 'lr': 2.328604337385943e-06, 'n_layers': 6, 'linear_0_out': 6, 'dropout_0': 0.029028160338846865, 'linear_1_out': 5, 'dropout_1': 0.20999740602457095, 'linear_2_out': 257, 'dropout_2': 0.32075044238563005, 'linear_3_out': 2, 'dropout_3': 0.396645326257043, 'linear_4_out': 18, 'dropout_4': 0.3398578454777849}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:19,490]\u001b[0m Trial 193 finished with value: 0.5326600793170666 and parameters: {'scaler': 3, 'batch_size': 19, 'loss_fn': 0, 'lr': 0.0006178542197824091, 'n_layers': 6, 'linear_0_out': 1111, 'dropout_0': 0.15329970082531957, 'linear_1_out': 708, 'dropout_1': 0.4708411667031412, 'linear_2_out': 28, 'dropout_2': 0.45206552559922347, 'linear_3_out': 18, 'dropout_3': 0.16229999956364555, 'linear_4_out': 2423, 'dropout_4': 0.47620522408867616}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:21,727]\u001b[0m Trial 194 finished with value: 0.42251815980629537 and parameters: {'scaler': 3, 'batch_size': 85, 'loss_fn': 0, 'lr': 3.913587237845502e-06, 'n_layers': 6, 'linear_0_out': 219, 'dropout_0': 0.3708943175618503, 'linear_1_out': 5, 'dropout_1': 0.26794399628553106, 'linear_2_out': 38, 'dropout_2': 0.10411210548890598, 'linear_3_out': 91, 'dropout_3': 0.13795686090322873, 'linear_4_out': 79, 'dropout_4': 0.10005467245043864}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:23,733]\u001b[0m Trial 195 finished with value: 0.6240956891051472 and parameters: {'scaler': 0, 'batch_size': 64, 'loss_fn': 1, 'lr': 6.640788826610823e-05, 'n_layers': 3, 'linear_0_out': 895, 'dropout_0': 0.40216645906023313, 'linear_1_out': 9, 'dropout_1': 0.45552425400305285}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:26,197]\u001b[0m Trial 196 finished with value: 0.5368937048503613 and parameters: {'scaler': 3, 'batch_size': 47, 'loss_fn': 2, 'lr': 1.0058490459127136e-05, 'n_layers': 2, 'linear_0_out': 592, 'dropout_0': 0.022534913695250403}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:29,018]\u001b[0m Trial 197 finished with value: 0.5079365079365079 and parameters: {'scaler': 3, 'batch_size': 70, 'loss_fn': 1, 'lr': 3.309747486515998e-06, 'n_layers': 3, 'linear_0_out': 937, 'dropout_0': 0.1684806633869107, 'linear_1_out': 42, 'dropout_1': 0.19556785606167326}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:33,845]\u001b[0m Trial 198 finished with value: 0.4801618478944061 and parameters: {'scaler': 1, 'batch_size': 28, 'loss_fn': 2, 'lr': 9.130072693436383e-05, 'n_layers': 10, 'linear_0_out': 206, 'dropout_0': 0.2625798649964994, 'linear_1_out': 33, 'dropout_1': 0.05277484213049016, 'linear_2_out': 52, 'dropout_2': 0.07755404658032189, 'linear_3_out': 113, 'dropout_3': 0.36512353880529197, 'linear_4_out': 1681, 'dropout_4': 0.1484264338439833, 'linear_5_out': 29, 'dropout_5': 0.09147596976266614, 'linear_6_out': 1011, 'dropout_6': 0.4120386122247114, 'linear_7_out': 471, 'dropout_7': 0.028645019274950667, 'linear_8_out': 93, 'dropout_8': 0.11750678101773454}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:37,849]\u001b[0m Trial 199 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 53, 'loss_fn': 1, 'lr': 1.0005005896259429e-06, 'n_layers': 9, 'linear_0_out': 33, 'dropout_0': 0.4537098994766778, 'linear_1_out': 60, 'dropout_1': 0.2155541472940824, 'linear_2_out': 13, 'dropout_2': 0.04084446879651937, 'linear_3_out': 15, 'dropout_3': 0.3042351325869208, 'linear_4_out': 430, 'dropout_4': 0.27041275882692184, 'linear_5_out': 416, 'dropout_5': 0.07887579582949372, 'linear_6_out': 114, 'dropout_6': 0.4413016135128552, 'linear_7_out': 8, 'dropout_7': 0.11383446919649515}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:41,681]\u001b[0m Trial 200 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 64, 'loss_fn': 1, 'lr': 0.00020938903106588417, 'n_layers': 9, 'linear_0_out': 911, 'dropout_0': 0.30576253886492155, 'linear_1_out': 141, 'dropout_1': 0.2248234494097029, 'linear_2_out': 2, 'dropout_2': 0.14959010973163123, 'linear_3_out': 2, 'dropout_3': 0.21889262442987656, 'linear_4_out': 819, 'dropout_4': 0.2984010088524106, 'linear_5_out': 225, 'dropout_5': 0.09400398588853748, 'linear_6_out': 10, 'dropout_6': 0.08156607648644726, 'linear_7_out': 778, 'dropout_7': 0.14015650649374628}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:43,889]\u001b[0m Trial 201 finished with value: 0.3520162011228777 and parameters: {'scaler': 0, 'batch_size': 34, 'loss_fn': 1, 'lr': 0.00020239864789966977, 'n_layers': 1}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:46,653]\u001b[0m Trial 202 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 44, 'loss_fn': 1, 'lr': 0.00010273011373943824, 'n_layers': 5, 'linear_0_out': 12, 'dropout_0': 0.37372199683203805, 'linear_1_out': 6, 'dropout_1': 0.0761189692815259, 'linear_2_out': 2, 'dropout_2': 0.430650178156351, 'linear_3_out': 58, 'dropout_3': 0.25835780466077274}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:49,638]\u001b[0m Trial 203 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 71, 'loss_fn': 1, 'lr': 1.2141266050266447e-06, 'n_layers': 5, 'linear_0_out': 3, 'dropout_0': 0.1610272136818458, 'linear_1_out': 2240, 'dropout_1': 0.42867712856052165, 'linear_2_out': 9, 'dropout_2': 0.1879812156563544, 'linear_3_out': 37, 'dropout_3': 0.3819341888500929}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:52,517]\u001b[0m Trial 204 finished with value: 0.4587719298245613 and parameters: {'scaler': 3, 'batch_size': 42, 'loss_fn': 0, 'lr': 0.0001319341321269011, 'n_layers': 6, 'linear_0_out': 16, 'dropout_0': 0.0762713843066754, 'linear_1_out': 83, 'dropout_1': 0.07107825113107413, 'linear_2_out': 1594, 'dropout_2': 0.2699453053053202, 'linear_3_out': 5, 'dropout_3': 0.3603212734584537, 'linear_4_out': 3, 'dropout_4': 0.38582239498701004}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:55,504]\u001b[0m Trial 205 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 28, 'loss_fn': 0, 'lr': 1.8758977181215423e-06, 'n_layers': 10, 'linear_0_out': 345, 'dropout_0': 0.2593639190797756, 'linear_1_out': 4, 'dropout_1': 0.08783828474414274, 'linear_2_out': 37, 'dropout_2': 0.18112941036610847, 'linear_3_out': 94, 'dropout_3': 0.03817198737860439, 'linear_4_out': 2, 'dropout_4': 0.2555515433450271, 'linear_5_out': 2, 'dropout_5': 0.02977597700508805, 'linear_6_out': 24, 'dropout_6': 0.03088953486740098, 'linear_7_out': 26, 'dropout_7': 0.12087525795471821, 'linear_8_out': 6, 'dropout_8': 0.20233991574313143}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:57,386]\u001b[0m Trial 206 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 94, 'loss_fn': 2, 'lr': 2.5837071032883567e-06, 'n_layers': 4, 'linear_0_out': 2, 'dropout_0': 0.1895340718910638, 'linear_1_out': 3, 'dropout_1': 0.280906455901148, 'linear_2_out': 175, 'dropout_2': 0.4935457683383479}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:00:59,245]\u001b[0m Trial 207 finished with value: 0.15767915581379816 and parameters: {'scaler': 2, 'batch_size': 62, 'loss_fn': 2, 'lr': 0.00039987341257384463, 'n_layers': 3, 'linear_0_out': 65, 'dropout_0': 0.4648871319455022, 'linear_1_out': 231, 'dropout_1': 0.33025955266037027}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:01,224]\u001b[0m Trial 208 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 32, 'loss_fn': 0, 'lr': 8.154076330408047e-06, 'n_layers': 3, 'linear_0_out': 3, 'dropout_0': 0.3128554532596294, 'linear_1_out': 64, 'dropout_1': 0.11742420537642306}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:04,687]\u001b[0m Trial 209 finished with value: 0.525402036987403 and parameters: {'scaler': 2, 'batch_size': 27, 'loss_fn': 2, 'lr': 5.323319149161415e-06, 'n_layers': 10, 'linear_0_out': 5, 'dropout_0': 0.12663072932982217, 'linear_1_out': 937, 'dropout_1': 0.21330416934591057, 'linear_2_out': 11, 'dropout_2': 0.34640688136008985, 'linear_3_out': 2, 'dropout_3': 0.4453025882892523, 'linear_4_out': 772, 'dropout_4': 0.04289851756621793, 'linear_5_out': 561, 'dropout_5': 0.48058522094159783, 'linear_6_out': 58, 'dropout_6': 0.2840766750630189, 'linear_7_out': 232, 'dropout_7': 0.1333634716080055, 'linear_8_out': 186, 'dropout_8': 0.23743375005147105}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:06,488]\u001b[0m Trial 210 finished with value: 0.40705128205128205 and parameters: {'scaler': 3, 'batch_size': 84, 'loss_fn': 2, 'lr': 9.875803204617612e-05, 'n_layers': 3, 'linear_0_out': 35, 'dropout_0': 0.019514569041797936, 'linear_1_out': 3, 'dropout_1': 0.28025595030959194}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:10,576]\u001b[0m Trial 211 finished with value: 0.062318840579710134 and parameters: {'scaler': 0, 'batch_size': 2, 'loss_fn': 2, 'lr': 8.936660175498316e-05, 'n_layers': 2, 'linear_0_out': 665, 'dropout_0': 0.21576886059079203}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:13,449]\u001b[0m Trial 212 finished with value: 0.5272775776977456 and parameters: {'scaler': 1, 'batch_size': 32, 'loss_fn': 0, 'lr': 4.4363591575703415e-06, 'n_layers': 6, 'linear_0_out': 523, 'dropout_0': 0.004871632618817623, 'linear_1_out': 141, 'dropout_1': 0.057940879337833096, 'linear_2_out': 133, 'dropout_2': 0.4184038177391245, 'linear_3_out': 8, 'dropout_3': 0.24775737623863386, 'linear_4_out': 468, 'dropout_4': 0.08778873962731032}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:15,910]\u001b[0m Trial 213 finished with value: 0.42251815980629537 and parameters: {'scaler': 1, 'batch_size': 85, 'loss_fn': 2, 'lr': 0.00014159695262470185, 'n_layers': 4, 'linear_0_out': 3, 'dropout_0': 0.06779844229144233, 'linear_1_out': 2060, 'dropout_1': 0.025858831170391228, 'linear_2_out': 294, 'dropout_2': 0.47184076421050164}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:19,240]\u001b[0m Trial 214 finished with value: 0.44397759103641465 and parameters: {'scaler': 1, 'batch_size': 86, 'loss_fn': 0, 'lr': 3.3714203430263777e-06, 'n_layers': 8, 'linear_0_out': 1036, 'dropout_0': 0.15933617609076434, 'linear_1_out': 191, 'dropout_1': 0.43820884894574624, 'linear_2_out': 2, 'dropout_2': 0.4278676310398775, 'linear_3_out': 105, 'dropout_3': 0.20700769238757555, 'linear_4_out': 72, 'dropout_4': 0.412031004030996, 'linear_5_out': 318, 'dropout_5': 0.2506324253411247, 'linear_6_out': 56, 'dropout_6': 0.44962885634769184}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:21,855]\u001b[0m Trial 215 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 57, 'loss_fn': 2, 'lr': 6.589842380831135e-06, 'n_layers': 5, 'linear_0_out': 18, 'dropout_0': 0.2552190880673247, 'linear_1_out': 8, 'dropout_1': 0.09903023915764159, 'linear_2_out': 348, 'dropout_2': 0.19286376868020327, 'linear_3_out': 8, 'dropout_3': 0.4292102007410801}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:30,665]\u001b[0m Trial 216 finished with value: 0.5235690235690235 and parameters: {'scaler': 2, 'batch_size': 57, 'loss_fn': 1, 'lr': 7.120593144375622e-06, 'n_layers': 10, 'linear_0_out': 309, 'dropout_0': 0.22466549848760609, 'linear_1_out': 350, 'dropout_1': 0.20669256160481642, 'linear_2_out': 31, 'dropout_2': 0.07820837711205691, 'linear_3_out': 72, 'dropout_3': 0.13133220709251392, 'linear_4_out': 165, 'dropout_4': 0.19930309141968228, 'linear_5_out': 845, 'dropout_5': 0.3856812955652618, 'linear_6_out': 4, 'dropout_6': 0.29554598159280754, 'linear_7_out': 299, 'dropout_7': 0.25722045580491276, 'linear_8_out': 3, 'dropout_8': 0.25162369706196774}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:41,908]\u001b[0m Trial 217 finished with value: 0.06923076923076923 and parameters: {'scaler': 2, 'batch_size': 24, 'loss_fn': 2, 'lr': 0.0008659304639583617, 'n_layers': 5, 'linear_0_out': 622, 'dropout_0': 0.08418386419490936, 'linear_1_out': 556, 'dropout_1': 0.48123357926686683, 'linear_2_out': 69, 'dropout_2': 0.1278599021039697, 'linear_3_out': 5, 'dropout_3': 0.45831341464193226}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:49,725]\u001b[0m Trial 218 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 77, 'loss_fn': 2, 'lr': 3.7267821424731736e-06, 'n_layers': 6, 'linear_0_out': 243, 'dropout_0': 0.3574881648130784, 'linear_1_out': 409, 'dropout_1': 0.1665750508170823, 'linear_2_out': 1043, 'dropout_2': 0.06585278122595045, 'linear_3_out': 12, 'dropout_3': 0.23435700028831258, 'linear_4_out': 121, 'dropout_4': 0.14764209082145824}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:01:54,675]\u001b[0m Trial 219 finished with value: 0.07777048220596608 and parameters: {'scaler': 0, 'batch_size': 97, 'loss_fn': 2, 'lr': 0.00025401698467769813, 'n_layers': 2, 'linear_0_out': 770, 'dropout_0': 0.3608047506256596}. Best is trial 86 with value: 0.9019613054121063.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:02:02,763]\u001b[0m Trial 220 finished with value: 0.9173732134823579 and parameters: {'scaler': 1, 'batch_size': 60, 'loss_fn': 1, 'lr': 0.000341741388163191, 'n_layers': 5, 'linear_0_out': 211, 'dropout_0': 0.40397171146131655, 'linear_1_out': 323, 'dropout_1': 0.39775029444446885, 'linear_2_out': 168, 'dropout_2': 0.4003903044524642, 'linear_3_out': 1273, 'dropout_3': 0.4522094207757908}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:02:12,145]\u001b[0m Trial 221 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 50, 'loss_fn': 1, 'lr': 4.582922074173489e-05, 'n_layers': 9, 'linear_0_out': 4, 'dropout_0': 0.16267609337043587, 'linear_1_out': 162, 'dropout_1': 0.17965063934356473, 'linear_2_out': 33, 'dropout_2': 0.16922544908001014, 'linear_3_out': 54, 'dropout_3': 0.18659797686365254, 'linear_4_out': 4, 'dropout_4': 0.09940639809933705, 'linear_5_out': 3, 'dropout_5': 0.2338285338595501, 'linear_6_out': 794, 'dropout_6': 0.04527554169259451, 'linear_7_out': 199, 'dropout_7': 0.21011158022675125}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:02:16,518]\u001b[0m Trial 222 finished with value: 0.5289143480632843 and parameters: {'scaler': 0, 'batch_size': 55, 'loss_fn': 1, 'lr': 3.8662611243805825e-05, 'n_layers': 2, 'linear_0_out': 2, 'dropout_0': 0.37397531012660495}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:02:42,453]\u001b[0m Trial 223 finished with value: 0.2636387888488729 and parameters: {'scaler': 0, 'batch_size': 32, 'loss_fn': 2, 'lr': 2.5453018850826866e-05, 'n_layers': 10, 'linear_0_out': 1059, 'dropout_0': 0.2503881539059274, 'linear_1_out': 157, 'dropout_1': 0.15727599962604305, 'linear_2_out': 14, 'dropout_2': 0.06510248110535127, 'linear_3_out': 86, 'dropout_3': 0.04083563254174338, 'linear_4_out': 41, 'dropout_4': 0.16086220996348843, 'linear_5_out': 529, 'dropout_5': 0.19072280689235926, 'linear_6_out': 1204, 'dropout_6': 0.09476521504538049, 'linear_7_out': 1494, 'dropout_7': 0.29664332230202767, 'linear_8_out': 4, 'dropout_8': 0.25107508524997046}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:02:52,619]\u001b[0m Trial 224 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 42, 'loss_fn': 0, 'lr': 2.188505859323783e-06, 'n_layers': 9, 'linear_0_out': 62, 'dropout_0': 0.4737860841150421, 'linear_1_out': 81, 'dropout_1': 0.3846128419474872, 'linear_2_out': 2033, 'dropout_2': 0.36467350496498113, 'linear_3_out': 109, 'dropout_3': 0.1833540698046638, 'linear_4_out': 2, 'dropout_4': 0.21627285457899004, 'linear_5_out': 32, 'dropout_5': 0.4115311288187769, 'linear_6_out': 6, 'dropout_6': 0.3713224259769243, 'linear_7_out': 2, 'dropout_7': 0.4431826640470998}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:00,708]\u001b[0m Trial 225 finished with value: 0.47452667814113597 and parameters: {'scaler': 0, 'batch_size': 59, 'loss_fn': 2, 'lr': 7.708229527852535e-06, 'n_layers': 7, 'linear_0_out': 35, 'dropout_0': 0.021369496510402874, 'linear_1_out': 144, 'dropout_1': 0.18185128291345148, 'linear_2_out': 2, 'dropout_2': 0.23613999053260126, 'linear_3_out': 3, 'dropout_3': 0.3140848288652279, 'linear_4_out': 75, 'dropout_4': 0.25017437158143485, 'linear_5_out': 1566, 'dropout_5': 0.44021368935809585}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:13,053]\u001b[0m Trial 226 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 12, 'loss_fn': 2, 'lr': 4.025774572771926e-05, 'n_layers': 4, 'linear_0_out': 569, 'dropout_0': 0.36557857292581664, 'linear_1_out': 247, 'dropout_1': 0.25133762372175156, 'linear_2_out': 2, 'dropout_2': 0.21401386453762622}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:17,563]\u001b[0m Trial 227 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 26, 'loss_fn': 2, 'lr': 1.2255212612005718e-06, 'n_layers': 1}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:22,748]\u001b[0m Trial 228 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 84, 'loss_fn': 0, 'lr': 6.827602173594579e-05, 'n_layers': 4, 'linear_0_out': 2, 'dropout_0': 0.31800924810896436, 'linear_1_out': 2, 'dropout_1': 0.055139974246444456, 'linear_2_out': 5, 'dropout_2': 0.07163895574091017}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:34,983]\u001b[0m Trial 229 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 15, 'loss_fn': 2, 'lr': 1.3012106995134795e-06, 'n_layers': 9, 'linear_0_out': 5, 'dropout_0': 0.46281736794275213, 'linear_1_out': 17, 'dropout_1': 0.2553915190972282, 'linear_2_out': 2, 'dropout_2': 0.3645694551811292, 'linear_3_out': 7, 'dropout_3': 0.4583083712550129, 'linear_4_out': 203, 'dropout_4': 0.14180957276548584, 'linear_5_out': 10, 'dropout_5': 0.08523960663950914, 'linear_6_out': 575, 'dropout_6': 0.2192383744973183, 'linear_7_out': 12, 'dropout_7': 0.4764097560600322}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:42,254]\u001b[0m Trial 230 finished with value: 0.49856321839080475 and parameters: {'scaler': 2, 'batch_size': 68, 'loss_fn': 2, 'lr': 0.00021932027013156765, 'n_layers': 6, 'linear_0_out': 379, 'dropout_0': 0.2341658334586616, 'linear_1_out': 12, 'dropout_1': 0.02031701998585006, 'linear_2_out': 228, 'dropout_2': 0.07129571730557904, 'linear_3_out': 45, 'dropout_3': 0.3333772714547239, 'linear_4_out': 1116, 'dropout_4': 0.3046818186273671}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:51,237]\u001b[0m Trial 231 finished with value: 0.753968253968254 and parameters: {'scaler': 2, 'batch_size': 74, 'loss_fn': 2, 'lr': 4.723017059769158e-06, 'n_layers': 6, 'linear_0_out': 1140, 'dropout_0': 0.35207575543638625, 'linear_1_out': 597, 'dropout_1': 0.1110465111584229, 'linear_2_out': 105, 'dropout_2': 0.16202135773588117, 'linear_3_out': 199, 'dropout_3': 0.2613048234411, 'linear_4_out': 155, 'dropout_4': 0.30883501216865666}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:03:58,362]\u001b[0m Trial 232 finished with value: 0.4942989214175654 and parameters: {'scaler': 3, 'batch_size': 41, 'loss_fn': 1, 'lr': 1.8241536995133073e-05, 'n_layers': 6, 'linear_0_out': 8, 'dropout_0': 0.2065651638595144, 'linear_1_out': 29, 'dropout_1': 0.377020219708536, 'linear_2_out': 37, 'dropout_2': 0.37743564425597836, 'linear_3_out': 527, 'dropout_3': 0.1928099308053255, 'linear_4_out': 39, 'dropout_4': 0.26035799690932754}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:04:19,251]\u001b[0m Trial 233 finished with value: 0.48948458948458945 and parameters: {'scaler': 2, 'batch_size': 8, 'loss_fn': 0, 'lr': 3.051018805838188e-06, 'n_layers': 9, 'linear_0_out': 144, 'dropout_0': 0.03199113109324331, 'linear_1_out': 175, 'dropout_1': 0.44609910554626764, 'linear_2_out': 347, 'dropout_2': 0.057601153836394636, 'linear_3_out': 208, 'dropout_3': 0.30535134022930055, 'linear_4_out': 162, 'dropout_4': 0.3975810653482691, 'linear_5_out': 14, 'dropout_5': 0.17773426367297562, 'linear_6_out': 7, 'dropout_6': 0.22858804153953255, 'linear_7_out': 31, 'dropout_7': 0.04205092162613555}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:04:28,124]\u001b[0m Trial 234 finished with value: 0.0560440950573778 and parameters: {'scaler': 2, 'batch_size': 33, 'loss_fn': 0, 'lr': 0.0006809076803553373, 'n_layers': 5, 'linear_0_out': 1055, 'dropout_0': 0.2889270025585048, 'linear_1_out': 30, 'dropout_1': 0.1730360371650504, 'linear_2_out': 1221, 'dropout_2': 0.2826226788915535, 'linear_3_out': 10, 'dropout_3': 0.25973443046819433}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:04:36,866]\u001b[0m Trial 235 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 79, 'loss_fn': 2, 'lr': 1.1192048884620058e-06, 'n_layers': 4, 'linear_0_out': 15, 'dropout_0': 0.2717258475537573, 'linear_1_out': 1146, 'dropout_1': 0.02025836807234832, 'linear_2_out': 779, 'dropout_2': 0.27856390290080857}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:04:51,347]\u001b[0m Trial 236 finished with value: 0.5307953826691968 and parameters: {'scaler': 1, 'batch_size': 24, 'loss_fn': 2, 'lr': 1.4425059705120416e-06, 'n_layers': 5, 'linear_0_out': 1426, 'dropout_0': 0.23129638710494344, 'linear_1_out': 646, 'dropout_1': 0.055989903392431595, 'linear_2_out': 13, 'dropout_2': 0.36769844459301637, 'linear_3_out': 151, 'dropout_3': 0.22157633127897575}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:04:59,004]\u001b[0m Trial 237 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 65, 'loss_fn': 1, 'lr': 1.7043899789564362e-05, 'n_layers': 10, 'linear_0_out': 2, 'dropout_0': 0.16598554532115828, 'linear_1_out': 753, 'dropout_1': 0.22572417463862465, 'linear_2_out': 20, 'dropout_2': 0.2939082070585839, 'linear_3_out': 30, 'dropout_3': 0.16475180802322248, 'linear_4_out': 11, 'dropout_4': 0.15652273609325407, 'linear_5_out': 1425, 'dropout_5': 0.47983646572471855, 'linear_6_out': 3, 'dropout_6': 0.3677069414345731, 'linear_7_out': 197, 'dropout_7': 0.315484332702079, 'linear_8_out': 2, 'dropout_8': 0.13672695780885002}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:07,357]\u001b[0m Trial 238 finished with value: 0.7770750988142292 and parameters: {'scaler': 0, 'batch_size': 85, 'loss_fn': 1, 'lr': 2.517113327212761e-05, 'n_layers': 3, 'linear_0_out': 926, 'dropout_0': 0.3999285876609139, 'linear_1_out': 909, 'dropout_1': 0.11297248284630718}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:10,778]\u001b[0m Trial 239 finished with value: 0.5271213748657358 and parameters: {'scaler': 3, 'batch_size': 53, 'loss_fn': 0, 'lr': 4.104430749439448e-05, 'n_layers': 9, 'linear_0_out': 54, 'dropout_0': 0.29635412203675965, 'linear_1_out': 2, 'dropout_1': 0.4823269964175359, 'linear_2_out': 58, 'dropout_2': 0.08013521435208831, 'linear_3_out': 19, 'dropout_3': 0.25665366995295125, 'linear_4_out': 4, 'dropout_4': 0.09832341226227742, 'linear_5_out': 1340, 'dropout_5': 0.4362762950859943, 'linear_6_out': 4, 'dropout_6': 0.13949895270128354, 'linear_7_out': 167, 'dropout_7': 0.12987682386568067}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:13,698]\u001b[0m Trial 240 finished with value: 0.07019243156199677 and parameters: {'scaler': 1, 'batch_size': 29, 'loss_fn': 0, 'lr': 0.0007988680566741309, 'n_layers': 8, 'linear_0_out': 1603, 'dropout_0': 0.28576996516194364, 'linear_1_out': 17, 'dropout_1': 0.08196342507406973, 'linear_2_out': 54, 'dropout_2': 0.24669925520623365, 'linear_3_out': 480, 'dropout_3': 0.2642197417639815, 'linear_4_out': 6, 'dropout_4': 0.4070953513922035, 'linear_5_out': 4, 'dropout_5': 0.2644570054006256, 'linear_6_out': 2, 'dropout_6': 0.18459047204961465}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:19,691]\u001b[0m Trial 241 finished with value: 0.5440000000000002 and parameters: {'scaler': 0, 'batch_size': 91, 'loss_fn': 0, 'lr': 6.711597759380588e-06, 'n_layers': 8, 'linear_0_out': 10, 'dropout_0': 0.30471464589060093, 'linear_1_out': 3, 'dropout_1': 0.10107270979322708, 'linear_2_out': 148, 'dropout_2': 0.04906937691480878, 'linear_3_out': 303, 'dropout_3': 0.22455010128587594, 'linear_4_out': 12, 'dropout_4': 0.4369501261323273, 'linear_5_out': 221, 'dropout_5': 0.03209219117705914, 'linear_6_out': 216, 'dropout_6': 0.09918961829552353}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:33,790]\u001b[0m Trial 242 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 95, 'loss_fn': 1, 'lr': 2.742307600083004e-05, 'n_layers': 7, 'linear_0_out': 456, 'dropout_0': 0.2785337469139208, 'linear_1_out': 277, 'dropout_1': 0.4295407523648759, 'linear_2_out': 14, 'dropout_2': 0.17008346696526405, 'linear_3_out': 2, 'dropout_3': 0.27713090643270977, 'linear_4_out': 2024, 'dropout_4': 0.36805134965043335, 'linear_5_out': 2367, 'dropout_5': 0.22717603817865994}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:36,072]\u001b[0m Trial 243 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 46, 'loss_fn': 2, 'lr': 1.5331376951348715e-05, 'n_layers': 5, 'linear_0_out': 860, 'dropout_0': 0.13469541517224587, 'linear_1_out': 145, 'dropout_1': 0.42288527841919293, 'linear_2_out': 598, 'dropout_2': 0.11936183322275756, 'linear_3_out': 2, 'dropout_3': 0.13841389516676272}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:38,394]\u001b[0m Trial 244 finished with value: 0.34399450926561426 and parameters: {'scaler': 3, 'batch_size': 66, 'loss_fn': 2, 'lr': 0.00018075857861794332, 'n_layers': 7, 'linear_0_out': 865, 'dropout_0': 0.13193351231134914, 'linear_1_out': 63, 'dropout_1': 0.2442187018722662, 'linear_2_out': 16, 'dropout_2': 0.3432104933110286, 'linear_3_out': 4, 'dropout_3': 0.40257456635721756, 'linear_4_out': 2, 'dropout_4': 0.19408992449136714, 'linear_5_out': 136, 'dropout_5': 0.21218204353259706}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:40,987]\u001b[0m Trial 245 finished with value: 0.4170807262912525 and parameters: {'scaler': 2, 'batch_size': 29, 'loss_fn': 0, 'lr': 0.00035946100764623916, 'n_layers': 8, 'linear_0_out': 358, 'dropout_0': 0.34464810155471787, 'linear_1_out': 3, 'dropout_1': 0.1493287171399335, 'linear_2_out': 2, 'dropout_2': 0.03026051039138744, 'linear_3_out': 2, 'dropout_3': 0.09946700216354237, 'linear_4_out': 2, 'dropout_4': 0.008441892214502922, 'linear_5_out': 9, 'dropout_5': 0.39942696178276665, 'linear_6_out': 2, 'dropout_6': 0.4922746171589249}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:42,738]\u001b[0m Trial 246 finished with value: 0.03137254901960784 and parameters: {'scaler': 1, 'batch_size': 31, 'loss_fn': 1, 'lr': 3.288438870476337e-05, 'n_layers': 2, 'linear_0_out': 8, 'dropout_0': 0.2748625561207103}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:45,008]\u001b[0m Trial 247 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 96, 'loss_fn': 2, 'lr': 0.00036350287792515453, 'n_layers': 8, 'linear_0_out': 14, 'dropout_0': 0.43628167876479224, 'linear_1_out': 2, 'dropout_1': 0.2467334700460574, 'linear_2_out': 193, 'dropout_2': 0.15609715718760914, 'linear_3_out': 3, 'dropout_3': 0.1285801546847647, 'linear_4_out': 54, 'dropout_4': 0.15905318003554408, 'linear_5_out': 33, 'dropout_5': 0.046562308857428014, 'linear_6_out': 2, 'dropout_6': 0.43880632379334483}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:46,626]\u001b[0m Trial 248 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 33, 'loss_fn': 0, 'lr': 1.679148127478417e-05, 'n_layers': 1}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:51,239]\u001b[0m Trial 249 finished with value: 0.4942989214175654 and parameters: {'scaler': 0, 'batch_size': 41, 'loss_fn': 2, 'lr': 1.635217140448484e-05, 'n_layers': 8, 'linear_0_out': 5, 'dropout_0': 0.2668405382491494, 'linear_1_out': 58, 'dropout_1': 0.29561597335217593, 'linear_2_out': 233, 'dropout_2': 0.4305097209072986, 'linear_3_out': 8, 'dropout_3': 0.19076705532912985, 'linear_4_out': 2, 'dropout_4': 0.31209063994387065, 'linear_5_out': 1541, 'dropout_5': 0.19809855436332097, 'linear_6_out': 2028, 'dropout_6': 0.2989376223340654}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:52,753]\u001b[0m Trial 250 finished with value: 0.6980123115486896 and parameters: {'scaler': 1, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.0004947567950209343, 'n_layers': 1}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:54,548]\u001b[0m Trial 251 finished with value: 0.34616109054344346 and parameters: {'scaler': 1, 'batch_size': 21, 'loss_fn': 1, 'lr': 0.0005664464090455539, 'n_layers': 2, 'linear_0_out': 7, 'dropout_0': 0.26476451262620526}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:57,023]\u001b[0m Trial 252 finished with value: 0.2510342009558749 and parameters: {'scaler': 2, 'batch_size': 88, 'loss_fn': 1, 'lr': 0.00045578787661787684, 'n_layers': 7, 'linear_0_out': 173, 'dropout_0': 0.3331364161864422, 'linear_1_out': 171, 'dropout_1': 0.09480698466922799, 'linear_2_out': 7, 'dropout_2': 0.12073152542079874, 'linear_3_out': 345, 'dropout_3': 0.2496772620762836, 'linear_4_out': 218, 'dropout_4': 0.39968170521035745, 'linear_5_out': 99, 'dropout_5': 0.23557052045880944}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:05:58,986]\u001b[0m Trial 253 finished with value: 0.3591549696404327 and parameters: {'scaler': 1, 'batch_size': 90, 'loss_fn': 1, 'lr': 0.00046929753876704636, 'n_layers': 2, 'linear_0_out': 30, 'dropout_0': 0.26813143504878373}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:06:27,290]\u001b[0m Trial 254 finished with value: 0.5440000000000002 and parameters: {'scaler': 3, 'batch_size': 94, 'loss_fn': 2, 'lr': 0.0004507048041377333, 'n_layers': 10, 'linear_0_out': 5, 'dropout_0': 0.39322275137238577, 'linear_1_out': 1309, 'dropout_1': 0.40618251802524624, 'linear_2_out': 667, 'dropout_2': 0.41470070632219436, 'linear_3_out': 6, 'dropout_3': 0.49790636474163663, 'linear_4_out': 197, 'dropout_4': 0.2104635320399486, 'linear_5_out': 1090, 'dropout_5': 0.29117563649461364, 'linear_6_out': 2385, 'dropout_6': 0.37603684722510206, 'linear_7_out': 23, 'dropout_7': 0.37128111265125, 'linear_8_out': 338, 'dropout_8': 0.15649538888839887}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:06:37,328]\u001b[0m Trial 255 finished with value: 0.5440000000000002 and parameters: {'scaler': 2, 'batch_size': 98, 'loss_fn': 2, 'lr': 3.45564490067905e-05, 'n_layers': 9, 'linear_0_out': 1059, 'dropout_0': 0.0703824581836468, 'linear_1_out': 23, 'dropout_1': 0.31813709551390423, 'linear_2_out': 52, 'dropout_2': 0.33907794879295566, 'linear_3_out': 2452, 'dropout_3': 0.03899831853055635, 'linear_4_out': 418, 'dropout_4': 0.4087122542754676, 'linear_5_out': 12, 'dropout_5': 0.1275780262030699, 'linear_6_out': 40, 'dropout_6': 0.19692837879664438, 'linear_7_out': 65, 'dropout_7': 0.10579210077112938}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:06:44,369]\u001b[0m Trial 256 finished with value: 0.5025960539979231 and parameters: {'scaler': 0, 'batch_size': 77, 'loss_fn': 0, 'lr': 3.3577992175822097e-06, 'n_layers': 10, 'linear_0_out': 58, 'dropout_0': 0.40637621140351354, 'linear_1_out': 1049, 'dropout_1': 0.3333811312342838, 'linear_2_out': 13, 'dropout_2': 0.43662255917087545, 'linear_3_out': 34, 'dropout_3': 0.11590359513244242, 'linear_4_out': 4, 'dropout_4': 0.4808344289714017, 'linear_5_out': 3, 'dropout_5': 0.2648802324673639, 'linear_6_out': 7, 'dropout_6': 0.43414019773100204, 'linear_7_out': 6, 'dropout_7': 0.3682398796918965, 'linear_8_out': 5, 'dropout_8': 0.4690561243483062}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:06:53,152]\u001b[0m Trial 257 finished with value: 0.5440000000000002 and parameters: {'scaler': 2, 'batch_size': 98, 'loss_fn': 2, 'lr': 6.812458286106508e-05, 'n_layers': 10, 'linear_0_out': 206, 'dropout_0': 0.20756043248385025, 'linear_1_out': 1893, 'dropout_1': 0.26202543077899354, 'linear_2_out': 26, 'dropout_2': 0.08123775170387276, 'linear_3_out': 316, 'dropout_3': 0.29816647189479056, 'linear_4_out': 8, 'dropout_4': 0.1249809173244606, 'linear_5_out': 8, 'dropout_5': 0.24792093249089686, 'linear_6_out': 2, 'dropout_6': 0.1446237422788344, 'linear_7_out': 354, 'dropout_7': 0.3106149516663374, 'linear_8_out': 651, 'dropout_8': 0.37241247745789635}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:06:57,661]\u001b[0m Trial 258 finished with value: 0.5410890697691186 and parameters: {'scaler': 2, 'batch_size': 23, 'loss_fn': 1, 'lr': 4.764090406471331e-05, 'n_layers': 2, 'linear_0_out': 2, 'dropout_0': 0.28478456705612054}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:16,397]\u001b[0m Trial 259 finished with value: 0.5166883116883116 and parameters: {'scaler': 2, 'batch_size': 9, 'loss_fn': 1, 'lr': 0.0001872965816662698, 'n_layers': 9, 'linear_0_out': 39, 'dropout_0': 0.18065002188620027, 'linear_1_out': 2363, 'dropout_1': 0.32848168537762246, 'linear_2_out': 10, 'dropout_2': 0.26643302935233265, 'linear_3_out': 3, 'dropout_3': 0.372636639888895, 'linear_4_out': 20, 'dropout_4': 0.08444168641941796, 'linear_5_out': 5, 'dropout_5': 0.007614432685115802, 'linear_6_out': 481, 'dropout_6': 0.36434993784722064, 'linear_7_out': 55, 'dropout_7': 0.15298237795196712}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:21,427]\u001b[0m Trial 260 finished with value: 0.27868852459016397 and parameters: {'scaler': 1, 'batch_size': 88, 'loss_fn': 1, 'lr': 0.0004558657023567956, 'n_layers': 5, 'linear_0_out': 27, 'dropout_0': 0.44204424597025427, 'linear_1_out': 4, 'dropout_1': 0.014782370063103012, 'linear_2_out': 7, 'dropout_2': 0.26034281665690745, 'linear_3_out': 2, 'dropout_3': 0.052132367071717756}. Best is trial 220 with value: 0.9173732134823579.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:29,263]\u001b[0m Trial 261 finished with value: 0.9300776397515527 and parameters: {'scaler': 0, 'batch_size': 53, 'loss_fn': 1, 'lr': 0.0008932524622143947, 'n_layers': 3, 'linear_0_out': 266, 'dropout_0': 0.22403142856094682, 'linear_1_out': 1708, 'dropout_1': 0.4553832838013057}. Best is trial 261 with value: 0.9300776397515527.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:33,452]\u001b[0m Trial 262 finished with value: 0.7163036855680984 and parameters: {'scaler': 1, 'batch_size': 57, 'loss_fn': 1, 'lr': 0.0009178644783827155, 'n_layers': 2, 'linear_0_out': 12, 'dropout_0': 0.18885796502949792}. Best is trial 261 with value: 0.9300776397515527.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:40,405]\u001b[0m Trial 263 finished with value: 0.9636566079690448 and parameters: {'scaler': 1, 'batch_size': 52, 'loss_fn': 1, 'lr': 0.0008784548258895558, 'n_layers': 4, 'linear_0_out': 1363, 'dropout_0': 0.2896287973587466, 'linear_1_out': 23, 'dropout_1': 0.40020335267747487, 'linear_2_out': 1428, 'dropout_2': 0.33674653235178925}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:45,802]\u001b[0m Trial 264 finished with value: 0.0 and parameters: {'scaler': 0, 'batch_size': 63, 'loss_fn': 1, 'lr': 0.000566491632571385, 'n_layers': 4, 'linear_0_out': 8, 'dropout_0': 0.4096302579228663, 'linear_1_out': 34, 'dropout_1': 0.3490232899562367, 'linear_2_out': 55, 'dropout_2': 0.4704324522087188}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:49,843]\u001b[0m Trial 265 finished with value: 0.5949758204299094 and parameters: {'scaler': 1, 'batch_size': 61, 'loss_fn': 1, 'lr': 0.0006171308477512409, 'n_layers': 2, 'linear_0_out': 2, 'dropout_0': 0.07789835220375196}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:07:54,410]\u001b[0m Trial 266 finished with value: 0.6268312826012157 and parameters: {'scaler': 1, 'batch_size': 52, 'loss_fn': 1, 'lr': 0.000508779125129061, 'n_layers': 2, 'linear_0_out': 6, 'dropout_0': 0.11050025332975061}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:00,575]\u001b[0m Trial 267 finished with value: 0.7892217042424031 and parameters: {'scaler': 1, 'batch_size': 48, 'loss_fn': 1, 'lr': 0.0007275885839076425, 'n_layers': 5, 'linear_0_out': 9, 'dropout_0': 0.07642510242786665, 'linear_1_out': 256, 'dropout_1': 0.10907787413390407, 'linear_2_out': 9, 'dropout_2': 0.09869413111105702, 'linear_3_out': 29, 'dropout_3': 0.4792965514931741}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:04,672]\u001b[0m Trial 268 finished with value: 0.7762154297616484 and parameters: {'scaler': 1, 'batch_size': 57, 'loss_fn': 1, 'lr': 0.0007980150854471295, 'n_layers': 1}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:09,843]\u001b[0m Trial 269 finished with value: 0.7619819234605248 and parameters: {'scaler': 1, 'batch_size': 51, 'loss_fn': 1, 'lr': 0.0005969793171285404, 'n_layers': 2, 'linear_0_out': 23, 'dropout_0': 0.14881208983206912}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:13,802]\u001b[0m Trial 270 finished with value: 0.5881637240013431 and parameters: {'scaler': 1, 'batch_size': 58, 'loss_fn': 1, 'lr': 0.0003054927362853932, 'n_layers': 1}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:18,278]\u001b[0m Trial 271 finished with value: 0.6804968531936502 and parameters: {'scaler': 1, 'batch_size': 54, 'loss_fn': 1, 'lr': 0.0009972162241510027, 'n_layers': 2, 'linear_0_out': 2, 'dropout_0': 0.17626376581961645}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:22,161]\u001b[0m Trial 272 finished with value: 0.7746729803100708 and parameters: {'scaler': 1, 'batch_size': 65, 'loss_fn': 1, 'lr': 0.0009534562270366233, 'n_layers': 1}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:26,427]\u001b[0m Trial 273 finished with value: 0.37838417010830805 and parameters: {'scaler': 1, 'batch_size': 63, 'loss_fn': 1, 'lr': 0.0006782954258052774, 'n_layers': 3, 'linear_0_out': 8, 'dropout_0': 0.3814636690108342, 'linear_1_out': 3, 'dropout_1': 0.07184052097710253}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:30,290]\u001b[0m Trial 274 finished with value: 0.4866557151365665 and parameters: {'scaler': 1, 'batch_size': 64, 'loss_fn': 1, 'lr': 0.00023484158495328943, 'n_layers': 1}. Best is trial 263 with value: 0.9636566079690448.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:42,427]\u001b[0m Trial 275 finished with value: 0.9675118532261389 and parameters: {'scaler': 1, 'batch_size': 13, 'loss_fn': 1, 'lr': 0.0009415413257581411, 'n_layers': 5, 'linear_0_out': 453, 'dropout_0': 0.4727775680279816, 'linear_1_out': 12, 'dropout_1': 0.14401341466765255, 'linear_2_out': 800, 'dropout_2': 0.39564182822524363, 'linear_3_out': 110, 'dropout_3': 0.1442943394300233}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:49,023]\u001b[0m Trial 276 finished with value: 0.6859130749073824 and parameters: {'scaler': 0, 'batch_size': 30, 'loss_fn': 1, 'lr': 0.0009898137698896225, 'n_layers': 3, 'linear_0_out': 125, 'dropout_0': 0.4230976076671306, 'linear_1_out': 16, 'dropout_1': 0.29610913749132234}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:08:58,585]\u001b[0m Trial 277 finished with value: 0.9580022362435878 and parameters: {'scaler': 1, 'batch_size': 24, 'loss_fn': 1, 'lr': 0.0005109587595267847, 'n_layers': 5, 'linear_0_out': 413, 'dropout_0': 0.4837192123461728, 'linear_1_out': 363, 'dropout_1': 0.1920490275542247, 'linear_2_out': 66, 'dropout_2': 0.444016568266347, 'linear_3_out': 186, 'dropout_3': 0.26777506602095}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:09:03,002]\u001b[0m Trial 278 finished with value: 0.8868035689800395 and parameters: {'scaler': 2, 'batch_size': 19, 'loss_fn': 1, 'lr': 0.0005929202628111649, 'n_layers': 1}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:09:06,893]\u001b[0m Trial 279 finished with value: 0.5509865274557382 and parameters: {'scaler': 2, 'batch_size': 51, 'loss_fn': 1, 'lr': 0.0002624582022611575, 'n_layers': 1}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:09:15,051]\u001b[0m Trial 280 finished with value: 0.7347229105753132 and parameters: {'scaler': 1, 'batch_size': 25, 'loss_fn': 1, 'lr': 0.0005405847695764104, 'n_layers': 5, 'linear_0_out': 839, 'dropout_0': 0.4327029893667593, 'linear_1_out': 3, 'dropout_1': 0.08800760588895551, 'linear_2_out': 7, 'dropout_2': 0.3115741462261473, 'linear_3_out': 3, 'dropout_3': 0.01449743499081324}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:09:26,427]\u001b[0m Trial 281 finished with value: 0.9518279722227089 and parameters: {'scaler': 1, 'batch_size': 16, 'loss_fn': 1, 'lr': 0.00038834407266058425, 'n_layers': 5, 'linear_0_out': 900, 'dropout_0': 0.4886995412855948, 'linear_1_out': 22, 'dropout_1': 0.3594295892544038, 'linear_2_out': 257, 'dropout_2': 0.3963351759751946, 'linear_3_out': 263, 'dropout_3': 0.30664278930073097}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:09:37,787]\u001b[0m Trial 282 finished with value: 0.8463382928929146 and parameters: {'scaler': 1, 'batch_size': 14, 'loss_fn': 1, 'lr': 0.00037085182179027055, 'n_layers': 5, 'linear_0_out': 977, 'dropout_0': 0.46889773449874533, 'linear_1_out': 55, 'dropout_1': 0.10424916024398528, 'linear_2_out': 102, 'dropout_2': 0.31831237410417057, 'linear_3_out': 4, 'dropout_3': 0.2825736693015674}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:09:46,595]\u001b[0m Trial 283 finished with value: 0.4252312716523242 and parameters: {'scaler': 1, 'batch_size': 20, 'loss_fn': 1, 'lr': 0.0003360464300997909, 'n_layers': 5, 'linear_0_out': 858, 'dropout_0': 0.4840810565844369, 'linear_1_out': 3, 'dropout_1': 0.2735384011532459, 'linear_2_out': 5, 'dropout_2': 0.05950677360416651, 'linear_3_out': 3, 'dropout_3': 0.45551265641545347}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:14,762]\u001b[0m Trial 284 finished with value: 0.9567162375521507 and parameters: {'scaler': 2, 'batch_size': 16, 'loss_fn': 1, 'lr': 0.0003250372469998563, 'n_layers': 3, 'linear_0_out': 669, 'dropout_0': 0.4859424395693867, 'linear_1_out': 127, 'dropout_1': 0.1250793611010695}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:16,849]\u001b[0m Trial 285 finished with value: 0.9190791747934606 and parameters: {'scaler': 2, 'batch_size': 13, 'loss_fn': 1, 'lr': 0.0008263103934394867, 'n_layers': 1}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:20,598]\u001b[0m Trial 286 finished with value: 0.864848484848485 and parameters: {'scaler': 2, 'batch_size': 9, 'loss_fn': 1, 'lr': 0.0004302421056804958, 'n_layers': 3, 'linear_0_out': 519, 'dropout_0': 0.49638758104835995, 'linear_1_out': 3, 'dropout_1': 0.2680907092560513}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:22,714]\u001b[0m Trial 287 finished with value: 0.8046825396825398 and parameters: {'scaler': 2, 'batch_size': 9, 'loss_fn': 1, 'lr': 0.0002886979383445457, 'n_layers': 1}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:24,531]\u001b[0m Trial 288 finished with value: 0.759846119824448 and parameters: {'scaler': 2, 'batch_size': 22, 'loss_fn': 1, 'lr': 0.0004990036542929513, 'n_layers': 2, 'linear_0_out': 533, 'dropout_0': 0.48394808487288044}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:26,966]\u001b[0m Trial 289 finished with value: 0.8044277360066833 and parameters: {'scaler': 2, 'batch_size': 5, 'loss_fn': 1, 'lr': 0.0007187584730586964, 'n_layers': 1}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:30,390]\u001b[0m Trial 290 finished with value: 0.689247311827957 and parameters: {'scaler': 2, 'batch_size': 3, 'loss_fn': 1, 'lr': 0.0005089748780386005, 'n_layers': 2, 'linear_0_out': 920, 'dropout_0': 0.4952004327743646}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:32,476]\u001b[0m Trial 291 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 9, 'loss_fn': 1, 'lr': 0.0005620032880140922, 'n_layers': 1}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:34,736]\u001b[0m Trial 292 finished with value: 0.7723832960984663 and parameters: {'scaler': 2, 'batch_size': 22, 'loss_fn': 1, 'lr': 0.00027680194637174575, 'n_layers': 3, 'linear_0_out': 2318, 'dropout_0': 0.4812513475758473, 'linear_1_out': 4, 'dropout_1': 0.38920146720225035}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:36,710]\u001b[0m Trial 293 finished with value: 0.7389616402116402 and parameters: {'scaler': 0, 'batch_size': 8, 'loss_fn': 1, 'lr': 0.0007342754812895233, 'n_layers': 1}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:38,660]\u001b[0m Trial 294 finished with value: 0.9601307005015446 and parameters: {'scaler': 2, 'batch_size': 38, 'loss_fn': 1, 'lr': 0.0005870297372779362, 'n_layers': 3, 'linear_0_out': 696, 'dropout_0': 0.4827521083275415, 'linear_1_out': 60, 'dropout_1': 0.3632244424286699}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:40,531]\u001b[0m Trial 295 finished with value: 0.7061976325617965 and parameters: {'scaler': 2, 'batch_size': 29, 'loss_fn': 1, 'lr': 0.00042781045684505575, 'n_layers': 2, 'linear_0_out': 1234, 'dropout_0': 0.49490784359311313}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:43,107]\u001b[0m Trial 296 finished with value: 0.9580207537560478 and parameters: {'scaler': 2, 'batch_size': 14, 'loss_fn': 1, 'lr': 0.00047382435150700246, 'n_layers': 4, 'linear_0_out': 1106, 'dropout_0': 0.4772286315609409, 'linear_1_out': 28, 'dropout_1': 0.3511613723101803, 'linear_2_out': 241, 'dropout_2': 0.28070810403785174}. Best is trial 275 with value: 0.9675118532261389.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:45,747]\u001b[0m Trial 297 finished with value: 0.969312263625989 and parameters: {'scaler': 2, 'batch_size': 41, 'loss_fn': 1, 'lr': 0.0007663412399078748, 'n_layers': 5, 'linear_0_out': 399, 'dropout_0': 0.49461689788800306, 'linear_1_out': 796, 'dropout_1': 0.2912367868011884, 'linear_2_out': 109, 'dropout_2': 0.1539915536711668, 'linear_3_out': 1504, 'dropout_3': 0.2585697857768926}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:48,255]\u001b[0m Trial 298 finished with value: 0.24998048248048246 and parameters: {'scaler': 2, 'batch_size': 18, 'loss_fn': 1, 'lr': 0.0005568092198440303, 'n_layers': 5, 'linear_0_out': 1315, 'dropout_0': 0.48137177755188065, 'linear_1_out': 27, 'dropout_1': 0.2708211457813088, 'linear_2_out': 4, 'dropout_2': 0.13256261856060242, 'linear_3_out': 15, 'dropout_3': 0.25757938459066065}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:50,432]\u001b[0m Trial 299 finished with value: 0.9446650306070552 and parameters: {'scaler': 2, 'batch_size': 54, 'loss_fn': 1, 'lr': 0.0007882867031436067, 'n_layers': 5, 'linear_0_out': 437, 'dropout_0': 0.49015434130608204, 'linear_1_out': 261, 'dropout_1': 0.1436012310638578, 'linear_2_out': 4, 'dropout_2': 0.27960909138762013, 'linear_3_out': 851, 'dropout_3': 0.20911604318403904}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:10:52,985]\u001b[0m Trial 300 finished with value: 0.5556416030885192 and parameters: {'scaler': 2, 'batch_size': 50, 'loss_fn': 1, 'lr': 0.000845124843768793, 'n_layers': 6, 'linear_0_out': 617, 'dropout_0': 0.49387726262850834, 'linear_1_out': 51, 'dropout_1': 0.14460425607743127, 'linear_2_out': 605, 'dropout_2': 0.06033247269211922, 'linear_3_out': 5, 'dropout_3': 0.4999783063788625, 'linear_4_out': 237, 'dropout_4': 0.27402620328835525}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:11:49,188]\u001b[0m Trial 301 finished with value: 0.5579710144927537 and parameters: {'scaler': 2, 'batch_size': 2, 'loss_fn': 1, 'lr': 7.458100516823504e-05, 'n_layers': 4, 'linear_0_out': 1566, 'dropout_0': 0.48178910332861813, 'linear_1_out': 547, 'dropout_1': 0.4984412273357208, 'linear_2_out': 6, 'dropout_2': 0.39569651937888806}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:11:56,521]\u001b[0m Trial 302 finished with value: 0.284939940778176 and parameters: {'scaler': 2, 'batch_size': 30, 'loss_fn': 1, 'lr': 0.00012435112909506198, 'n_layers': 4, 'linear_0_out': 265, 'dropout_0': 0.49143896687054267, 'linear_1_out': 19, 'dropout_1': 0.3656163424926356, 'linear_2_out': 286, 'dropout_2': 0.49916502139902064}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:04,132]\u001b[0m Trial 303 finished with value: 0.8560743675883655 and parameters: {'scaler': 1, 'batch_size': 61, 'loss_fn': 1, 'lr': 0.0008559750558876147, 'n_layers': 7, 'linear_0_out': 561, 'dropout_0': 0.49387334287370244, 'linear_1_out': 3, 'dropout_1': 0.0010626974082638685, 'linear_2_out': 385, 'dropout_2': 0.2843884591494034, 'linear_3_out': 252, 'dropout_3': 0.3767625174131989, 'linear_4_out': 58, 'dropout_4': 0.17826726252029224, 'linear_5_out': 455, 'dropout_5': 0.19006496433302722}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:10,811]\u001b[0m Trial 304 finished with value: 0.7432358643771686 and parameters: {'scaler': 1, 'batch_size': 57, 'loss_fn': 1, 'lr': 0.000590905671613733, 'n_layers': 6, 'linear_0_out': 484, 'dropout_0': 0.46480798130131096, 'linear_1_out': 152, 'dropout_1': 0.44670301325782724, 'linear_2_out': 5, 'dropout_2': 0.004453079945978766, 'linear_3_out': 10, 'dropout_3': 0.3987359717232944, 'linear_4_out': 101, 'dropout_4': 0.47308043176771597}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:15,412]\u001b[0m Trial 305 finished with value: 0.9399679487179486 and parameters: {'scaler': 2, 'batch_size': 12, 'loss_fn': 1, 'lr': 0.0009270718338972268, 'n_layers': 1}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:20,058]\u001b[0m Trial 306 finished with value: 0.9417040598290599 and parameters: {'scaler': 2, 'batch_size': 12, 'loss_fn': 1, 'lr': 0.0009842647917776032, 'n_layers': 1}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:24,582]\u001b[0m Trial 307 finished with value: 0.9089910882768025 and parameters: {'scaler': 2, 'batch_size': 13, 'loss_fn': 1, 'lr': 0.0006996182155830344, 'n_layers': 1}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:30,357]\u001b[0m Trial 308 finished with value: 0.7939014202172096 and parameters: {'scaler': 2, 'batch_size': 5, 'loss_fn': 1, 'lr': 0.00040310146508047283, 'n_layers': 1}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:34,807]\u001b[0m Trial 309 finished with value: 0.6906072168572167 and parameters: {'scaler': 2, 'batch_size': 18, 'loss_fn': 1, 'lr': 0.00036740649276201665, 'n_layers': 1}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:39,212]\u001b[0m Trial 310 finished with value: 0.5964796781183337 and parameters: {'scaler': 2, 'batch_size': 15, 'loss_fn': 1, 'lr': 0.0001380203252446111, 'n_layers': 1}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:12:57,770]\u001b[0m Trial 311 finished with value: 0.8427128427128429 and parameters: {'scaler': 1, 'batch_size': 9, 'loss_fn': 1, 'lr': 5.7039895644483635e-05, 'n_layers': 6, 'linear_0_out': 327, 'dropout_0': 0.4993834130851178, 'linear_1_out': 87, 'dropout_1': 0.13289069129432474, 'linear_2_out': 440, 'dropout_2': 0.3287751929575052, 'linear_3_out': 661, 'dropout_3': 0.33399923801120873, 'linear_4_out': 43, 'dropout_4': 0.1385413345468552}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:13:09,118]\u001b[0m Trial 312 finished with value: 0.0 and parameters: {'scaler': 1, 'batch_size': 12, 'loss_fn': 1, 'lr': 3.245830466295631e-05, 'n_layers': 6, 'linear_0_out': 445, 'dropout_0': 0.44740894335028547, 'linear_1_out': 2, 'dropout_1': 0.15396812633768298, 'linear_2_out': 2, 'dropout_2': 0.2150135353760187, 'linear_3_out': 8, 'dropout_3': 0.3518238041459948, 'linear_4_out': 8, 'dropout_4': 0.04071591778316902}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:13:16,771]\u001b[0m Trial 313 finished with value: 0.953883364779441 and parameters: {'scaler': 2, 'batch_size': 53, 'loss_fn': 1, 'lr': 0.0006621185320384342, 'n_layers': 3, 'linear_0_out': 316, 'dropout_0': 0.46162466528896323, 'linear_1_out': 756, 'dropout_1': 0.03001643014713251}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:13:31,181]\u001b[0m Trial 314 finished with value: 0.8526251526251525 and parameters: {'scaler': 1, 'batch_size': 10, 'loss_fn': 1, 'lr': 0.0007756971886609888, 'n_layers': 5, 'linear_0_out': 406, 'dropout_0': 0.49027822208990046, 'linear_1_out': 394, 'dropout_1': 0.4647126629908167, 'linear_2_out': 3, 'dropout_2': 0.27983396493454693, 'linear_3_out': 43, 'dropout_3': 0.39935502935811173}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:13:37,938]\u001b[0m Trial 315 finished with value: 0.2850091583919792 and parameters: {'scaler': 2, 'batch_size': 55, 'loss_fn': 1, 'lr': 0.0002855900806738581, 'n_layers': 5, 'linear_0_out': 433, 'dropout_0': 0.47963417953468374, 'linear_1_out': 153, 'dropout_1': 0.13913671828557628, 'linear_2_out': 2, 'dropout_2': 0.24143386442075787, 'linear_3_out': 1140, 'dropout_3': 0.4526815851613336}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:13:44,172]\u001b[0m Trial 316 finished with value: 0.9372883557285085 and parameters: {'scaler': 2, 'batch_size': 42, 'loss_fn': 1, 'lr': 0.0008114873439687575, 'n_layers': 4, 'linear_0_out': 386, 'dropout_0': 0.49684805882366123, 'linear_1_out': 4, 'dropout_1': 0.43033848367934446, 'linear_2_out': 2, 'dropout_2': 0.0461746376701061}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:13:54,331]\u001b[0m Trial 317 finished with value: 0.9621964241517084 and parameters: {'scaler': 2, 'batch_size': 40, 'loss_fn': 1, 'lr': 0.0008347143827326726, 'n_layers': 4, 'linear_0_out': 372, 'dropout_0': 0.48067955187449535, 'linear_1_out': 1946, 'dropout_1': 0.19348370359577738, 'linear_2_out': 3, 'dropout_2': 0.23522767717676069}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:14:40,705]\u001b[0m Trial 318 finished with value: 0.3516483516483517 and parameters: {'scaler': 1, 'batch_size': 1, 'loss_fn': 1, 'lr': 0.0009681742748192928, 'n_layers': 4, 'linear_0_out': 289, 'dropout_0': 0.48370877263591616, 'linear_1_out': 2, 'dropout_1': 0.008185077449679778, 'linear_2_out': 97, 'dropout_2': 0.10560310989754834}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:14:47,569]\u001b[0m Trial 319 finished with value: 0.9507155545979076 and parameters: {'scaler': 2, 'batch_size': 43, 'loss_fn': 1, 'lr': 0.0005750897935849817, 'n_layers': 4, 'linear_0_out': 287, 'dropout_0': 0.49386445692844244, 'linear_1_out': 151, 'dropout_1': 0.1673496319218407, 'linear_2_out': 4, 'dropout_2': 0.4922009291141689}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:01,464]\u001b[0m Trial 320 finished with value: 0.08130081300813008 and parameters: {'scaler': 2, 'batch_size': 40, 'loss_fn': 0, 'lr': 0.0007709304159772192, 'n_layers': 2, 'linear_0_out': 226, 'dropout_0': 0.4747264972576124}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:09,395]\u001b[0m Trial 321 finished with value: 0.9047433067566478 and parameters: {'scaler': 2, 'batch_size': 56, 'loss_fn': 1, 'lr': 0.0005507299945011942, 'n_layers': 4, 'linear_0_out': 339, 'dropout_0': 0.49297985296112706, 'linear_1_out': 10, 'dropout_1': 0.030988573037098344, 'linear_2_out': 12, 'dropout_2': 0.1258500279501058}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:11,680]\u001b[0m Trial 322 finished with value: 0.8185896559580771 and parameters: {'scaler': 2, 'batch_size': 32, 'loss_fn': 1, 'lr': 0.0005190436826276502, 'n_layers': 4, 'linear_0_out': 220, 'dropout_0': 0.49927444870263354, 'linear_1_out': 14, 'dropout_1': 0.17783711560037313, 'linear_2_out': 589, 'dropout_2': 0.02989221797390096}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:13,647]\u001b[0m Trial 323 finished with value: 0.8829749210049151 and parameters: {'scaler': 2, 'batch_size': 60, 'loss_fn': 1, 'lr': 0.0005738709279798248, 'n_layers': 3, 'linear_0_out': 248, 'dropout_0': 0.47764082641409333, 'linear_1_out': 21, 'dropout_1': 0.0518727714826156}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:15,840]\u001b[0m Trial 324 finished with value: 0.9643014527031264 and parameters: {'scaler': 2, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.000736584966559298, 'n_layers': 4, 'linear_0_out': 155, 'dropout_0': 0.48467037437860355, 'linear_1_out': 2191, 'dropout_1': 0.07198586615707658, 'linear_2_out': 52, 'dropout_2': 0.24002171630195457}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:18,339]\u001b[0m Trial 325 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 67, 'loss_fn': 1, 'lr': 0.0004904826014793366, 'n_layers': 5, 'linear_0_out': 232, 'dropout_0': 0.46650517055784374, 'linear_1_out': 493, 'dropout_1': 0.13607293564566664, 'linear_2_out': 357, 'dropout_2': 0.013169279570428682, 'linear_3_out': 1456, 'dropout_3': 0.04947782562895886}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:20,918]\u001b[0m Trial 326 finished with value: 0.8672818679282777 and parameters: {'scaler': 2, 'batch_size': 59, 'loss_fn': 1, 'lr': 0.0008395178661979184, 'n_layers': 4, 'linear_0_out': 234, 'dropout_0': 0.4859527449504211, 'linear_1_out': 53, 'dropout_1': 0.0867148566308365, 'linear_2_out': 23, 'dropout_2': 0.3210102583847434}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:23,134]\u001b[0m Trial 327 finished with value: 0.9569597097154198 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.0002390181351628969, 'n_layers': 3, 'linear_0_out': 444, 'dropout_0': 0.4972871491566636, 'linear_1_out': 1989, 'dropout_1': 0.09358343759584502}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:25,281]\u001b[0m Trial 328 finished with value: 0.9431077694235588 and parameters: {'scaler': 2, 'batch_size': 81, 'loss_fn': 1, 'lr': 6.367600524963324e-05, 'n_layers': 3, 'linear_0_out': 441, 'dropout_0': 0.4337630381220706, 'linear_1_out': 1938, 'dropout_1': 0.21261458359610413}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:26,953]\u001b[0m Trial 329 finished with value: 0.3789196153279025 and parameters: {'scaler': 2, 'batch_size': 90, 'loss_fn': 1, 'lr': 8.061714610610161e-05, 'n_layers': 2, 'linear_0_out': 251, 'dropout_0': 0.49997797111804904}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:29,183]\u001b[0m Trial 330 finished with value: 0.9594524119947849 and parameters: {'scaler': 2, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.00013023685988694948, 'n_layers': 4, 'linear_0_out': 393, 'dropout_0': 0.44043692791812306, 'linear_1_out': 925, 'dropout_1': 0.10156532142310087, 'linear_2_out': 4, 'dropout_2': 0.14455425996522137}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:31,704]\u001b[0m Trial 331 finished with value: 0.9431287151902822 and parameters: {'scaler': 2, 'batch_size': 95, 'loss_fn': 1, 'lr': 0.0005798284167031351, 'n_layers': 4, 'linear_0_out': 327, 'dropout_0': 0.4562424736646104, 'linear_1_out': 2400, 'dropout_1': 0.15907843219264725, 'linear_2_out': 231, 'dropout_2': 0.42227227379856747}. Best is trial 297 with value: 0.969312263625989.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:34,036]\u001b[0m Trial 332 finished with value: 0.9700272673188788 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.00036895778746798947, 'n_layers': 3, 'linear_0_out': 398, 'dropout_0': 0.4147965547365413, 'linear_1_out': 2356, 'dropout_1': 0.08667969766952671}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:36,500]\u001b[0m Trial 333 finished with value: 0.9689624411701375 and parameters: {'scaler': 2, 'batch_size': 78, 'loss_fn': 1, 'lr': 0.00015285912326568545, 'n_layers': 4, 'linear_0_out': 557, 'dropout_0': 0.4137289323397211, 'linear_1_out': 2041, 'dropout_1': 0.09789083805946569, 'linear_2_out': 122, 'dropout_2': 0.26149233263951177}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:38,798]\u001b[0m Trial 334 finished with value: 0.474316829004329 and parameters: {'scaler': 2, 'batch_size': 90, 'loss_fn': 1, 'lr': 0.0004221373101796735, 'n_layers': 3, 'linear_0_out': 458, 'dropout_0': 0.4314773239820202, 'linear_1_out': 2305, 'dropout_1': 0.10982918175818741}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:40,749]\u001b[0m Trial 335 finished with value: 0.6553967144828945 and parameters: {'scaler': 2, 'batch_size': 72, 'loss_fn': 1, 'lr': 1.9122493011451146e-05, 'n_layers': 3, 'linear_0_out': 227, 'dropout_0': 0.4126109084953936, 'linear_1_out': 1964, 'dropout_1': 0.1639313566515368}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:42,485]\u001b[0m Trial 336 finished with value: 0.8687839465598728 and parameters: {'scaler': 2, 'batch_size': 74, 'loss_fn': 1, 'lr': 0.00022949750462998906, 'n_layers': 2, 'linear_0_out': 372, 'dropout_0': 0.41004235608412454}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:45,502]\u001b[0m Trial 337 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 30, 'loss_fn': 1, 'lr': 0.0004877847581213513, 'n_layers': 6, 'linear_0_out': 567, 'dropout_0': 0.42375245509873194, 'linear_1_out': 1511, 'dropout_1': 0.08440440468554591, 'linear_2_out': 3, 'dropout_2': 0.07327023077663314, 'linear_3_out': 1834, 'dropout_3': 0.001312430041822743, 'linear_4_out': 55, 'dropout_4': 0.3781712403710623}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:47,696]\u001b[0m Trial 338 finished with value: 0.9650860909335487 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 0.000679998464489748, 'n_layers': 5, 'linear_0_out': 237, 'dropout_0': 0.4183145360320187, 'linear_1_out': 2395, 'dropout_1': 0.15181888950369812, 'linear_2_out': 7, 'dropout_2': 0.22978185816393176, 'linear_3_out': 58, 'dropout_3': 0.13019857885076402}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:51,108]\u001b[0m Trial 339 finished with value: 0.9646933797229448 and parameters: {'scaler': 2, 'batch_size': 83, 'loss_fn': 1, 'lr': 0.0001736077694061434, 'n_layers': 5, 'linear_0_out': 469, 'dropout_0': 0.41372452847872165, 'linear_1_out': 1925, 'dropout_1': 0.06711190807267065, 'linear_2_out': 1017, 'dropout_2': 0.46257809003611616, 'linear_3_out': 389, 'dropout_3': 0.004318295858523502}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:53,445]\u001b[0m Trial 340 finished with value: 0.12371134020618557 and parameters: {'scaler': 2, 'batch_size': 95, 'loss_fn': 2, 'lr': 0.0007225440539044379, 'n_layers': 4, 'linear_0_out': 306, 'dropout_0': 0.43277183601442776, 'linear_1_out': 2459, 'dropout_1': 0.1197777648296636, 'linear_2_out': 159, 'dropout_2': 0.11605593399029962}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:55,760]\u001b[0m Trial 341 finished with value: 0.9139425444277197 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 9.3683689260988e-05, 'n_layers': 5, 'linear_0_out': 360, 'dropout_0': 0.41858543502825635, 'linear_1_out': 2316, 'dropout_1': 0.10008257847661112, 'linear_2_out': 11, 'dropout_2': 0.0919019774520618, 'linear_3_out': 105, 'dropout_3': 0.22335932797674873}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:15:58,406]\u001b[0m Trial 342 finished with value: 0.9215600448933785 and parameters: {'scaler': 2, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.000800263087166733, 'n_layers': 6, 'linear_0_out': 355, 'dropout_0': 0.4128619932427098, 'linear_1_out': 2370, 'dropout_1': 0.10583182854503739, 'linear_2_out': 6, 'dropout_2': 0.46632046551005896, 'linear_3_out': 9, 'dropout_3': 0.38936945175356097, 'linear_4_out': 2, 'dropout_4': 0.09174005425197845}. Best is trial 332 with value: 0.9700272673188788.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:16:01,777]\u001b[0m Trial 343 finished with value: 0.9753149867374006 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.0009155181596879362, 'n_layers': 4, 'linear_0_out': 443, 'dropout_0': 0.3955847768373275, 'linear_1_out': 1548, 'dropout_1': 0.1827383991528654, 'linear_2_out': 652, 'dropout_2': 0.2682132780504239}. Best is trial 343 with value: 0.9753149867374006.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:16:05,820]\u001b[0m Trial 344 finished with value: 0.9591502713704205 and parameters: {'scaler': 2, 'batch_size': 94, 'loss_fn': 1, 'lr': 0.0007605579348390188, 'n_layers': 5, 'linear_0_out': 781, 'dropout_0': 0.41713291435979627, 'linear_1_out': 1993, 'dropout_1': 0.1836802949525273, 'linear_2_out': 181, 'dropout_2': 0.2144491956864028, 'linear_3_out': 38, 'dropout_3': 0.06270200689923366}. Best is trial 343 with value: 0.9753149867374006.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:16:09,763]\u001b[0m Trial 345 finished with value: 0.9461496880999523 and parameters: {'scaler': 2, 'batch_size': 94, 'loss_fn': 1, 'lr': 0.00045817164312113946, 'n_layers': 5, 'linear_0_out': 720, 'dropout_0': 0.4195666005925509, 'linear_1_out': 2246, 'dropout_1': 0.2160515302409264, 'linear_2_out': 5, 'dropout_2': 0.45949853844309546, 'linear_3_out': 45, 'dropout_3': 0.23622754451240152}. Best is trial 343 with value: 0.9753149867374006.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:16:19,683]\u001b[0m Trial 346 finished with value: 0.05702193531387918 and parameters: {'scaler': 2, 'batch_size': 89, 'loss_fn': 0, 'lr': 0.00039150098713472235, 'n_layers': 6, 'linear_0_out': 725, 'dropout_0': 0.4086926583426216, 'linear_1_out': 2375, 'dropout_1': 0.20081696329265408, 'linear_2_out': 210, 'dropout_2': 0.007063477520165062, 'linear_3_out': 78, 'dropout_3': 0.44266777594548024, 'linear_4_out': 33, 'dropout_4': 0.20630184227969645}. Best is trial 343 with value: 0.9753149867374006.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:16:32,401]\u001b[0m Trial 347 finished with value: 0.9748030397022334 and parameters: {'scaler': 2, 'batch_size': 85, 'loss_fn': 1, 'lr': 0.0008875395618058381, 'n_layers': 4, 'linear_0_out': 926, 'dropout_0': 0.41684657847684686, 'linear_1_out': 1737, 'dropout_1': 0.2193728863575125, 'linear_2_out': 43, 'dropout_2': 0.427551026252219}. Best is trial 343 with value: 0.9753149867374006.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:16:43,166]\u001b[0m Trial 348 finished with value: 0.9323981658339713 and parameters: {'scaler': 2, 'batch_size': 100, 'loss_fn': 1, 'lr': 0.00036680327163788733, 'n_layers': 5, 'linear_0_out': 880, 'dropout_0': 0.4235216174393608, 'linear_1_out': 1841, 'dropout_1': 0.18706006501237213, 'linear_2_out': 139, 'dropout_2': 0.3736754515067221, 'linear_3_out': 309, 'dropout_3': 0.025429874568835553}. Best is trial 343 with value: 0.9753149867374006.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:16:53,581]\u001b[0m Trial 349 finished with value: 0.9532374435600243 and parameters: {'scaler': 2, 'batch_size': 100, 'loss_fn': 1, 'lr': 0.0005514368042695011, 'n_layers': 3, 'linear_0_out': 845, 'dropout_0': 0.43557933985096164, 'linear_1_out': 2155, 'dropout_1': 0.1592358228115777}. Best is trial 343 with value: 0.9753149867374006.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:17:54,455]\u001b[0m Trial 350 finished with value: 0.976923076923077 and parameters: {'scaler': 2, 'batch_size': 84, 'loss_fn': 1, 'lr': 0.0006999934740862301, 'n_layers': 4, 'linear_0_out': 993, 'dropout_0': 0.4126313374017483, 'linear_1_out': 1445, 'dropout_1': 0.17006837543007386, 'linear_2_out': 2104, 'dropout_2': 0.3531040861979386}. Best is trial 350 with value: 0.976923076923077.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:18:05,858]\u001b[0m Trial 351 finished with value: 0.9728139919694565 and parameters: {'scaler': 2, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.00030712981258157154, 'n_layers': 4, 'linear_0_out': 1850, 'dropout_0': 0.4294813837531416, 'linear_1_out': 851, 'dropout_1': 0.1535126338738452, 'linear_2_out': 111, 'dropout_2': 0.02258828997482143}. Best is trial 350 with value: 0.976923076923077.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:18:50,343]\u001b[0m Trial 352 finished with value: 0.9676514116575591 and parameters: {'scaler': 2, 'batch_size': 83, 'loss_fn': 1, 'lr': 0.0009787117038763372, 'n_layers': 5, 'linear_0_out': 1974, 'dropout_0': 0.4008967406206085, 'linear_1_out': 798, 'dropout_1': 0.1865626150084113, 'linear_2_out': 1362, 'dropout_2': 0.23477840817751838, 'linear_3_out': 1294, 'dropout_3': 0.20920346678701113}. Best is trial 350 with value: 0.976923076923077.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:20:21,592]\u001b[0m Trial 353 finished with value: 0.10483870967741934 and parameters: {'scaler': 1, 'batch_size': 3, 'loss_fn': 2, 'lr': 0.0002807251055166974, 'n_layers': 5, 'linear_0_out': 2374, 'dropout_0': 0.36879360603624267, 'linear_1_out': 660, 'dropout_1': 0.18397670578357608, 'linear_2_out': 109, 'dropout_2': 0.44685896476136683, 'linear_3_out': 46, 'dropout_3': 0.089765701596771}. Best is trial 350 with value: 0.976923076923077.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:20:24,554]\u001b[0m Trial 354 finished with value: 0.9774825992242706 and parameters: {'scaler': 2, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.000981789029031719, 'n_layers': 3, 'linear_0_out': 1620, 'dropout_0': 0.41119912801421127, 'linear_1_out': 1121, 'dropout_1': 0.11022910277011493}. Best is trial 354 with value: 0.9774825992242706.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:20:33,202]\u001b[0m Trial 355 finished with value: 0.9792748601486181 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.0008982878069655724, 'n_layers': 3, 'linear_0_out': 2137, 'dropout_0': 0.4535774135628239, 'linear_1_out': 881, 'dropout_1': 0.13964207694868172}. Best is trial 355 with value: 0.9792748601486181.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:20:41,775]\u001b[0m Trial 356 finished with value: 0.9818391393442623 and parameters: {'scaler': 2, 'batch_size': 84, 'loss_fn': 1, 'lr': 0.0009109095024703572, 'n_layers': 4, 'linear_0_out': 2431, 'dropout_0': 0.44020043499824185, 'linear_1_out': 789, 'dropout_1': 0.18518754158773107, 'linear_2_out': 35, 'dropout_2': 0.1908133145843311}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:20:45,264]\u001b[0m Trial 357 finished with value: 0.47262349522623487 and parameters: {'scaler': 0, 'batch_size': 88, 'loss_fn': 1, 'lr': 0.0009038413366796438, 'n_layers': 4, 'linear_0_out': 1873, 'dropout_0': 0.41688407054716253, 'linear_1_out': 1099, 'dropout_1': 0.14898012990545842, 'linear_2_out': 340, 'dropout_2': 0.42036681328563547}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:21:13,212]\u001b[0m Trial 358 finished with value: 0.9746473970944312 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 0.0006307241743532918, 'n_layers': 5, 'linear_0_out': 2489, 'dropout_0': 0.4218788399677466, 'linear_1_out': 858, 'dropout_1': 0.141821191884006, 'linear_2_out': 2, 'dropout_2': 0.2474075670456894, 'linear_3_out': 11, 'dropout_3': 0.08221634483889295}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:21:24,301]\u001b[0m Trial 359 finished with value: 0.8191112807222621 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.0008744460513990489, 'n_layers': 1}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:22:29,039]\u001b[0m Trial 360 finished with value: 0.9795303023479253 and parameters: {'scaler': 2, 'batch_size': 85, 'loss_fn': 1, 'lr': 0.0007032625255631235, 'n_layers': 4, 'linear_0_out': 2369, 'dropout_0': 0.4110976875963997, 'linear_1_out': 835, 'dropout_1': 0.1536566173706581, 'linear_2_out': 209, 'dropout_2': 0.4177728205859717}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:23:26,597]\u001b[0m Trial 361 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 88, 'loss_fn': 1, 'lr': 0.0006134186661070211, 'n_layers': 4, 'linear_0_out': 2294, 'dropout_0': 0.3910302550309737, 'linear_1_out': 1008, 'dropout_1': 0.13485708721989081, 'linear_2_out': 85, 'dropout_2': 0.09689707853054819}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:23:43,486]\u001b[0m Trial 362 finished with value: 0.979937304075235 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.0005000666843099838, 'n_layers': 3, 'linear_0_out': 2231, 'dropout_0': 0.39972923392401877, 'linear_1_out': 932, 'dropout_1': 0.15255430700503014}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:23:58,320]\u001b[0m Trial 363 finished with value: 0.9698032040717944 and parameters: {'scaler': 2, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.00030575727751745165, 'n_layers': 5, 'linear_0_out': 2246, 'dropout_0': 0.418128591261114, 'linear_1_out': 699, 'dropout_1': 0.19570667188796262, 'linear_2_out': 395, 'dropout_2': 0.2606663344786845, 'linear_3_out': 587, 'dropout_3': 0.4823614132338157}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:24:07,057]\u001b[0m Trial 364 finished with value: 0.9806695038318519 and parameters: {'scaler': 2, 'batch_size': 83, 'loss_fn': 1, 'lr': 0.000606202637004604, 'n_layers': 4, 'linear_0_out': 1202, 'dropout_0': 0.3950479642234874, 'linear_1_out': 691, 'dropout_1': 0.16734104595973953, 'linear_2_out': 34, 'dropout_2': 0.15950104772307327}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:24:12,671]\u001b[0m Trial 365 finished with value: 0.04651162790697674 and parameters: {'scaler': 2, 'batch_size': 82, 'loss_fn': 0, 'lr': 0.0006825648866115123, 'n_layers': 2, 'linear_0_out': 2443, 'dropout_0': 0.4178553848691552}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:24:29,181]\u001b[0m Trial 366 finished with value: 0.9707821114269082 and parameters: {'scaler': 2, 'batch_size': 72, 'loss_fn': 1, 'lr': 0.0007877748604471881, 'n_layers': 5, 'linear_0_out': 1881, 'dropout_0': 0.429382287559934, 'linear_1_out': 616, 'dropout_1': 0.17807414600457408, 'linear_2_out': 12, 'dropout_2': 0.3454932333260836, 'linear_3_out': 2030, 'dropout_3': 0.14290947705066837}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:24:44,346]\u001b[0m Trial 367 finished with value: 0.9810329447229996 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.0008874376735608686, 'n_layers': 3, 'linear_0_out': 2343, 'dropout_0': 0.41324411998853133, 'linear_1_out': 847, 'dropout_1': 0.16443658077023188}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:24:57,662]\u001b[0m Trial 368 finished with value: 0.9792115902964962 and parameters: {'scaler': 2, 'batch_size': 71, 'loss_fn': 1, 'lr': 0.0005913106625502397, 'n_layers': 3, 'linear_0_out': 2311, 'dropout_0': 0.4265078243163753, 'linear_1_out': 762, 'dropout_1': 0.1615394063384562}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:08,527]\u001b[0m Trial 369 finished with value: 0.9783657256348421 and parameters: {'scaler': 2, 'batch_size': 74, 'loss_fn': 1, 'lr': 0.0007245438616564801, 'n_layers': 4, 'linear_0_out': 2437, 'dropout_0': 0.37981118939740116, 'linear_1_out': 752, 'dropout_1': 0.17758361311305887, 'linear_2_out': 226, 'dropout_2': 0.26035175268753563}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:12,115]\u001b[0m Trial 370 finished with value: 0.9802248677248679 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.0007233425785866762, 'n_layers': 4, 'linear_0_out': 2302, 'dropout_0': 0.3712764630245941, 'linear_1_out': 802, 'dropout_1': 0.17041090021929242, 'linear_2_out': 204, 'dropout_2': 0.25485806714817366}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:14,576]\u001b[0m Trial 371 finished with value: 0.9744694165500711 and parameters: {'scaler': 2, 'batch_size': 78, 'loss_fn': 1, 'lr': 0.0003940365758029899, 'n_layers': 4, 'linear_0_out': 1962, 'dropout_0': 0.3809059970551077, 'linear_1_out': 660, 'dropout_1': 0.1742593117634314, 'linear_2_out': 126, 'dropout_2': 0.23784768371725146}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:18,778]\u001b[0m Trial 372 finished with value: 0.9785331384015598 and parameters: {'scaler': 2, 'batch_size': 74, 'loss_fn': 1, 'lr': 0.000975643402778436, 'n_layers': 4, 'linear_0_out': 2255, 'dropout_0': 0.4174249819279452, 'linear_1_out': 635, 'dropout_1': 0.20540150836497145, 'linear_2_out': 239, 'dropout_2': 0.2551109903391793}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:21,341]\u001b[0m Trial 373 finished with value: 0.9773933931582581 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 0.0007208563818107713, 'n_layers': 3, 'linear_0_out': 1957, 'dropout_0': 0.38351604167946407, 'linear_1_out': 669, 'dropout_1': 0.2504176816626134}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:23,815]\u001b[0m Trial 374 finished with value: 0.9783008341745921 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 0.0008930131567141735, 'n_layers': 3, 'linear_0_out': 1931, 'dropout_0': 0.39031215051320756, 'linear_1_out': 623, 'dropout_1': 0.24875723468996858}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:34,729]\u001b[0m Trial 375 finished with value: 0.9734579504316347 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.0008970111508734696, 'n_layers': 4, 'linear_0_out': 2271, 'dropout_0': 0.3630322452243082, 'linear_1_out': 859, 'dropout_1': 0.2597155989964756, 'linear_2_out': 1786, 'dropout_2': 0.4075185284133841}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:37,583]\u001b[0m Trial 376 finished with value: 0.9766805307981776 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.0009190479323777457, 'n_layers': 3, 'linear_0_out': 2083, 'dropout_0': 0.40511806591796107, 'linear_1_out': 488, 'dropout_1': 0.23585325887338354}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:39,536]\u001b[0m Trial 377 finished with value: 0.9697979797979798 and parameters: {'scaler': 2, 'batch_size': 72, 'loss_fn': 1, 'lr': 0.0009558334294042628, 'n_layers': 2, 'linear_0_out': 2409, 'dropout_0': 0.3556257373097059}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:41,292]\u001b[0m Trial 378 finished with value: 0.7579383866907087 and parameters: {'scaler': 2, 'batch_size': 66, 'loss_fn': 1, 'lr': 0.0008305434630419981, 'n_layers': 1}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:44,169]\u001b[0m Trial 379 finished with value: 0.978752302903246 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.0006992907583435444, 'n_layers': 3, 'linear_0_out': 1782, 'dropout_0': 0.3834511146559776, 'linear_1_out': 767, 'dropout_1': 0.24417922674866904}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:46,864]\u001b[0m Trial 380 finished with value: 0.9784313725490194 and parameters: {'scaler': 2, 'batch_size': 67, 'loss_fn': 1, 'lr': 0.000830220270266808, 'n_layers': 3, 'linear_0_out': 2256, 'dropout_0': 0.38874854927158736, 'linear_1_out': 302, 'dropout_1': 0.2429273748227962}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:49,438]\u001b[0m Trial 381 finished with value: 0.9790002770013349 and parameters: {'scaler': 2, 'batch_size': 82, 'loss_fn': 1, 'lr': 0.00042873743447839857, 'n_layers': 3, 'linear_0_out': 2340, 'dropout_0': 0.3685881435207139, 'linear_1_out': 422, 'dropout_1': 0.24393907137063442}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:52,438]\u001b[0m Trial 382 finished with value: 0.9792748601486181 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.0005996676360511203, 'n_layers': 3, 'linear_0_out': 2439, 'dropout_0': 0.3734609764859692, 'linear_1_out': 592, 'dropout_1': 0.25993806575883377}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:25:56,363]\u001b[0m Trial 383 finished with value: 0.9773679854981084 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.000820220294090734, 'n_layers': 3, 'linear_0_out': 2450, 'dropout_0': 0.351647374152412, 'linear_1_out': 668, 'dropout_1': 0.2345436471552837}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:26:00,779]\u001b[0m Trial 384 finished with value: 0.9812465828321489 and parameters: {'scaler': 2, 'batch_size': 82, 'loss_fn': 1, 'lr': 0.0007483836533930407, 'n_layers': 3, 'linear_0_out': 2167, 'dropout_0': 0.37204809595707783, 'linear_1_out': 497, 'dropout_1': 0.2604193521917778}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:26:08,796]\u001b[0m Trial 385 finished with value: 0.979937304075235 and parameters: {'scaler': 2, 'batch_size': 78, 'loss_fn': 1, 'lr': 0.0006569235998559884, 'n_layers': 3, 'linear_0_out': 2362, 'dropout_0': 0.34321927789427625, 'linear_1_out': 306, 'dropout_1': 0.25242379754439104}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:26:19,959]\u001b[0m Trial 386 finished with value: 0.9792748601486181 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.000939832434297984, 'n_layers': 3, 'linear_0_out': 2248, 'dropout_0': 0.3541744273197069, 'linear_1_out': 557, 'dropout_1': 0.26239307711177895}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:26:25,997]\u001b[0m Trial 387 finished with value: 0.9716473419933009 and parameters: {'scaler': 2, 'batch_size': 82, 'loss_fn': 1, 'lr': 0.0007766082789767274, 'n_layers': 2, 'linear_0_out': 2147, 'dropout_0': 0.32973638124156135}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:26:34,982]\u001b[0m Trial 388 finished with value: 0.979937304075235 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.000610931890500447, 'n_layers': 3, 'linear_0_out': 2140, 'dropout_0': 0.3436294895671554, 'linear_1_out': 337, 'dropout_1': 0.2740483418644576}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:26:46,437]\u001b[0m Trial 389 finished with value: 0.9765800113491278 and parameters: {'scaler': 2, 'batch_size': 72, 'loss_fn': 1, 'lr': 0.0009862827721322052, 'n_layers': 3, 'linear_0_out': 2130, 'dropout_0': 0.32036857884189, 'linear_1_out': 537, 'dropout_1': 0.26437521768734756}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:26:56,140]\u001b[0m Trial 390 finished with value: 0.9784313725490194 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.0005226844166071623, 'n_layers': 3, 'linear_0_out': 2410, 'dropout_0': 0.31775131141680724, 'linear_1_out': 370, 'dropout_1': 0.27129561296831095}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:27:12,325]\u001b[0m Trial 391 finished with value: 0.06849315068493152 and parameters: {'scaler': 2, 'batch_size': 68, 'loss_fn': 0, 'lr': 0.0005375311178425228, 'n_layers': 5, 'linear_0_out': 2494, 'dropout_0': 0.30628696874823935, 'linear_1_out': 412, 'dropout_1': 0.2361296214600975, 'linear_2_out': 2431, 'dropout_2': 0.3403384523497758, 'linear_3_out': 46, 'dropout_3': 0.2881654632309806}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:27:18,016]\u001b[0m Trial 392 finished with value: 0.9688516113516114 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.0004407526033600676, 'n_layers': 2, 'linear_0_out': 2378, 'dropout_0': 0.36796296216778207}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:27:26,227]\u001b[0m Trial 393 finished with value: 0.9772936008785068 and parameters: {'scaler': 2, 'batch_size': 74, 'loss_fn': 1, 'lr': 0.0005920803643028695, 'n_layers': 3, 'linear_0_out': 2307, 'dropout_0': 0.3551786241639712, 'linear_1_out': 270, 'dropout_1': 0.29886661672922665}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:27:35,330]\u001b[0m Trial 394 finished with value: 0.9758281316498797 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.0008749916216372166, 'n_layers': 3, 'linear_0_out': 2422, 'dropout_0': 0.35582008417039035, 'linear_1_out': 355, 'dropout_1': 0.256500925085251}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:27:46,106]\u001b[0m Trial 395 finished with value: 0.0625 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 2, 'lr': 0.0009700357367883137, 'n_layers': 3, 'linear_0_out': 2498, 'dropout_0': 0.34064152824388816, 'linear_1_out': 445, 'dropout_1': 0.2899084991110054}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:27:51,797]\u001b[0m Trial 396 finished with value: 0.9283137902246509 and parameters: {'scaler': 0, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.00037259985812924425, 'n_layers': 2, 'linear_0_out': 2360, 'dropout_0': 0.3743754144925661}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:27:58,300]\u001b[0m Trial 397 finished with value: 0.9709958101512747 and parameters: {'scaler': 2, 'batch_size': 78, 'loss_fn': 1, 'lr': 0.0006996754084671605, 'n_layers': 3, 'linear_0_out': 1193, 'dropout_0': 0.3471429376065529, 'linear_1_out': 211, 'dropout_1': 0.2795548450441618}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:04,166]\u001b[0m Trial 398 finished with value: 0.9694663846446432 and parameters: {'scaler': 2, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.00039429057007843383, 'n_layers': 2, 'linear_0_out': 2461, 'dropout_0': 0.35838329164403865}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:12,892]\u001b[0m Trial 399 finished with value: 0.9772936008785068 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.00038808626620852614, 'n_layers': 3, 'linear_0_out': 2427, 'dropout_0': 0.4433427763223595, 'linear_1_out': 381, 'dropout_1': 0.2533298596481803}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:18,920]\u001b[0m Trial 400 finished with value: 0.9580587096957796 and parameters: {'scaler': 2, 'batch_size': 68, 'loss_fn': 1, 'lr': 0.0003574508673298105, 'n_layers': 2, 'linear_0_out': 2313, 'dropout_0': 0.4470635768790415}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:25,843]\u001b[0m Trial 401 finished with value: 0.9761058864507139 and parameters: {'scaler': 2, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.0006269933284684544, 'n_layers': 3, 'linear_0_out': 1393, 'dropout_0': 0.34355145661055053, 'linear_1_out': 300, 'dropout_1': 0.3017977193405767}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:35,300]\u001b[0m Trial 402 finished with value: 0.9744029267891641 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.00038640897677702973, 'n_layers': 3, 'linear_0_out': 2479, 'dropout_0': 0.33250146925576163, 'linear_1_out': 394, 'dropout_1': 0.25866957265521995}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:44,502]\u001b[0m Trial 403 finished with value: 0.965377351218008 and parameters: {'scaler': 2, 'batch_size': 61, 'loss_fn': 1, 'lr': 0.00017064124858085574, 'n_layers': 3, 'linear_0_out': 2448, 'dropout_0': 0.39710232673078616, 'linear_1_out': 355, 'dropout_1': 0.30145847163686035}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:49,726]\u001b[0m Trial 404 finished with value: 0.9358814672060939 and parameters: {'scaler': 2, 'batch_size': 99, 'loss_fn': 1, 'lr': 0.0006806722974985173, 'n_layers': 2, 'linear_0_out': 2412, 'dropout_0': 0.4448854799799602}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:28:58,056]\u001b[0m Trial 405 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.0002171486755398699, 'n_layers': 3, 'linear_0_out': 1135, 'dropout_0': 0.3562857221983922, 'linear_1_out': 733, 'dropout_1': 0.26933878575320974}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:29:06,065]\u001b[0m Trial 406 finished with value: 0.973703757256389 and parameters: {'scaler': 2, 'batch_size': 72, 'loss_fn': 1, 'lr': 0.0006683442593670234, 'n_layers': 3, 'linear_0_out': 1246, 'dropout_0': 0.363336901811183, 'linear_1_out': 493, 'dropout_1': 0.250646346280227}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:29:14,295]\u001b[0m Trial 407 finished with value: 0.4823953823953824 and parameters: {'scaler': 2, 'batch_size': 87, 'loss_fn': 1, 'lr': 0.000935731064657551, 'n_layers': 3, 'linear_0_out': 2163, 'dropout_0': 0.43880600524008756, 'linear_1_out': 310, 'dropout_1': 0.2237779530022084}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:29:24,474]\u001b[0m Trial 408 finished with value: 0.9784313725490194 and parameters: {'scaler': 2, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.0004568915967995102, 'n_layers': 3, 'linear_0_out': 2298, 'dropout_0': 0.377526191292502, 'linear_1_out': 530, 'dropout_1': 0.23624578080123076}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:29:56,384]\u001b[0m Trial 409 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 62, 'loss_fn': 1, 'lr': 0.0007033951142939475, 'n_layers': 3, 'linear_0_out': 2349, 'dropout_0': 0.3808574653603075, 'linear_1_out': 954, 'dropout_1': 0.2519483058083831}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:07,663]\u001b[0m Trial 410 finished with value: 0.9734612976122408 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.0009273949215713953, 'n_layers': 4, 'linear_0_out': 806, 'dropout_0': 0.34909690292667106, 'linear_1_out': 350, 'dropout_1': 0.21418947104657918, 'linear_2_out': 195, 'dropout_2': 0.23686624481391766}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:10,294]\u001b[0m Trial 411 finished with value: 0.9762413512413515 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.00027435896884414043, 'n_layers': 3, 'linear_0_out': 2427, 'dropout_0': 0.3580417364266467, 'linear_1_out': 705, 'dropout_1': 0.23862023913961067}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:12,035]\u001b[0m Trial 412 finished with value: 0.26282051282051283 and parameters: {'scaler': 2, 'batch_size': 61, 'loss_fn': 2, 'lr': 8.453458978728946e-05, 'n_layers': 1}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:15,163]\u001b[0m Trial 413 finished with value: 0.979937304075235 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.0009341591723768365, 'n_layers': 3, 'linear_0_out': 2499, 'dropout_0': 0.4265563060773569, 'linear_1_out': 593, 'dropout_1': 0.21867828433171757}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:16,964]\u001b[0m Trial 414 finished with value: 0.973420775590587 and parameters: {'scaler': 2, 'batch_size': 74, 'loss_fn': 1, 'lr': 0.0009603007634342584, 'n_layers': 2, 'linear_0_out': 2321, 'dropout_0': 0.40251153550218766}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:18,694]\u001b[0m Trial 415 finished with value: 0.4469767742965859 and parameters: {'scaler': 2, 'batch_size': 87, 'loss_fn': 1, 'lr': 0.0002915358896721114, 'n_layers': 2, 'linear_0_out': 1013, 'dropout_0': 0.3527808920665022}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:21,304]\u001b[0m Trial 416 finished with value: 0.9806140350877193 and parameters: {'scaler': 2, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.0007102647203462515, 'n_layers': 3, 'linear_0_out': 2401, 'dropout_0': 0.4154011422959845, 'linear_1_out': 506, 'dropout_1': 0.20216809923285284}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:23,934]\u001b[0m Trial 417 finished with value: 0.049999999999999996 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 0, 'lr': 0.0009340045127576356, 'n_layers': 4, 'linear_0_out': 2418, 'dropout_0': 0.487925930479166, 'linear_1_out': 419, 'dropout_1': 0.18471056026713423, 'linear_2_out': 110, 'dropout_2': 0.2498972489618282}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:26,575]\u001b[0m Trial 418 finished with value: 0.9742142944311111 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.0008570189631579129, 'n_layers': 3, 'linear_0_out': 2353, 'dropout_0': 0.453587316227098, 'linear_1_out': 503, 'dropout_1': 0.1786675568314698}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:28,923]\u001b[0m Trial 419 finished with value: 0.9688671255736339 and parameters: {'scaler': 2, 'batch_size': 63, 'loss_fn': 1, 'lr': 0.0004467673511823808, 'n_layers': 3, 'linear_0_out': 2368, 'dropout_0': 0.4040651665817364, 'linear_1_out': 450, 'dropout_1': 0.19957124873623558}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:34,681]\u001b[0m Trial 420 finished with value: 0.9773333333333329 and parameters: {'scaler': 2, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.0004118052268043426, 'n_layers': 4, 'linear_0_out': 2496, 'dropout_0': 0.39483316497761456, 'linear_1_out': 657, 'dropout_1': 0.25661726455696143, 'linear_2_out': 1336, 'dropout_2': 0.44821976230262367}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:38,701]\u001b[0m Trial 421 finished with value: 0.9735881895881894 and parameters: {'scaler': 2, 'batch_size': 66, 'loss_fn': 1, 'lr': 0.0007615347003834792, 'n_layers': 3, 'linear_0_out': 958, 'dropout_0': 0.37045111645954937, 'linear_1_out': 529, 'dropout_1': 0.20344382886772858}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:41,310]\u001b[0m Trial 422 finished with value: 0.9784313725490194 and parameters: {'scaler': 2, 'batch_size': 66, 'loss_fn': 1, 'lr': 0.0009329400871381764, 'n_layers': 3, 'linear_0_out': 911, 'dropout_0': 0.35623761909782586, 'linear_1_out': 543, 'dropout_1': 0.22488978697726156}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:43,362]\u001b[0m Trial 423 finished with value: 0.9577182979622003 and parameters: {'scaler': 2, 'batch_size': 54, 'loss_fn': 1, 'lr': 0.0009297775943922928, 'n_layers': 2, 'linear_0_out': 1028, 'dropout_0': 0.34207593067927916}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:45,493]\u001b[0m Trial 424 finished with value: 0.9719065509531226 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.000267602294415285, 'n_layers': 3, 'linear_0_out': 2315, 'dropout_0': 0.4118480710343386, 'linear_1_out': 290, 'dropout_1': 0.23891306388122313}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:48,122]\u001b[0m Trial 425 finished with value: 0.07038327526132401 and parameters: {'scaler': 2, 'batch_size': 78, 'loss_fn': 2, 'lr': 0.0002450179333074949, 'n_layers': 4, 'linear_0_out': 1131, 'dropout_0': 0.38343805002275644, 'linear_1_out': 567, 'dropout_1': 0.17844830624737057, 'linear_2_out': 1555, 'dropout_2': 0.4277683688157479}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:50,677]\u001b[0m Trial 426 finished with value: 0.9792748601486181 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 0.0009197057224907914, 'n_layers': 3, 'linear_0_out': 2210, 'dropout_0': 0.4232897016650698, 'linear_1_out': 526, 'dropout_1': 0.14023881203131522}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:30:58,621]\u001b[0m Trial 427 finished with value: 0.9766739963115338 and parameters: {'scaler': 2, 'batch_size': 75, 'loss_fn': 1, 'lr': 0.000912969644011047, 'n_layers': 4, 'linear_0_out': 2392, 'dropout_0': 0.41938055449161865, 'linear_1_out': 609, 'dropout_1': 0.32212966904540274, 'linear_2_out': 917, 'dropout_2': 0.47106112177534554}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:31:01,439]\u001b[0m Trial 428 finished with value: 0.9548168249660787 and parameters: {'scaler': 1, 'batch_size': 95, 'loss_fn': 1, 'lr': 0.0009243683229240222, 'n_layers': 3, 'linear_0_out': 785, 'dropout_0': 0.3430234512353827, 'linear_1_out': 630, 'dropout_1': 0.20405951486657248}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:31:06,329]\u001b[0m Trial 429 finished with value: 0.9771278284887156 and parameters: {'scaler': 2, 'batch_size': 85, 'loss_fn': 1, 'lr': 0.0009922902436669359, 'n_layers': 2, 'linear_0_out': 2286, 'dropout_0': 0.32901620089296174}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:31:20,985]\u001b[0m Trial 430 finished with value: 0.9786117586117584 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.0009782477687514772, 'n_layers': 4, 'linear_0_out': 2295, 'dropout_0': 0.40788221395790164, 'linear_1_out': 564, 'dropout_1': 0.16107368995170185, 'linear_2_out': 103, 'dropout_2': 0.2259725719374136}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:31:30,085]\u001b[0m Trial 431 finished with value: 0.9767383328926493 and parameters: {'scaler': 2, 'batch_size': 85, 'loss_fn': 1, 'lr': 0.0002556483513406125, 'n_layers': 3, 'linear_0_out': 2412, 'dropout_0': 0.44888073238178294, 'linear_1_out': 436, 'dropout_1': 0.11795664975006287}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:32:30,728]\u001b[0m Trial 432 finished with value: 0.9798305860805862 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.000988330048483698, 'n_layers': 4, 'linear_0_out': 2492, 'dropout_0': 0.39569814364348826, 'linear_1_out': 416, 'dropout_1': 0.15830194398685546, 'linear_2_out': 2432, 'dropout_2': 0.45245196628923023}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:33:17,199]\u001b[0m Trial 433 finished with value: 0.0 and parameters: {'scaler': 2, 'batch_size': 93, 'loss_fn': 0, 'lr': 1.0303719922175292e-06, 'n_layers': 6, 'linear_0_out': 1967, 'dropout_0': 0.29162875476409805, 'linear_1_out': 310, 'dropout_1': 0.18801392141624929, 'linear_2_out': 2103, 'dropout_2': 0.45177575350888755, 'linear_3_out': 1777, 'dropout_3': 0.12357258299556756, 'linear_4_out': 1881, 'dropout_4': 0.2620130472954617}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:33:25,048]\u001b[0m Trial 434 finished with value: 0.9694531522117729 and parameters: {'scaler': 2, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.0003030997710557332, 'n_layers': 4, 'linear_0_out': 1176, 'dropout_0': 0.38638898997160354, 'linear_1_out': 523, 'dropout_1': 0.14232662722609424, 'linear_2_out': 160, 'dropout_2': 0.25220485966653156}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:33:36,479]\u001b[0m Trial 435 finished with value: 0.5320813771517995 and parameters: {'scaler': 3, 'batch_size': 49, 'loss_fn': 2, 'lr': 0.000695713477588327, 'n_layers': 3, 'linear_0_out': 2374, 'dropout_0': 0.45288683922987844, 'linear_1_out': 531, 'dropout_1': 0.13722357954485154}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:33:42,835]\u001b[0m Trial 436 finished with value: 0.9539575515694917 and parameters: {'scaler': 2, 'batch_size': 99, 'loss_fn': 1, 'lr': 0.0009281187656619838, 'n_layers': 4, 'linear_0_out': 1187, 'dropout_0': 0.3888519038295197, 'linear_1_out': 188, 'dropout_1': 0.22322971321436239, 'linear_2_out': 129, 'dropout_2': 0.24890272967963128}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:33:46,950]\u001b[0m Trial 437 finished with value: 0.39999999999999997 and parameters: {'scaler': 1, 'batch_size': 82, 'loss_fn': 1, 'lr': 5.437672222031525e-06, 'n_layers': 1}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:33:56,331]\u001b[0m Trial 438 finished with value: 0.6050742992232354 and parameters: {'scaler': 0, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.00017560471339810943, 'n_layers': 5, 'linear_0_out': 775, 'dropout_0': 0.3373234779093623, 'linear_1_out': 186, 'dropout_1': 0.263028413181361, 'linear_2_out': 1574, 'dropout_2': 0.43206364475023573, 'linear_3_out': 333, 'dropout_3': 0.39067044837939846}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:34:02,778]\u001b[0m Trial 439 finished with value: 0.9402639882333587 and parameters: {'scaler': 2, 'batch_size': 58, 'loss_fn': 1, 'lr': 0.00023619390899281813, 'n_layers': 2, 'linear_0_out': 2369, 'dropout_0': 0.39718546510894737}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:34:39,887]\u001b[0m Trial 440 finished with value: 0.9727272727272727 and parameters: {'scaler': 2, 'batch_size': 74, 'loss_fn': 1, 'lr': 0.0009319534878993391, 'n_layers': 4, 'linear_0_out': 2180, 'dropout_0': 0.27628970061638536, 'linear_1_out': 452, 'dropout_1': 0.12534755174000156, 'linear_2_out': 2321, 'dropout_2': 0.4807140494228559}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:34:50,628]\u001b[0m Trial 441 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 84, 'loss_fn': 1, 'lr': 0.0008469362892742636, 'n_layers': 3, 'linear_0_out': 2362, 'dropout_0': 0.4723479374048435, 'linear_1_out': 574, 'dropout_1': 0.2186739233654882}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:34:54,875]\u001b[0m Trial 442 finished with value: 0.4257672482668541 and parameters: {'scaler': 2, 'batch_size': 73, 'loss_fn': 1, 'lr': 0.0001705220720811459, 'n_layers': 1}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:05,165]\u001b[0m Trial 443 finished with value: 0.9746208291203237 and parameters: {'scaler': 2, 'batch_size': 60, 'loss_fn': 1, 'lr': 0.0006289221795286555, 'n_layers': 3, 'linear_0_out': 2435, 'dropout_0': 0.4237741479867772, 'linear_1_out': 357, 'dropout_1': 0.19280853491465808}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:08,674]\u001b[0m Trial 444 finished with value: 0.4658555065006677 and parameters: {'scaler': 2, 'batch_size': 88, 'loss_fn': 1, 'lr': 0.00026876567038474676, 'n_layers': 3, 'linear_0_out': 830, 'dropout_0': 0.36510938438730456, 'linear_1_out': 466, 'dropout_1': 0.13770080735952717}. Best is trial 356 with value: 0.9818391393442623.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:19,615]\u001b[0m Trial 445 finished with value: 0.9818783068783071 and parameters: {'scaler': 2, 'batch_size': 66, 'loss_fn': 1, 'lr': 0.0009561630720745768, 'n_layers': 4, 'linear_0_out': 2335, 'dropout_0': 0.3031297560027301, 'linear_1_out': 893, 'dropout_1': 0.2923717670502679, 'linear_2_out': 1741, 'dropout_2': 0.48206556058130473}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:23,950]\u001b[0m Trial 446 finished with value: 0.427536231884058 and parameters: {'scaler': 0, 'batch_size': 2, 'loss_fn': 0, 'lr': 1.7848127477456556e-06, 'n_layers': 2, 'linear_0_out': 2259, 'dropout_0': 0.26520276751685296}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:26,295]\u001b[0m Trial 447 finished with value: 0.9605226301046734 and parameters: {'scaler': 0, 'batch_size': 72, 'loss_fn': 1, 'lr': 0.0009169445706265211, 'n_layers': 3, 'linear_0_out': 2407, 'dropout_0': 0.29565874471653597, 'linear_1_out': 380, 'dropout_1': 0.3254724104075567}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:28,541]\u001b[0m Trial 448 finished with value: 0.4823953823953824 and parameters: {'scaler': 2, 'batch_size': 89, 'loss_fn': 1, 'lr': 0.0008849154718397873, 'n_layers': 3, 'linear_0_out': 867, 'dropout_0': 0.3615914155523251, 'linear_1_out': 994, 'dropout_1': 0.23501480838652172}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:38,453]\u001b[0m Trial 449 finished with value: 0.9784313725490194 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.0008678173768211097, 'n_layers': 5, 'linear_0_out': 2429, 'dropout_0': 0.35590999699941805, 'linear_1_out': 1423, 'dropout_1': 0.2901661568247361, 'linear_2_out': 1048, 'dropout_2': 0.4897045677057781, 'linear_3_out': 5, 'dropout_3': 0.48737230250010666}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:40,347]\u001b[0m Trial 450 finished with value: 0.9614189362247074 and parameters: {'scaler': 2, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.0009571110269756431, 'n_layers': 2, 'linear_0_out': 884, 'dropout_0': 0.33279381084245235}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:35:43,107]\u001b[0m Trial 451 finished with value: 0.9756944444444444 and parameters: {'scaler': 2, 'batch_size': 62, 'loss_fn': 1, 'lr': 0.0007483533719594353, 'n_layers': 4, 'linear_0_out': 2316, 'dropout_0': 0.3538366029050679, 'linear_1_out': 167, 'dropout_1': 0.2400258283488945, 'linear_2_out': 889, 'dropout_2': 0.49822719847335756}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:36:06,146]\u001b[0m Trial 452 finished with value: 0.9793980128579778 and parameters: {'scaler': 2, 'batch_size': 78, 'loss_fn': 1, 'lr': 0.0008210900056164686, 'n_layers': 6, 'linear_0_out': 1292, 'dropout_0': 0.4370500255236415, 'linear_1_out': 1108, 'dropout_1': 0.2740359693317849, 'linear_2_out': 988, 'dropout_2': 0.48228230352230567, 'linear_3_out': 2095, 'dropout_3': 0.4330850276286033, 'linear_4_out': 782, 'dropout_4': 0.16313221086509988}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:36:49,928]\u001b[0m Trial 453 finished with value: 0.9755977520210642 and parameters: {'scaler': 2, 'batch_size': 81, 'loss_fn': 1, 'lr': 0.0002596477775614526, 'n_layers': 5, 'linear_0_out': 2297, 'dropout_0': 0.47445942356522075, 'linear_1_out': 1214, 'dropout_1': 0.32838247254371034, 'linear_2_out': 2165, 'dropout_2': 0.48248885867194397, 'linear_3_out': 834, 'dropout_3': 0.4441639785631295}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:37:24,599]\u001b[0m Trial 454 finished with value: 0.9742194469223909 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.0007549085428888658, 'n_layers': 7, 'linear_0_out': 1336, 'dropout_0': 0.42685527534741335, 'linear_1_out': 1067, 'dropout_1': 0.2529253198815304, 'linear_2_out': 2433, 'dropout_2': 0.4774758233585071, 'linear_3_out': 11, 'dropout_3': 0.08532810996350432, 'linear_4_out': 412, 'dropout_4': 0.28886764694662165, 'linear_5_out': 3, 'dropout_5': 0.19975279952905217}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:37:46,305]\u001b[0m Trial 455 finished with value: 0.970429466698057 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.000567219860189962, 'n_layers': 6, 'linear_0_out': 1127, 'dropout_0': 0.3965885696715377, 'linear_1_out': 1651, 'dropout_1': 0.28799769461144564, 'linear_2_out': 894, 'dropout_2': 0.4937084762007006, 'linear_3_out': 18, 'dropout_3': 0.3303454069984864, 'linear_4_out': 34, 'dropout_4': 0.32433814974219666}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:38:45,887]\u001b[0m Trial 456 finished with value: 0.9731851851851848 and parameters: {'scaler': 2, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.0008207768084695565, 'n_layers': 5, 'linear_0_out': 2331, 'dropout_0': 0.42729858263331794, 'linear_1_out': 903, 'dropout_1': 0.2917315932194328, 'linear_2_out': 1874, 'dropout_2': 0.45617916141019965, 'linear_3_out': 565, 'dropout_3': 0.35353627613284044}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:39:19,936]\u001b[0m Trial 457 finished with value: 0.972857892594735 and parameters: {'scaler': 2, 'batch_size': 72, 'loss_fn': 1, 'lr': 0.0003569467021359129, 'n_layers': 5, 'linear_0_out': 1127, 'dropout_0': 0.42185850815619924, 'linear_1_out': 1967, 'dropout_1': 0.28205513845683544, 'linear_2_out': 1236, 'dropout_2': 0.4833551638457117, 'linear_3_out': 146, 'dropout_3': 0.45323386491150114}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:39:46,891]\u001b[0m Trial 458 finished with value: 0.4811826101905119 and parameters: {'scaler': 2, 'batch_size': 90, 'loss_fn': 1, 'lr': 0.0009357929544430709, 'n_layers': 5, 'linear_0_out': 1200, 'dropout_0': 0.4211896701601681, 'linear_1_out': 881, 'dropout_1': 0.1747234562946636, 'linear_2_out': 1848, 'dropout_2': 0.4931275075702931, 'linear_3_out': 9, 'dropout_3': 0.25377824942648286}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:39:57,129]\u001b[0m Trial 459 finished with value: 0.9501735764235765 and parameters: {'scaler': 2, 'batch_size': 91, 'loss_fn': 1, 'lr': 0.00019565327668777225, 'n_layers': 3, 'linear_0_out': 2435, 'dropout_0': 0.3755623751285095, 'linear_1_out': 717, 'dropout_1': 0.33194325068694475}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:04,526]\u001b[0m Trial 460 finished with value: 0.4823953823953824 and parameters: {'scaler': 2, 'batch_size': 89, 'loss_fn': 1, 'lr': 0.0007543546499528898, 'n_layers': 3, 'linear_0_out': 949, 'dropout_0': 0.3402756595606381, 'linear_1_out': 629, 'dropout_1': 0.15384908569660208}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:11,233]\u001b[0m Trial 461 finished with value: 0.06976744186046512 and parameters: {'scaler': 2, 'batch_size': 81, 'loss_fn': 2, 'lr': 0.0005265568185588578, 'n_layers': 7, 'linear_0_out': 2195, 'dropout_0': 0.29757570821840196, 'linear_1_out': 487, 'dropout_1': 0.14104663951490878, 'linear_2_out': 817, 'dropout_2': 0.4982926332765936, 'linear_3_out': 409, 'dropout_3': 0.11201719849600356, 'linear_4_out': 7, 'dropout_4': 0.3421365225771181, 'linear_5_out': 491, 'dropout_5': 0.4431823941548506}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:12,967]\u001b[0m Trial 462 finished with value: 0.3060606060606061 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 2.0917149839569978e-06, 'n_layers': 1}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:15,707]\u001b[0m Trial 463 finished with value: 0.4823953823953824 and parameters: {'scaler': 2, 'batch_size': 87, 'loss_fn': 1, 'lr': 0.0007933632496712876, 'n_layers': 3, 'linear_0_out': 2475, 'dropout_0': 0.4458374126319467, 'linear_1_out': 560, 'dropout_1': 0.17292261483893992}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:22,659]\u001b[0m Trial 464 finished with value: 0.043387586952117245 and parameters: {'scaler': 2, 'batch_size': 64, 'loss_fn': 0, 'lr': 0.0006901580298318977, 'n_layers': 8, 'linear_0_out': 2185, 'dropout_0': 0.309987425732305, 'linear_1_out': 1457, 'dropout_1': 0.24653618429083332, 'linear_2_out': 2225, 'dropout_2': 0.4962228588761574, 'linear_3_out': 42, 'dropout_3': 0.3581480461874537, 'linear_4_out': 5, 'dropout_4': 0.15737962620023, 'linear_5_out': 163, 'dropout_5': 0.07394177600324836, 'linear_6_out': 1800, 'dropout_6': 0.06392873889425016}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:35,810]\u001b[0m Trial 465 finished with value: 0.9793964748223567 and parameters: {'scaler': 2, 'batch_size': 78, 'loss_fn': 1, 'lr': 0.0007303177868409044, 'n_layers': 4, 'linear_0_out': 2320, 'dropout_0': 0.4993178756996489, 'linear_1_out': 894, 'dropout_1': 0.19608092585912046, 'linear_2_out': 2306, 'dropout_2': 0.42815813483937737}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:45,103]\u001b[0m Trial 466 finished with value: 0.9709066859066858 and parameters: {'scaler': 2, 'batch_size': 69, 'loss_fn': 1, 'lr': 0.0008964913861999014, 'n_layers': 7, 'linear_0_out': 2473, 'dropout_0': 0.49666764820998327, 'linear_1_out': 876, 'dropout_1': 0.19420246735381858, 'linear_2_out': 2385, 'dropout_2': 0.4428544951102612, 'linear_3_out': 477, 'dropout_3': 0.1593069276343126, 'linear_4_out': 345, 'dropout_4': 0.2023788539408532, 'linear_5_out': 385, 'dropout_5': 0.4501691713528147}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:40:52,160]\u001b[0m Trial 467 finished with value: 0.06849315068493152 and parameters: {'scaler': 2, 'batch_size': 68, 'loss_fn': 2, 'lr': 0.0008327858550508855, 'n_layers': 5, 'linear_0_out': 2493, 'dropout_0': 0.4335419248004742, 'linear_1_out': 387, 'dropout_1': 0.11654183683117825, 'linear_2_out': 1033, 'dropout_2': 0.40087032536198813, 'linear_3_out': 125, 'dropout_3': 0.08196403341354319}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:42:39,156]\u001b[0m Trial 468 finished with value: 0.9740450678615493 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.00028826107622293616, 'n_layers': 5, 'linear_0_out': 2414, 'dropout_0': 0.4424183132796627, 'linear_1_out': 874, 'dropout_1': 0.2110885387841975, 'linear_2_out': 2363, 'dropout_2': 0.4222522178992955, 'linear_3_out': 1739, 'dropout_3': 0.2662427914230276}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:43:07,965]\u001b[0m Trial 469 finished with value: 0.9757609057609058 and parameters: {'scaler': 2, 'batch_size': 84, 'loss_fn': 1, 'lr': 0.0007893511526627994, 'n_layers': 5, 'linear_0_out': 1310, 'dropout_0': 0.4258455697741423, 'linear_1_out': 273, 'dropout_1': 0.20502262073447738, 'linear_2_out': 2156, 'dropout_2': 0.4374583633922817, 'linear_3_out': 9, 'dropout_3': 0.20421365028149013}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:43:24,870]\u001b[0m Trial 470 finished with value: 0.478561422528683 and parameters: {'scaler': 2, 'batch_size': 87, 'loss_fn': 1, 'lr': 0.00031779722387881775, 'n_layers': 4, 'linear_0_out': 2490, 'dropout_0': 0.4051624180625156, 'linear_1_out': 765, 'dropout_1': 0.13512268097551383, 'linear_2_out': 1459, 'dropout_2': 0.42306707822813555}. Best is trial 445 with value: 0.9818783068783071.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:44:09,442]\u001b[0m Trial 471 finished with value: 0.9825190358209227 and parameters: {'scaler': 2, 'batch_size': 70, 'loss_fn': 1, 'lr': 0.0009363244593836366, 'n_layers': 5, 'linear_0_out': 1180, 'dropout_0': 0.41254567127451774, 'linear_1_out': 667, 'dropout_1': 0.1841969635108051, 'linear_2_out': 2450, 'dropout_2': 0.4578606088564118, 'linear_3_out': 316, 'dropout_3': 0.46765020419328074}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:44:15,077]\u001b[0m Trial 472 finished with value: 0.0615869697761519 and parameters: {'scaler': 2, 'batch_size': 85, 'loss_fn': 2, 'lr': 0.00019738554145739716, 'n_layers': 2, 'linear_0_out': 2431, 'dropout_0': 0.46608082468621354}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:08,982]\u001b[0m Trial 473 finished with value: 0.9761235350210711 and parameters: {'scaler': 2, 'batch_size': 76, 'loss_fn': 1, 'lr': 0.0008429716695199021, 'n_layers': 4, 'linear_0_out': 2490, 'dropout_0': 0.48754996410790596, 'linear_1_out': 761, 'dropout_1': 0.164979686012132, 'linear_2_out': 2226, 'dropout_2': 0.4370928083437538}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:16,602]\u001b[0m Trial 474 finished with value: 0.9792748601486181 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.0009183017919360644, 'n_layers': 5, 'linear_0_out': 1245, 'dropout_0': 0.43146242327745327, 'linear_1_out': 1018, 'dropout_1': 0.17787720179255948, 'linear_2_out': 668, 'dropout_2': 0.49686497846717026, 'linear_3_out': 1250, 'dropout_3': 0.07014464895024736}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:21,338]\u001b[0m Trial 475 finished with value: 0.0 and parameters: {'scaler': 3, 'batch_size': 29, 'loss_fn': 1, 'lr': 2.2282591848085926e-05, 'n_layers': 10, 'linear_0_out': 887, 'dropout_0': 0.436510643312898, 'linear_1_out': 932, 'dropout_1': 0.14739175125819093, 'linear_2_out': 624, 'dropout_2': 0.4480483274384045, 'linear_3_out': 966, 'dropout_3': 0.2950835901581069, 'linear_4_out': 31, 'dropout_4': 0.2321835121667037, 'linear_5_out': 545, 'dropout_5': 0.4223875397014929, 'linear_6_out': 198, 'dropout_6': 0.02923064651394658, 'linear_7_out': 604, 'dropout_7': 0.01287210687493473, 'linear_8_out': 27, 'dropout_8': 0.22208371885605915}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:24,993]\u001b[0m Trial 476 finished with value: 0.9793088067919651 and parameters: {'scaler': 2, 'batch_size': 77, 'loss_fn': 1, 'lr': 0.0008817324389853034, 'n_layers': 5, 'linear_0_out': 950, 'dropout_0': 0.42899803191638997, 'linear_1_out': 487, 'dropout_1': 0.10411999394378356, 'linear_2_out': 871, 'dropout_2': 0.4868051476185108, 'linear_3_out': 64, 'dropout_3': 0.12797669639753217}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:27,940]\u001b[0m Trial 477 finished with value: 0.8205043577296072 and parameters: {'scaler': 2, 'batch_size': 99, 'loss_fn': 1, 'lr': 0.000997875773979011, 'n_layers': 6, 'linear_0_out': 1027, 'dropout_0': 0.41559581361752385, 'linear_1_out': 265, 'dropout_1': 0.09518150195119887, 'linear_2_out': 652, 'dropout_2': 0.45850072622960475, 'linear_3_out': 34, 'dropout_3': 0.3936492132941991, 'linear_4_out': 11, 'dropout_4': 0.4066253809858515}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:30,102]\u001b[0m Trial 478 finished with value: 0.9539575515694917 and parameters: {'scaler': 2, 'batch_size': 91, 'loss_fn': 1, 'lr': 0.000987532063667221, 'n_layers': 3, 'linear_0_out': 849, 'dropout_0': 0.39444392986964694, 'linear_1_out': 474, 'dropout_1': 0.12409526627132947}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:32,051]\u001b[0m Trial 479 finished with value: 0.7664638560893853 and parameters: {'scaler': 0, 'batch_size': 99, 'loss_fn': 1, 'lr': 0.0001549211751760615, 'n_layers': 2, 'linear_0_out': 1011, 'dropout_0': 0.4224700520849849}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:34,297]\u001b[0m Trial 480 finished with value: 0.516941391941392 and parameters: {'scaler': 3, 'batch_size': 75, 'loss_fn': 0, 'lr': 0.00026194915203300634, 'n_layers': 3, 'linear_0_out': 876, 'dropout_0': 0.42386577903754125, 'linear_1_out': 1002, 'dropout_1': 0.21547673610322687}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:38,648]\u001b[0m Trial 481 finished with value: 0.48043871551334244 and parameters: {'scaler': 2, 'batch_size': 87, 'loss_fn': 1, 'lr': 0.0008931370273110804, 'n_layers': 4, 'linear_0_out': 885, 'dropout_0': 0.4011028841703496, 'linear_1_out': 933, 'dropout_1': 0.20815049927476148, 'linear_2_out': 868, 'dropout_2': 0.4945860289072796}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:41,174]\u001b[0m Trial 482 finished with value: 0.9732588547205483 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 1, 'lr': 0.0003197201066754723, 'n_layers': 4, 'linear_0_out': 1112, 'dropout_0': 0.4478221484062238, 'linear_1_out': 381, 'dropout_1': 0.09320010564647255, 'linear_2_out': 819, 'dropout_2': 0.4775650756628653}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:44,263]\u001b[0m Trial 483 finished with value: 0.8913845741692189 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.0006288657775049987, 'n_layers': 5, 'linear_0_out': 1105, 'dropout_0': 0.4200463546971664, 'linear_1_out': 873, 'dropout_1': 0.1249484035301952, 'linear_2_out': 742, 'dropout_2': 0.4998404067262506, 'linear_3_out': 2, 'dropout_3': 0.0713994334540553}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:45,892]\u001b[0m Trial 484 finished with value: 0.24183598915661078 and parameters: {'scaler': 2, 'batch_size': 88, 'loss_fn': 1, 'lr': 0.0002944966809639329, 'n_layers': 1}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:48,277]\u001b[0m Trial 485 finished with value: 0.05494505494505496 and parameters: {'scaler': 2, 'batch_size': 86, 'loss_fn': 0, 'lr': 0.00024114201173099892, 'n_layers': 3, 'linear_0_out': 2076, 'dropout_0': 0.4881902646307189, 'linear_1_out': 550, 'dropout_1': 0.28712388016889134}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:45:56,585]\u001b[0m Trial 486 finished with value: 0.4775440976933515 and parameters: {'scaler': 2, 'batch_size': 88, 'loss_fn': 1, 'lr': 0.0009780325868427558, 'n_layers': 6, 'linear_0_out': 862, 'dropout_0': 0.3975819384696663, 'linear_1_out': 721, 'dropout_1': 0.18118968379774722, 'linear_2_out': 2419, 'dropout_2': 0.4267015385427209, 'linear_3_out': 1437, 'dropout_3': 0.2351999646104565, 'linear_4_out': 2, 'dropout_4': 0.3052216263138644}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:46:01,448]\u001b[0m Trial 487 finished with value: 0.9165961641272826 and parameters: {'scaler': 2, 'batch_size': 57, 'loss_fn': 1, 'lr': 0.00025012515745802174, 'n_layers': 6, 'linear_0_out': 924, 'dropout_0': 0.37556057327154446, 'linear_1_out': 839, 'dropout_1': 0.15091733443391792, 'linear_2_out': 769, 'dropout_2': 0.49722240309390286, 'linear_3_out': 44, 'dropout_3': 0.044293834400900955, 'linear_4_out': 20, 'dropout_4': 0.30721304217699946}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:46:29,191]\u001b[0m Trial 488 finished with value: 0.9782116281085796 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.000996209436128558, 'n_layers': 5, 'linear_0_out': 2408, 'dropout_0': 0.4013969432029061, 'linear_1_out': 262, 'dropout_1': 0.1798461934994979, 'linear_2_out': 2482, 'dropout_2': 0.4037907124502943, 'linear_3_out': 158, 'dropout_3': 0.44345151480287925}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:46:37,680]\u001b[0m Trial 489 finished with value: 0.9778492109877265 and parameters: {'scaler': 2, 'batch_size': 80, 'loss_fn': 1, 'lr': 0.000202602011491237, 'n_layers': 3, 'linear_0_out': 949, 'dropout_0': 0.3695980352349966, 'linear_1_out': 987, 'dropout_1': 0.2715722791791332}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:46:59,066]\u001b[0m Trial 490 finished with value: 0.9810329447229996 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.0009376543077468199, 'n_layers': 3, 'linear_0_out': 2474, 'dropout_0': 0.49484255018346496, 'linear_1_out': 1219, 'dropout_1': 0.22037098683402595}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:47:05,101]\u001b[0m Trial 491 finished with value: 0.9721470605896835 and parameters: {'scaler': 2, 'batch_size': 85, 'loss_fn': 1, 'lr': 0.0007748068416359011, 'n_layers': 2, 'linear_0_out': 1245, 'dropout_0': 0.49812767467585184}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:47:22,074]\u001b[0m Trial 492 finished with value: 0.9473104352449561 and parameters: {'scaler': 2, 'batch_size': 99, 'loss_fn': 1, 'lr': 0.00016397522179737145, 'n_layers': 4, 'linear_0_out': 2488, 'dropout_0': 0.4946015615201958, 'linear_1_out': 873, 'dropout_1': 0.207987520061888, 'linear_2_out': 2432, 'dropout_2': 0.3863680704729826}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:47:27,481]\u001b[0m Trial 493 finished with value: 0.5440000000000002 and parameters: {'scaler': 3, 'batch_size': 100, 'loss_fn': 0, 'lr': 0.0007262491116656142, 'n_layers': 2, 'linear_0_out': 2311, 'dropout_0': 0.4903439657101474}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:47:40,473]\u001b[0m Trial 494 finished with value: 0.9663517027455084 and parameters: {'scaler': 1, 'batch_size': 78, 'loss_fn': 1, 'lr': 0.00031367418139488653, 'n_layers': 4, 'linear_0_out': 1153, 'dropout_0': 0.46141509104684264, 'linear_1_out': 608, 'dropout_1': 0.0936320494757854, 'linear_2_out': 2384, 'dropout_2': 0.41068545672263246}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:47:57,831]\u001b[0m Trial 495 finished with value: 0.977687072264852 and parameters: {'scaler': 2, 'batch_size': 83, 'loss_fn': 1, 'lr': 0.0002779517949879144, 'n_layers': 4, 'linear_0_out': 1105, 'dropout_0': 0.43175019535375786, 'linear_1_out': 1078, 'dropout_1': 0.20716299852403908, 'linear_2_out': 2347, 'dropout_2': 0.48577155484333806}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:48:50,841]\u001b[0m Trial 496 finished with value: 0.9704198808710089 and parameters: {'scaler': 2, 'batch_size': 71, 'loss_fn': 1, 'lr': 0.0009627927767880109, 'n_layers': 5, 'linear_0_out': 1164, 'dropout_0': 0.4596828161268173, 'linear_1_out': 1030, 'dropout_1': 0.16252921185526575, 'linear_2_out': 1850, 'dropout_2': 0.48383585997741846, 'linear_3_out': 58, 'dropout_3': 0.052368896970540146}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:48:58,596]\u001b[0m Trial 497 finished with value: 0.9603110653856923 and parameters: {'scaler': 2, 'batch_size': 97, 'loss_fn': 1, 'lr': 0.0009091764191925919, 'n_layers': 3, 'linear_0_out': 2203, 'dropout_0': 0.49489701084388643, 'linear_1_out': 233, 'dropout_1': 0.18327176858076138}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:49:15,421]\u001b[0m Trial 498 finished with value: 0.9800930950989395 and parameters: {'scaler': 2, 'batch_size': 79, 'loss_fn': 1, 'lr': 0.0008864407461408658, 'n_layers': 3, 'linear_0_out': 2272, 'dropout_0': 0.34073978438536356, 'linear_1_out': 975, 'dropout_1': 0.16725236177005637}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n",
      "\u001b[32m[I 2022-11-03 18:49:29,566]\u001b[0m Trial 499 finished with value: 0.05157212059721683 and parameters: {'scaler': 2, 'batch_size': 92, 'loss_fn': 0, 'lr': 0.0008088882804232447, 'n_layers': 3, 'linear_0_out': 2488, 'dropout_0': 0.4011687644005178, 'linear_1_out': 945, 'dropout_1': 0.13009397971245035}. Best is trial 471 with value: 0.9825190358209227.\u001b[0m\n"
     ],
     "output_type":"stream"
    },
    {
     "name":"stderr",
     "text":[
      "<ipython-input-22-7439391e44c9>:2: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  tensorboard_callback_nn = TensorBoardCallback(TENSORBOARD_LOGDIR_NN_SHALLOW + '\/', metric_name=\"F1\")\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/optuna\/samplers\/_tpe\/sampler.py:281: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/optuna\/samplers\/_tpe\/sampler.py:292: ExperimentalWarning: ``group`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-03 17:39:35,978]\u001b[0m A new study created in RDB with name: nn_shallow\u001b[0m\n",
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/optuna\/progress_bar.py:49: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"2e2302b3388a420eb06d1dd1458e816c"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"qbuk0mW2OTMipiOKFzJR1B"
       }
      }
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"cCzdDxifEvPHLS76LwbRnS",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Lets check the results of this:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"WMl5qqCDys887z0JOn9E8J",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "study.best_params"
   ],
   "execution_count":23,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "{'batch_size': 70,\n",
       " 'dropout_0': 0.41254567127451774,\n",
       " 'dropout_1': 0.1841969635108051,\n",
       " 'dropout_2': 0.4578606088564118,\n",
       " 'dropout_3': 0.46765020419328074,\n",
       " 'linear_0_out': 1180,\n",
       " 'linear_1_out': 667,\n",
       " 'linear_2_out': 2450,\n",
       " 'linear_3_out': 316,\n",
       " 'loss_fn': 1,\n",
       " 'lr': 0.0009363244593836366,\n",
       " 'n_layers': 5,\n",
       " 'scaler': 2}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"nyEzWuh7WPG1swN8RCh6Xr",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "You can comment-in the next cell to take a look at the results of the parameter search. set the parameter to e.g. TENSORBOARD_LOGDIR_NN_SHALLOW if you want to view the board for the previous search of hyper parameters for the shallow neural network. Unfortunately switching back and forth between different boards only seem to work if you restart the notebooks kernel in between."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"CfW2qQVVMleKKXUlieihAH",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# view_tensorboard(TENSORBOARD_LOGDIR_NN_SHALLOW)"
   ],
   "execution_count":24,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"4qwztvc9LfyFatl8FUpOyK",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Alternatively, if you are running this code locally, you can enter localhost:x into your browser where x is the port given by the method call below."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"fSXF483iYZKYWjRsC3ttk9",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# notebook.list()"
   ],
   "execution_count":47,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"RXvIhix05wKZuRHlgBOI1O",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "In this cell the importance of the hyperparameters is calculated. Note that this graph will differ ever so slightly at each run because of some randomness. Unfortunately I was not able to find the right way to set a seed manually.\n",
    "\n",
    "Quite surprisingly when I first ran this code the number of learnable model parameters (that is the number of weights the model has - here defined by linear_0_out and linear_1_out) almost did not matter! It is tempting to just disregard these variables now, but the error I made was in the assumption that the ideal parameter for the sizes of the layers lie in a much lower rates. As a reaction I changed these ranges and their importance in this graph went up.\n",
    "\n",
    "(In the current state of the project these parameters cannot be seen in this graph anymore, since the depth of the network is now determined dynamically. However, I am sure that there are options to change this.)"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"QVA3KXI3GFpSkWBjJjxmMq",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "optuna.visualization.plot_param_importances(study, evaluator=optuna.importance.FanovaImportanceEvaluator(n_trees=10, max_depth=8), target_name='F1')"
   ],
   "execution_count":26,
   "outputs":[
    {
     "data":{
      "application\/vnd.plotly.v1+json":{
       "data":[
        {
         "cliponaxis":false,
         "hovertemplate":[
          "batch_size (IntDistribution): 0.057516401537278106<extra><\/extra>",
          "n_layers (IntDistribution): 0.09559588169118181<extra><\/extra>",
          "lr (FloatDistribution): 0.16709272454786986<extra><\/extra>",
          "loss_fn (CategoricalDistribution): 0.2941159250459715<extra><\/extra>",
          "scaler (CategoricalDistribution): 0.38567906717769873<extra><\/extra>"
         ],
         "marker":{
          "color":"rgb(66,146,198)"
         },
         "orientation":"h",
         "text":[
          "0.06",
          "0.10",
          "0.17",
          "0.29",
          "0.39"
         ],
         "textposition":"outside",
         "x":[
          0.057516401537278106,
          0.09559588169118181,
          0.16709272454786986,
          0.2941159250459715,
          0.38567906717769873
         ],
         "y":[
          "batch_size",
          "n_layers",
          "lr",
          "loss_fn",
          "scaler"
         ],
         "type":"bar"
        }
       ],
       "layout":{
        "showlegend":false,
        "title":{
         "text":"Hyperparameter Importances"
        },
        "xaxis":{
         "title":{
          "text":"Importance for F1"
         }
        },
        "yaxis":{
         "title":{
          "text":"Hyperparameter"
         }
        },
        "template":{
         "data":{
          "bar":[
           {
            "error_x":{
             "color":"#2a3f5f"
            },
            "error_y":{
             "color":"#2a3f5f"
            },
            "marker":{
             "line":{
              "color":"#E5ECF6",
              "width":0.5
             },
             "pattern":{
              "fillmode":"overlay",
              "size":10,
              "solidity":0.2
             }
            },
            "type":"bar"
           }
          ],
          "barpolar":[
           {
            "marker":{
             "line":{
              "color":"#E5ECF6",
              "width":0.5
             },
             "pattern":{
              "fillmode":"overlay",
              "size":10,
              "solidity":0.2
             }
            },
            "type":"barpolar"
           }
          ],
          "carpet":[
           {
            "aaxis":{
             "endlinecolor":"#2a3f5f",
             "gridcolor":"white",
             "linecolor":"white",
             "minorgridcolor":"white",
             "startlinecolor":"#2a3f5f"
            },
            "baxis":{
             "endlinecolor":"#2a3f5f",
             "gridcolor":"white",
             "linecolor":"white",
             "minorgridcolor":"white",
             "startlinecolor":"#2a3f5f"
            },
            "type":"carpet"
           }
          ],
          "choropleth":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "type":"choropleth"
           }
          ],
          "contour":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "colorscale":[
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type":"contour"
           }
          ],
          "contourcarpet":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "type":"contourcarpet"
           }
          ],
          "heatmap":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "colorscale":[
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type":"heatmap"
           }
          ],
          "heatmapgl":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "colorscale":[
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type":"heatmapgl"
           }
          ],
          "histogram":[
           {
            "marker":{
             "pattern":{
              "fillmode":"overlay",
              "size":10,
              "solidity":0.2
             }
            },
            "type":"histogram"
           }
          ],
          "histogram2d":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "colorscale":[
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type":"histogram2d"
           }
          ],
          "histogram2dcontour":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "colorscale":[
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type":"histogram2dcontour"
           }
          ],
          "mesh3d":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "type":"mesh3d"
           }
          ],
          "parcoords":[
           {
            "line":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"parcoords"
           }
          ],
          "pie":[
           {
            "automargin":true,
            "type":"pie"
           }
          ],
          "scatter":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scatter"
           }
          ],
          "scatter3d":[
           {
            "line":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scatter3d"
           }
          ],
          "scattercarpet":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scattercarpet"
           }
          ],
          "scattergeo":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scattergeo"
           }
          ],
          "scattergl":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scattergl"
           }
          ],
          "scattermapbox":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scattermapbox"
           }
          ],
          "scatterpolar":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scatterpolar"
           }
          ],
          "scatterpolargl":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scatterpolargl"
           }
          ],
          "scatterternary":[
           {
            "marker":{
             "colorbar":{
              "outlinewidth":0,
              "ticks":""
             }
            },
            "type":"scatterternary"
           }
          ],
          "surface":[
           {
            "colorbar":{
             "outlinewidth":0,
             "ticks":""
            },
            "colorscale":[
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type":"surface"
           }
          ],
          "table":[
           {
            "cells":{
             "fill":{
              "color":"#EBF0F8"
             },
             "line":{
              "color":"white"
             }
            },
            "header":{
             "fill":{
              "color":"#C8D4E3"
             },
             "line":{
              "color":"white"
             }
            },
            "type":"table"
           }
          ]
         },
         "layout":{
          "annotationdefaults":{
           "arrowcolor":"#2a3f5f",
           "arrowhead":0,
           "arrowwidth":1
          },
          "autotypenumbers":"strict",
          "coloraxis":{
           "colorbar":{
            "outlinewidth":0,
            "ticks":""
           }
          },
          "colorscale":{
           "diverging":[
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential":[
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus":[
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway":[
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font":{
           "color":"#2a3f5f"
          },
          "geo":{
           "bgcolor":"white",
           "lakecolor":"white",
           "landcolor":"#E5ECF6",
           "showlakes":true,
           "showland":true,
           "subunitcolor":"white"
          },
          "hoverlabel":{
           "align":"left"
          },
          "hovermode":"closest",
          "mapbox":{
           "style":"light"
          },
          "paper_bgcolor":"white",
          "plot_bgcolor":"#E5ECF6",
          "polar":{
           "angularaxis":{
            "gridcolor":"white",
            "linecolor":"white",
            "ticks":""
           },
           "bgcolor":"#E5ECF6",
           "radialaxis":{
            "gridcolor":"white",
            "linecolor":"white",
            "ticks":""
           }
          },
          "scene":{
           "xaxis":{
            "backgroundcolor":"#E5ECF6",
            "gridcolor":"white",
            "gridwidth":2,
            "linecolor":"white",
            "showbackground":true,
            "ticks":"",
            "zerolinecolor":"white"
           },
           "yaxis":{
            "backgroundcolor":"#E5ECF6",
            "gridcolor":"white",
            "gridwidth":2,
            "linecolor":"white",
            "showbackground":true,
            "ticks":"",
            "zerolinecolor":"white"
           },
           "zaxis":{
            "backgroundcolor":"#E5ECF6",
            "gridcolor":"white",
            "gridwidth":2,
            "linecolor":"white",
            "showbackground":true,
            "ticks":"",
            "zerolinecolor":"white"
           }
          },
          "shapedefaults":{
           "line":{
            "color":"#2a3f5f"
           }
          },
          "ternary":{
           "aaxis":{
            "gridcolor":"white",
            "linecolor":"white",
            "ticks":""
           },
           "baxis":{
            "gridcolor":"white",
            "linecolor":"white",
            "ticks":""
           },
           "bgcolor":"#E5ECF6",
           "caxis":{
            "gridcolor":"white",
            "linecolor":"white",
            "ticks":""
           }
          },
          "title":{
           "x":0.05
          },
          "xaxis":{
           "automargin":true,
           "gridcolor":"white",
           "linecolor":"white",
           "ticks":"",
           "title":{
            "standoff":15
           },
           "zerolinecolor":"white",
           "zerolinewidth":2
          },
          "yaxis":{
           "automargin":true,
           "gridcolor":"white",
           "linecolor":"white",
           "ticks":"",
           "title":{
            "standoff":15
           },
           "zerolinecolor":"white",
           "zerolinewidth":2
          }
         }
        }
       },
       "config":{
        "plotlyServerURL":"https:\/\/plot.ly"
       }
      }
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"beVWYAWzK8JUihIvKknRwi",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Now let's see if the results calculated on the validation sets are comparable with those in the test set. If the test performance is significantly worse, then we might have accidentally used information of data from the validation split when training the model before. Pay special attention to aggregates of the dataset you use or metrics that were calculated over parts of the dataset."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"cJOOVJr5aLS0B454pjA6NA",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "best_params = study.best_params\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        temp = []\n",
    "        last_input = input_size\n",
    "        for i in range(n_layers := best_params['n_layers']):\n",
    "            is_final_layer = i == n_layers - 1\n",
    "            if is_final_layer:\n",
    "                linear_out = 2\n",
    "            else:\n",
    "                linear_out = best_params[f'linear_{i}_out']\n",
    "\n",
    "            temp.append(nn.Linear(last_input, linear_out))\n",
    "            last_input = linear_out\n",
    "\n",
    "            if not is_final_layer:\n",
    "                temp.append(nn.Dropout(p=best_params[f'dropout_{i}']))\n",
    "                temp.append(nn.LeakyReLU())\n",
    "\n",
    "        self.linear_leaky_relu_stack = nn.Sequential(\n",
    "            *temp\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_leaky_relu_stack(x)\n",
    "        return nn.functional.softmax(logits, 1) # 1 is the dimension\n",
    "\n",
    "# Reducing randomness of result by averaging accross multiple random seeds\n",
    "scores = []\n",
    "for i in range(10):\n",
    "    torch.manual_seed(i)\n",
    "    val_score, best_epochs = test_params(None, datasets_tvt, NeuralNetwork, scalers[best_params['scaler']], best_params['batch_size'], loss_functions[best_params['loss_fn']], best_params['lr'], False)\n",
    "\n",
    "    final_model = NeuralNetwork(all_X_train.shape[1] - 1)\n",
    "    training_set = pd.DataFrame(scalers[best_params['scaler']].fit_transform(all_X_train.to_numpy()), columns=all_X_train.columns)\n",
    "    torch.manual_seed(i)\n",
    "    train_loader = DataLoader(CancerDataset(training_set, all_y_train), batch_size=best_params['batch_size'], shuffle=True, drop_last=False)\n",
    "    optimizer = torch.optim.Adam(lr=best_params['lr'], params=[p for p in final_model.parameters() if p.requires_grad])\n",
    "\n",
    "    for epoch in range(sorted(best_epochs)[int(len(best_epochs) \/ 2)] + 1):\n",
    "        train_loop(train_loader, final_model, loss_functions[best_params['loss_fn']], optimizer)\n",
    "\n",
    "\n",
    "    scores.append(test_loop(\n",
    "        DataLoader(\n",
    "            CancerDataset(\n",
    "                pd.DataFrame(scalers[best_params['scaler']].fit_transform(all_X_test.to_numpy()), columns=all_X_test.columns), all_y_test\n",
    "            ), batch_size=best_params['batch_size'], shuffle=False, drop_last=False\n",
    "        ),\n",
    "        final_model)\n",
    "    )\n",
    "\n",
    "    torch.save(final_model.state_dict(), f'final_model_{i}')\n",
    "\n",
    "print(f'Validation F1 score = {val_score}')\n",
    "\n",
    "result_dict['F1']['NN_shallow'] = sum(scores) \/ len(scores)\n",
    "\n",
    "result_dict"
   ],
   "execution_count":53,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Validation F1 score = 0.9825190358209227\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/plain":[
       "{'F1': {'Lasso': 0.9382716049382716, 'NN_shallow': 0.9397242982835083}}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"NZWHFi6M5GoMY4IL2Z2rT8",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "For reasons of reproducibility, the final model and sets are saved. (This is for my personal use â€” Never process or open pickle files from someone else, as that is not secure.) Note that the saving of the models has already been done in the code cell above."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"GJ94uVFtVw9sbJbWgI1Eeo",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pickle\n",
    "\n",
    "with open('all_X_train', 'wb+') as f:\n",
    "    pickle.dump(all_X_train, f)\n",
    "\n",
    "with open('all_X_test', 'wb+') as f:\n",
    "    pickle.dump(all_X_test, f)"
   ],
   "execution_count":51,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"zCTKsAOQPb9OCrpy9BAZk2",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# tracemalloc.stop()"
   ],
   "execution_count":52,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"fEzUx5DYJCD0NDfOE8QOfp",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "The improvement over the simple lasso model is not as significant as one might have thought. Perhaps the data is not complex enough for neural networks to really play their strengths. It should also be said that the lasso model is fully optimized as well and it seemed to have handled this kind of task quite nicely. Whatever the case, it does not really matter though, as for this notebook the journey was the goal. I hope that you had as interesting a time reading this as I had making it."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"C8OIJKmgww3reuOBACzkta",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "widgets":{
   "application\/vnd.jupyter.widget-state+json":{
    "version_major":2,
    "version_minor":0,
    "state":{
     "6db3f33375824d5b9103854f535417bb":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "e25ec013ed1b4317ad4df565013e8071":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"ProgressStyleModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"StyleView",
       "bar_color":null,
       "description_width":""
      }
     },
     "f062b39d3c5c4722b3a9bbc155dcf66d":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"FloatProgressModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"ProgressView",
       "bar_style":"success",
       "description":"",
       "description_tooltip":null,
       "layout":"IPY_MODEL_6db3f33375824d5b9103854f535417bb",
       "max":500,
       "min":0,
       "orientation":"horizontal",
       "style":"IPY_MODEL_e25ec013ed1b4317ad4df565013e8071",
       "value":500
      }
     },
     "7bc138bc28204730a6c892dd89d00cfd":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "fdf74a86fd194d82abb9b4d6f495c6d8":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"DescriptionStyleModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"StyleView",
       "description_width":""
      }
     },
     "65dff1dc58a44898b438a49eadecdb75":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"HTMLModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"HTMLView",
       "description":"",
       "description_tooltip":null,
       "layout":"IPY_MODEL_7bc138bc28204730a6c892dd89d00cfd",
       "placeholder":"â€‹",
       "style":"IPY_MODEL_fdf74a86fd194d82abb9b4d6f495c6d8",
       "value":"100%",
       "disabled":false
      }
     },
     "9183464ce4c34221bdc9617c4fc04b6b":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "b8a25a3fcef04db59d0fed80fbf1123b":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"DescriptionStyleModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"StyleView",
       "description_width":""
      }
     },
     "ffb844ec0e414cecb08d3f6020189fff":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"HTMLModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"HTMLView",
       "description":"",
       "description_tooltip":null,
       "layout":"IPY_MODEL_9183464ce4c34221bdc9617c4fc04b6b",
       "placeholder":"â€‹",
       "style":"IPY_MODEL_b8a25a3fcef04db59d0fed80fbf1123b",
       "value":" 500\/500 [1:09:53&lt;00:00, 17.52s\/it]",
       "disabled":false
      }
     },
     "8ce28f79880846e6b9fd4fe1468aac6d":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "2e2302b3388a420eb06d1dd1458e816c":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"HBoxModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"HBoxView",
       "box_style":"",
       "children":[
        "IPY_MODEL_65dff1dc58a44898b438a49eadecdb75",
        "IPY_MODEL_f062b39d3c5c4722b3a9bbc155dcf66d",
        "IPY_MODEL_ffb844ec0e414cecb08d3f6020189fff"
       ],
       "layout":"IPY_MODEL_8ce28f79880846e6b9fd4fe1468aac6d"
      }
     },
     "988cc6d0b6584246b7b13695231c11b1":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "89ff62e17efa40309f33549727affbef":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"ProgressStyleModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"StyleView",
       "bar_color":null,
       "description_width":""
      }
     },
     "03ba300c2d4e4dae825385d82321a2ca":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"FloatProgressModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"ProgressView",
       "bar_style":"success",
       "description":"",
       "description_tooltip":null,
       "layout":"IPY_MODEL_988cc6d0b6584246b7b13695231c11b1",
       "max":150,
       "min":0,
       "orientation":"horizontal",
       "style":"IPY_MODEL_89ff62e17efa40309f33549727affbef",
       "value":150
      }
     },
     "737d04125cc74ecca634fd003bc26598":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "5f960035084c441c991178a3ab023cbf":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"DescriptionStyleModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"StyleView",
       "description_width":""
      }
     },
     "3050c4e61a2b4155b83208732ce5d0e2":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"HTMLModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"HTMLView",
       "description":"",
       "description_tooltip":null,
       "layout":"IPY_MODEL_737d04125cc74ecca634fd003bc26598",
       "placeholder":"â€‹",
       "style":"IPY_MODEL_5f960035084c441c991178a3ab023cbf",
       "value":"100%",
       "disabled":false
      }
     },
     "cbe2474b2c284e3fa50f63a001911b03":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "1432f9a2aaf144958471301b7bd20512":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"DescriptionStyleModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"StyleView",
       "description_width":""
      }
     },
     "4ceb9657129d44f193507ae17cc0ecfe":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"HTMLModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"HTMLView",
       "description":"",
       "description_tooltip":null,
       "layout":"IPY_MODEL_cbe2474b2c284e3fa50f63a001911b03",
       "placeholder":"â€‹",
       "style":"IPY_MODEL_1432f9a2aaf144958471301b7bd20512",
       "value":" 150\/150 [00:55&lt;00:00,  3.57it\/s]",
       "disabled":false
      }
     },
     "f8ba1a30fa324622bef138434e548ab3":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "_model_module":"@jupyter-widgets\/base",
       "_model_module_version":"1.2.0",
       "_model_name":"LayoutModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/base",
       "_view_module_version":"1.2.0",
       "_view_name":"LayoutView",
       "align_content":null,
       "align_items":null,
       "align_self":null,
       "border":null,
       "bottom":null,
       "display":null,
       "flex":null,
       "flex_flow":null,
       "grid_area":null,
       "grid_auto_columns":null,
       "grid_auto_flow":null,
       "grid_auto_rows":null,
       "grid_column":null,
       "grid_gap":null,
       "grid_row":null,
       "grid_template_areas":null,
       "grid_template_columns":null,
       "grid_template_rows":null,
       "height":null,
       "justify_content":null,
       "justify_items":null,
       "left":null,
       "margin":null,
       "max_height":null,
       "max_width":null,
       "min_height":null,
       "min_width":null,
       "object_fit":null,
       "object_position":null,
       "order":null,
       "overflow":null,
       "overflow_x":null,
       "overflow_y":null,
       "padding":null,
       "right":null,
       "top":null,
       "visibility":null,
       "width":null
      }
     },
     "22d82dea14c545889bbe7680f44fcc7f":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "_dom_classes":[
        
       ],
       "_model_module":"@jupyter-widgets\/controls",
       "_model_module_version":"1.5.0",
       "_model_name":"HBoxModel",
       "_view_count":null,
       "_view_module":"@jupyter-widgets\/controls",
       "_view_module_version":"1.5.0",
       "_view_name":"HBoxView",
       "box_style":"",
       "children":[
        "IPY_MODEL_3050c4e61a2b4155b83208732ce5d0e2",
        "IPY_MODEL_03ba300c2d4e4dae825385d82321a2ca",
        "IPY_MODEL_4ceb9657129d44f193507ae17cc0ecfe"
       ],
       "layout":"IPY_MODEL_f8ba1a30fa324622bef138434e548ab3"
      }
     }
    }
   }
  },
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"iterative-stratification",
     "source":"PIP"
    },
    {
     "name":"optuna",
     "version":"3.0.3",
     "source":"PIP"
    },
    {
     "name":"memory-profiler",
     "version":"0.60.0",
     "source":"PIP"
    }
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}